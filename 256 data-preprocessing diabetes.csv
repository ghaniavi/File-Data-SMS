Authors,Title,Publication year,Abstract,Keywords
Dagher I,Art networks with geometrical distances,2006,"In this paper, ART networks (Fuzzy ART and Fuzzy ARTMAP) with geometrical norms are presented. The category choice of these networks is based on the Lp norm. Geometrical properties of these architectures are presented. Comparisons between this category choice and the category choice of the ART networks are illustrated. And simulation results on the databases taken from the UCI repository are performed. It will be shown that using the Lp norm is geometrically more attractive. It will operate directly on the input patterns without the need for doing any preprocessing. It should be noted that the ART architecture requires two preprocessing steps: normalization and complement coding. Simulation results on different databases show the good generalization performance of the Fuzzy ARTMAP with Lp norm compared to the performance of a typical Fuzzy ARTMAP.","norm, Fuzzy ART, Fuzzy ARTMAP, Neural networks, Category choice"
"Ding X,Mower J,Subramanian D,Cohen T",Augmenting aer2vec: Enriching distributed representations of adverse event report data with orthographic and lexical information,2021,"Adverse Drug Events (ADEs) are prevalent, costly, and sometimes preventable. Post-marketing drug surveillance aims to monitor ADEs that occur after a drug is released to market. Reports of such ADEs are aggregated by reporting systems, such as the Food and Drug Administration (FDA) Adverse Event Reporting System (FAERS). In this paper, we consider the topic of how best to represent data derived from reports in FAERS for the purpose of detecting post-marketing surveillance signals, in order to inform regulatory decision making. In our previous work, we developed aer2vec, a method for deriving distributed representations (concept embeddings) of drugs and side effects from ADE reports, establishing the utility of distributional information for pharmacovigilance signal detection. In this paper, we advance this line of research further by evaluating the utility of encoding orthographic and lexical information. We do so by adapting two Natural Language Processing methods, subword embedding and vector retrofitting, which were developed to encode such information into word embeddings. Models were compared for their ability to distinguish between positive and negative examples in a set of manually curated drug/ADE relationships, with both aer2vec enhancements offering advantages in performances over baseline models, and best performance obtained when retrofitting and subword embeddings were applied in concert. In addition, this work demonstrates that models leveraging distributed representations do not require extensive manual preprocessing to perform well on this pharmacovigilance signal detection task, and may even benefit from information that would otherwise be lost during the normalization and standardization process.","Pharmacovigilance, Post-marketing surveillance, Natural language processing, Word embeddings, Retrofitting, Subword embeddings"
"Li J,Chen Q,Hu X,Yuan P,Cui L,Tu L,Cui J,Huang J,Jiang T,Ma X,Yao X,Zhou C,Lu H,Xu J",Establishment of noninvasive diabetes risk prediction model based on tongue features and machine learning techniques,2021,"Background Diabetes is a chronic noncommunicable disease with high incidence rate. Diabetics without early diagnosis or standard treatment may contribute to serious multisystem complications, which can be life threatening. Timely detection and intervention of prediabetes is very important to prevent diabetes, because it is inevitable in the development and progress of the disease. Objective Our objective was to establish the predictive model that can be applied to evaluate people with blood glucose in high and critical state. Methods We established the diabetes risk prediction model formed by a combined TCM tongue diagnosis with machine learning techniques. 1512 subjects were recruited from the hospital. After data preprocessing, we got the dataset 1 and dataset 2. Dataset 1 was used to train classical machine learning model, while dataset 2 was used to train deep learning model. To evaluate the performance of the prediction model, we used Classification Accuracy(CA), Precision, Recall, F1-score, Precision-Recall curve(P-R curve), Area Under the Precision-Recall curve(AUPRC), Receiver Operating Characteristic curve(ROC curve), Area Under the Receiver Operating Characteristic curve(AUROC), then selected the best diabetes risk prediction model. Results On the test set of dataset 1, the CA of non-invasive Stacking model was 71 %, micro average AUROC was 0.87, macro average AUROC was 0.84, and micro average AUPRC was 0.77. In the critical blood glucose group, the AUROC was 0.84, AUPRC was 0.67. In the high blood glucose group, AUROC was 0.87, AUPRC was 0.83. On the validation set of dataset 2, the CA of ResNet50 model was 69 %, micro average AUROC was 0.84, macro average AUROC was 0.83, and micro average AUPRC was 0.73. In the critical blood glucose group, AUROC was 0.88, AUPRC was 0.71. In the high blood glucose group, AUROC was 0.80, AUPRC was 0.76. On the test set of dataset 2, the CA of ResNet50 model was 65 %, micro average AUROC was 0.83, macro average AUROC was 0.82, and micro average AUPRC was 0.71. In the critical blood glucose group, the prediction of AUROC was 0.84, AUPRC was 0.60. In the high blood glucose group, AUROC was 0.87, AUPRC was 0.71. Conclusions Tongue features can improve the prediction accuracy of the diabetes risk prediction model formed by classical machine learning model significantly. In addition to the excellent performance, Stacking model and ResNet50 model which were recommended had non-invasive operation and were easy to use. Stacking model and ResNet50 model had high precision, low false positive rate and low misdiagnosis rate on detecting hyperglycemia. While on detecting blood glucose value in critical state, Stacking model and ResNet50 model had a high sensitivity, a low false negative rate and a low missed diagnosis rate. The study had proved that the differential changes of tongue features reflected the abnormal glucose metabolism, thus the diabetes risk prediction model formed by a combined TCM tongue diagnosis and machine learning technique was feasible.","Chinese medicine, Tongue diagnosis, Diabetes, High blood glucose, Critical blood glucose, Non-invasive, Machine learning, Risk prediction"
"Tsiknakis N,Theodoropoulos D,Manikis G,Ktistakis E,Boutsora O,Berto A,Scarpa F,Scarpa A,Fotiadis DI,Marias K",Deep learning for diabetic retinopathy detection and classification based on fundus images: A review,2021,"Diabetic Retinopathy is a retina disease caused by diabetes mellitus and it is the leading cause of blindness globally. Early detection and treatment are necessary in order to delay or avoid vision deterioration and vision loss. To that end, many artificial-intelligence-powered methods have been proposed by the research community for the detection and classification of diabetic retinopathy on fundus retina images. This review article provides a thorough analysis of the use of deep learning methods at the various steps of the diabetic retinopathy detection pipeline based on fundus images. We discuss several aspects of that pipeline, ranging from the datasets that are widely used by the research community, the preprocessing techniques employed and how these accelerate and improve the models' performance, to the development of such deep learning models for the diagnosis and grading of the disease as well as the localization of the disease's lesions. We also discuss certain models that have been applied in real clinical settings. Finally, we conclude with some important insights and provide future research directions.","Artificial intelligence, Classification, Deep learning, Detection, Diabetic retinopathy, Fundus, Retina, Review, Segmentation"
"Herrera-Pereda R,Taboada Crispi A,Babin D,Philips W,Holsbach Costa M",A Review On digital image processing techniques for in-Vivo confocal images of the cornea,2021,"This work reviews the scientific literature regarding digital image processing for in vivo confocal microscopy images of the cornea. We present and discuss a selection of prominent techniques designed for semi- and automatic analysis of four areas of the cornea (epithelium, sub-basal nerve plexus, stroma and endothelium). The main context is image enhancement, detection of structures of interest, and quantification of clinical information. We have found that the preprocessing stage lacks of quantitative studies regarding the quality of the enhanced image, or its effects in subsequent steps of the image processing. Threshold values are widely used in the reviewed methods, although generally, they are selected empirically and manually. The image processing results are evaluated in many cases through comparison with gold standards not widely accepted. It is necessary to standardize values to be quantified in terms of sensitivity and specificity of methods. Most of the reviewed studies do not show an estimation of the computational cost of the image processing. We conclude that reliable, automatic, computer-assisted image analysis of the cornea is still an open issue, constituting an interesting and worthwhile area of research.","Cornea, Confocal microscopy, Digital image processing, Review"
"Wu H,Yang S,Huang Z,He J,Wang X",Type 2 diabetes mellitus prediction model based on data mining,2018,"Due to its continuously increasing occurrence, more and more families are influenced by diabetes mellitus. Most diabetics know little about their health quality or the risk factors they face prior to diagnosis. In this study, we have proposed a novel model based on data mining techniques for predicting type 2 diabetes mellitus (T2DM). The main problems that we are trying to solve are to improve the accuracy of the prediction model, and to make the model adaptive to more than one dataset. Based on a series of preprocessing procedures, the model is comprised of two parts, the improved K-means algorithm and the logistic regression algorithm. The Pima Indians Diabetes Dataset and the Waikato Environment for Knowledge Analysis toolkit were utilized to compare our results with the results from other researchers. The conclusion shows that the model attained a 3.04% higher accuracy of prediction than those of other researchers. Moreover, our model ensures that the dataset quality is sufficient. To further evaluate the performance of our model, we applied it to two other diabetes datasets. Both experiments' results show good performance. As a result, the model is shown to be useful for the realistic health management of diabetes.","Hybrid prediction model, Data mining, Diabetes mellitus"
"Wang D,Zhang D,Lu G",A robust signal preprocessing framework for wrist pulse analysis,2016,"Wrist pulse has been a physical health indicator in Traditional Chinese Medicine (TCM) for a long history. With the development of sensor technology and bioinformatics, quantifying pulse diagnosis by using signal processing technology is attracting increasing attentions in recent years. Since wrist pulse signals collected by the sensors are often corrupted by artifacts in real situations, many approaches on the wrist pulse preprocessing including pulse de-noising and baseline wander removal are introduced for more accurate wrist pulse analysis. However, these scattered methods are incomplete with some limitations when used to preprocess our special pulse data for the clinical applications. This paper presents a robust signal preprocessing framework for wrist pulse analysis. The cascade filter based on frequency-dependent analysis (FDA) is first introduced to remove the high frequency noises and to select the significant pulse intervals. Then the curve fitting method is developed to adjust the direction and the baseline drift with minimum signal distortion. Last, the period segmentation and pulse normalization is applied for the feature extraction. The effectiveness of the proposed pulse preprocessing is validated through experiments on actual pulse records with biochemical markers. In contrast with the traditional methods, the proposed preprocessing framework is effective in extracting more accurate pulse features. And the highest classification rate 91.6% is obtained on diabetes diagnosis. The results demonstrate that our method is superior to the former pulse preprocessing researches and practical for wrist pulse analysis.","Wrist pulse preprocessing, Wavelet-based decomposition, Intra-class distance, Period segmentation"
"Garcia LP,Lehmann J,de Carvalho AC,Lorena AC",New label noise injection methods for the evaluation of noise filters,2019,"Noise is often present in real datasets used for training Machine Learning classifiers. Their disruptive effects in the learning process may include: increasing the complexity of the induced models, a higher processing time and a reduced predictive power in the classification of new examples. Therefore, treating noisy data in a preprocessing step is crucial for improving data quality and to reduce their harmful effects in the learning process. There are various filters using different concepts for identifying noisy examples in a dataset. Their ability in noise preprocessing is usually assessed in the identification of artificial noise injected into one or more datasets. This is performed to overcome the limitation that only a domain expert can guarantee whether a real example is indeed noisy. The most frequently used label noise injection method is the noise at random method, in which a percentage of the training examples have their labels randomly exchanged. This is carried out regardless of the characteristics and example space positions of the selected examples. This paper proposes two novel methods to inject label noise in classification datasets. These methods, based on complexity measures, can produce more challenging and realistic noisy datasets by the disturbance of the labels of critical examples situated close to the decision borders and can improve the noise filtering evaluation. An extensive experimental evaluation of different noise filters is performed using public datasets with imputed label noise and the influence of the noise injection methods are compared in both data preprocessing and classification steps.","Label noise, Noise injection, Borderline noise, Noise filters"
"An N,Xiao Y,Yuan J,Yang J,Alterovitz G",Extracting causal relations from the literature with word vector mapping,2019,"Causal graphs play an essential role in the determination of causalities and have been applied in many domains including biology and medicine. Traditional causal graph construction methods are usually data-driven and may not deliver the desired accuracy of a graph. Considering the vast number of publications with causality knowledge, extracting causal relations from the literature to help to establish causal graphs becomes possible. Current supervised-learning-based causality extraction methods requires sufficient labeled data to train a model, and rule-based causality extraction methods are limited by the predefined patterns. This paper proposes a causality extraction framework by integrating rule-based methods and unsupervised learning models to overcome these limitations. The proposed method consists of three modules, including data preprocessing, syntactic pattern matching, and causality determination. In data preprocessing, abstracts are crawled based on attribute names before sentences are extracted and simplified. In syntactic pattern matching, these simplified sentences are parsed to obtain the part-of-speech tags, and triples are achieved based on these tags by matching the two designed syntactic patterns. In causality determination, four verb seed sets are initialized, and word vectors are constructed for the verbs in both the seed sets and the triples by applying an unsupervised machine learning model. Causal relations are identified by comparing the similarity between the verbs in each triple and that in each seed set to overcome the limitation of the seed sets. Causality extraction results on the attributes from the risk factors for Alzheimer’s disease show that our method outperforms Bui’s method and Alashri’s method in terms of precision, recall, specificity, accuracy and F-score, with increases in the F-score of 8.29% and 5.37%, respectively.","Causality, Literature analysis, Word vector, Causal graph, Causal extraction"
Kiziloz HE,Classifier ensemble methods in feature selection,2021,"Feature selection has become an indispensable preprocessing step in an expert system. Improving the feature selection performance could guide such a system to make better decisions. Classifier ensembles are known to improve performance when compared to the use of a single classifier. In this study, we aim to perform a formal comparison of different classifier ensemble methods on the feature selection domain. For this purpose, we compare the performances of six classifier ensemble methods: a greedy approach, two average-based approaches, two majority voting approaches, and a meta-classifier approach. In our study, the classifier ensemble involves five machine learning techniques: Logistic Regression, Support Vector Machines, Extreme Learning Machine, Naïve Bayes, and Decision Tree. Experiments are carried on 12 well-known datasets, and results with statistical tests are provided. The results indicate that ensemble methods perform better than single classifiers, yet, they require a longer execution time. Moreover, they can minimize the number of features better than existing ensemble algorithms, namely Random Forest, AdaBoost, and Gradient Boosting, in a less amount of time. Among ensemble methods, the greedy based method performs well in terms of both classification accuracy and execution time.","Feature selection, Multiobjective optimization, Machine learning, Classifier ensemble"
"Antal B,Hajdu A",Improving microaneurysm detection in color fundus images by using context-aware approaches,2013,"In this paper, we present two approaches to improve microaneurysm detector ensembles. First, we provide an approach to select a set of preprocessing methods for a microaneurysm candidate extractor to enhance its detection performance in color fundus images. The performance of the candidate extractor with each preprocessing method is measured in six microaneurysm categories. The best performing preprocessing method for each category is selected and organized into an ensemble-based method. We tested our approach on the publicly available DiaretDB1 database, where the proposed approach led to an improvement regarding the individual approaches. Second, an adaptive weighting approach for microaneurysm detector ensembles is presented.The basis of the adaptive weighting approach is the spatial location and contrast of the detected microaneurysm. During training, the performance of ensemble members is measured with respect to these contextual information, which serves as a basis for the optimal weights assigned to the detectors. We have tested this approach on two publicly available datasets, where it showed its competitiveness compared without previously published ensemble-based approach for microaneurysm detection. Moreover, the proposed approach outperformed all the investigated individual detectors.","Microaneurysm detection, Retinal image processing, Ensemble learning, Context-aware weighting"
"Ahmed N,Ahammed R,Islam MM,Uddin MA,Akhter A,Talukder MA,Paul BK",Machine learning based diabetes prediction and development of smart web application,2021,"Diabetes is a very common disease affecting individuals worldwide. Diabetes increases the risk of long-term complications including heart disease, and kidney failure among others. People might live longer and lead healthier lives if this disease is detected early. Different supervised machine learning models trained with appropriate datasets can aid in diagnosing the diabetes at the primary stage. The goal of this work is to find effective machine-learning-based classifier models for detecting diabetes in individuals utilizing clinical data. The machine learning algorithms to be trained with several datasets in this article include Decision tree (DT), Naive Bayes (NB), k-nearest neighbor (KNN), Random Forest (RF), Gradient Boosting (GB), Logistic Regression (LR) and Support Vector Machine (SVM). We have applied efficient pre-processing techniques including label-encoding and normalization that improve the accuracy of the models. Further, using various feature selection approaches, we have identified and prioritized a number of risk factors. Extensive experiments have been conducted to analyze the performance of the model using two different datasets. Our model is compared with some recent study and the results show that the proposed model can provide better accuracy of 2.71% to 13.13% depending on the dataset and the adopted ML algorithm. Finally, a machine learning algorithm showing the highest accuracy is selected for further development. We integrate this model in a web application using python flask web development framework. The results of this study suggest that an appropriate preprocessing pipeline on clinical data and applying ML-based classification may predict diabetes accurately and efficiently.","Diabetes prediction, Machine learning, Flask, Accuracy, Random Forest (RF), Support Vector Machines (SVM), Logistic regression (LR), Gradient boosting (GB), k-nearest neighbor (k-NN)"
"Wang Y,Shan S",Accurate disease detection quantification of iris based retinal images using random implication image classifier technique,2021,"In a recent analysis, eye disease is complicated to predict the affected area by using fundus imaging. The eye disease like lesion, this lesion affected retinal image is due to unevenness illumination, contrast is low, and blurring image is analyzed, when this image is analysis not found the affected region of lesion affected retinal image in the conventional system. The conventional system is having some loss like accuracy less, and it takes more time to analyze the image, so the proposed technique is developed to diagnose eye retinal lesion disease to improve the image quality and increase the accuracy. The proposed Random Implication Image Classifier Technique (RIICT) method is developed in this system to classify the image in various color spaces can achieve excellent accuracy in different image analyzing. Preprocessing of the retinal image uses a median filter for noise removal and enhancement; this preprocessing process is covert the color image to grayscale image. In segmentation, the Discrete Image Clustering Technique (DICT) algorithms that are selected and arranged to produce seeds are used to separate the image foreground and background of the input image to find the affected region based on the similarity easily. The proposed Random Implication Image Classifier Technique (RIICT) algorithm is used to classifying the lesion results of this system. This proposed system detects the disease like cotton wool spot, lesion quickly, and classifies the development region in various iris images to handle in this system. Finally, the RIICT system is given a better accuracy result is 96.7%.","Random Implication Image Classifier Technique (RIICT), Discrete Image Clustering Technique (DICT), Median filter, Segmentation, Preprocessing"
"Arias-Garzón D,Alzate-Grisales JA,Orozco-Arias S,Arteaga-Arteaga HB,Bravo-Ortiz MA,Mora-Rubio A,Saborit-Torres JM,Serrano JÁ,de la Iglesia Vayá M,Cardona-Morales O,Tabares-Soto R",COVID-19 detection in X-ray images using convolutional neural networks,2021,"COVID-19 global pandemic affects health care and lifestyle worldwide, and its early detection is critical to control cases’ spreading and mortality. The actual leader diagnosis test is the Reverse transcription Polymerase chain reaction (RT-PCR), result times and cost of these tests are high, so other fast and accessible diagnostic tools are needed. Inspired by recent research that correlates the presence of COVID-19 to findings in Chest X-ray images, this papers’ approach uses existing deep learning models (VGG19 and U-Net) to process these images and classify them as positive or negative for COVID-19. The proposed system involves a preprocessing stage with lung segmentation, removing the surroundings which does not offer relevant information for the task and may produce biased results; after this initial stage comes the classification model trained under the transfer learning scheme; and finally, results analysis and interpretation via heat maps visualization. The best models achieved a detection accuracy of COVID-19 around 97%.","COVID-19, Deep learning, Transfer learning, X-ray, Segmentation"
"Sharma M,Singh G,Singh R",Stark Assessment of Lifestyle Based Human Disorders Using Data Mining Based Learning Techniques,2017,"Background: Medical informatics has observed an unrestrained growth in the database. Latest advancements in the field of medical sciences have wiped out lots of critical diseases. Nowadays, the medical industry is affluent in data sources. These data sources are of use only if these are effectively analyzed on time. Methods: Data mining techniques are artificially intelligent and used to investigate known and unknown patterns available in the medical databases. Nowadays, data mining techniques are chronically used to mine abundant data sources of medical science. This paper explores the practice of diverse data mining techniques, the role of dataset used, effect of preprocessing, and the performances of different data mining techniques in diagnosis of different lifestyle based diseases. The venture of this paper is to fetch out stark assessments of different data mining techniques used in medical sciences. Results: By far, surveillance discloses that significant effort has been made for mining the data allied to the Cardiology and Diabetes. As per Google Scholar, in last seven years, the percentage of articles published related to cardio, diabetes, digestive, dentistry and ophthalmology disease diagnosis using data mining are 42%, 26%, 18%, 10% and 4% respectively. So, a little attention has been paid to develop predictive model for the diseases viz. ophthalmology, dentistry and digestive disorders. In addition, the rate of usage of preprocessing in diagnosis of different disorders related to cardio, diabetes, digestive, dentistry and ophthalmology lies between 10.65%–17.75%, 8.48%–14.80%, 4.58–8.93%, 2.96%–7.73% and 5.83%–12.93% respectively. Conclusion: An attention is obligatory to develop smart diagnostic system to aware and save human masses from wide critical spectrum of diseases related to ophthalmology, oral and digestive systems.","Data mining, Lifestyle, Heart disease, Diabetes, Ophthalmology, Oral and digestive disorder"
"Fathi S,Ahmadi M,Birashk B,Dehnad A",Development and use of a clinical decision support system for the diagnosis of social anxiety disorder,2020,"Background Mental disorders, according to the definition of World Health Organization, consist of a wide range of signs, which are generally specified by a combination of unusual thoughts, feelings, behavior, and relationships with others. Social anxiety disorder (SAD) is one of the most prevalent mental disorders, described as permanent and severe fear or feeling of embarrassment in social situations. Considering the imprecise nature of SAD symptoms, the main objective of this study was to generate an intelligent decision support system for SAD diagnosis, using Adaptive neuro-fuzzy inference system (ANFIS) technique and to conduct an evaluation method, using sensitivity, specificity and accuracy metrics. Method In this study, a real-world dataset with the sample size of 214 was selected and used to generate the model. The method comprised a multi-stage procedure named preprocessing, classification, and evaluation. The preprocessing stage, itself, consists of three steps called normalization, feature selection, and anomaly detection, using the Self-Organizing Map (SOM) clustering method. The ANFIS technique with 5-fold cross-validation was used for the classification of social anxiety disorder. Results and conclusion The preprocessed dataset with seven input features were used to train the ANFIS model. The hybrid optimization learning algorithm and 41 epochs were used as optimal learning parameters. The accuracy, sensitivity, and specificity metrics were reported 98.67%, 97.14%, and 100%, respectively. The results revealed that the proposed model was quite appropriate for SAD diagnosis and in line with findings of other studies. Further research study addressing the design of a decision support system for diagnosing the severity of SAD is recommended.","Social anxiety disorder, Social phobia, Adaptive neuro-fuzzy inference system, Neuro-fuzzy, Artificial intelligence, Clinical decision support system"
"Nahato KB,Nehemiah KH,Kannan A",Hybrid approach using fuzzy sets and extreme learning machine for classifying clinical datasets,2016,"Data mining techniques play a major role in developing computer aided diagnosis systems and expert systems that will aid a physician in clinical decision making. In this work, a classifier that combines the relative merits of fuzzy sets and extreme learning machine (FELM) for clinical datasets is proposed. The three major subsystems in the FELM framework are preprocessing subsystem, fuzzification subsystem and classification subsystem. Missing value imputation and outlier elimination are handled by the preprocessing subsystem. The fuzzification subsystem maps each feature to a fuzzy set and the classification subsystem uses extreme learning machine for classification. Cleveland heart disease (CHD), Statlog heart disease (SHD) and Pima Indian diabetes (PID) datasets from the University of California Irvine (UCI) machine learning repository have been used for experimentation. The CHD and SHD datasets have been experimented with two class labels one indicating the absence and the other indicating the presence of heart disease. The CHD dataset has also been experimented with five class labels, one class label indicating the absence of heart disease and the other four class labels indicating the severity of heart disease namely low risk, medium risk, high risk and serious. The PID data set has been experimented with two class labels one indicating the absence and the other indicating the presence of gestational diabetes. The classifier has achieved an accuracy of 93.55% for CHD data set with two class labels; 73.77% for CHD data set with five class labels; 94.44% for SHD data set and 92.54% for PID dataset.","Extreme learning machine, Fuzzification, Fuzzy set, Classification, Euclidean distance, Membership function"
"Murugesan S,Tay DB,Cooke I,Faou P",Application of dual tree complex wavelet transform in tandem mass spectrometry,2015,"Mass Spectrometry (MS) is a widely used technique in molecular biology for high throughput identification and sequencing of peptides (and proteins). Tandem mass spectrometry (MS/MS) is a specialised mass spectrometry technique whereby the sequence of peptides can be determined. Preprocessing of the MS/MS data is indispensable before performing any statistical analysis on the data. In this work, preprocessing of MS/MS data is proposed based on the Dual Tree Complex Wavelet Transform (DTCWT) using almost symmetric Hilbert pair of wavelets. After the preprocessing step, the identification of peptides is done using the database search approach. The performance of the proposed preprocessing technique is evaluated by comparing its performance against Discrete Wavelet Transform (DWT) and Stationary Wavelet Transform (SWT). The preprocessing performed using DTCWT identified more peptides compared to DWT and SWT.","Tandem mass spectrometry, Proteomic data processing, Dual tree complex wavelet transform, Signal denoising, Peptides detection"
"Truda G,Marais P",Evaluating warfarin dosing models on multiple datasets with a novel software framework and evolutionary optimisation,2021,"Warfarin is an effective preventative treatment for arterial and venous thromboembolism, but requires individualised dosing due to its narrow therapeutic range and high individual variation. Many machine learning techniques have been demonstrated in this domain. This study evaluated the accuracy of the most promising algorithms on the International Warfarin Pharmacogenetics Consortium dataset and a novel clinical dataset of South African patients. Support vectors and linear regression were amongst the top performers in both datasets and performed comparably to recent stacked ensemble approaches, whilst neural networks were one of the worst performers in both datasets. We also introduced genetic programming to automatically optimise model architectures and hyperparameters without human guidance. Remarkably, the generated models were found to match the performance of the best models hand-crafted by human experts. Finally, we present a novel software framework (Warfit-learn) for warfarin dosing research. It leverages the most successful techniques in preprocessing, imputation, and parallel evaluation, with the goal of accelerating research and making results in this domain more reproducible.","Warfarin, Machine learning, Genetic programming, Python, Supervised learning, Anticoagulant, Pharmacogenetics, Software"
"Burattini L,Bini S,Burattini R",Automatic microvolt T-wave alternans identification in relation to ECG interferences surviving preprocessing,2011,"The aim was to investigate the effect of interferences surviving preprocessing (residual noise, baseline wanderings, respiration modulation, replaced beats, missed beats and T-waves misalignment) on automatic identification of T-wave alternans (TWA), an ECG index of risk for sudden cardiac death. The procedures denominated fast-Fourier-transform spectral method (FFTSM), complex-demodulation method (CDM), modified-moving-average method (MMAM), Laplacian-likelihood-ratio method (LLRM), and adaptive-match-filter method (AMFM) were applied to interferences-corrupted synthetic ECG tracings and Holter ECG recordings from control-healthy subjects (CH-group; n=25) and acute-myocardial-infarction patients (AMI group; n=25). The presence of interferences in simulated data caused detection of false-positive TWA by all techniques but the FFTSM and AMFM. Clinical applications evidenced a discrepancy in that the FFTSM and LLRM detected no more than one TWA case in each population, whereas the CDM, MMAM, and AMFM detected TWA in all CH-subjects and AMI-patients, with significantly lower TWA amplitude in the former group. Because the AMFM is not prone to false-positive TWA detections, the latter finding suggests TWA as a phenomenon having continuously changing amplitude from physiological to pathological conditions. Only occasional detection of TWA by the FFTSM and LLRM in clinics can be ascribed to their limited ability in identifying TWA in the presence of interferences surviving preprocessing.","T-wave alternans, Adaptive-match-filter method, Fast-Fourier-transform spectral method, Complex-demodulation method, Laplacian-likelihood-ratio method, Modified-moving-average method"
"Zhou L,Siddiqui T,Seliger SL,Blumenthal JB,Kang Y,Doerfler R,Fink JC",Text preprocessing for improving hypoglycemia detection from clinical notes – A case study of patients with diabetes,2019,"Background and objective Hypoglycemia is a common safety event when attempting to optimize glycemic control in diabetes (DM). While electronic medical records provide a natural ground for detecting and analyzing hypoglycemia, ICD codes used in the databases may be invalid, insensitive or non-specific in detecting new hypoglycemic events. We developed text preprocessing methods to improve automatic detection of hypoglycemia from analysis of clinical encounter text notes. Methods We set out to improve hypoglycemia detection from clinical notes by introducing three preprocessing methods: stop word filtering, medication signaling, and ICD narrative enrichment. To test the proposed methods, we selected clinical notes from VA Maryland Healthcare System, based on various combinations of three criteria that are suggestive of hypoglycemia, including ICD-9 code of diabetes and hypoglycemia, laboratory glucose values < 70 md/dL, and text reference to a proximate hypoglycemia event. In addition, we constructed one dataset of 395 clinical notes from year 2009 and another of 460 notes from year 2014 to test the generality of the proposed methods. For each of the datasets, two physician judges manually reviewed individual clinical notes to determine whether hypoglycemia was present or absent. A third physician judge served as a final adjudicator for disagreements. Results Each of the proposed preprocessing methods contributed to the performance of hypoglycemia detection by significantly increasing the F1 score in the range of 5.3?7.4% on one dataset (p < .01). Among the methods, stop word filtering contributed most to the performance improvement (7.4%). Combining all the preprocessing methods led to greater performance gain (p < .001) compared with using each method individually. Similar patterns were observed for the other dataset with the F1 score being increased in the range of 7.7%?9.4% by individual methods (p < .001). Nevertheless, combining the three methods did not yield additional performance gain. Conclusion The proposed text preprocessing methods improved the performance of hypoglycemia detection from clinical text notes. Stop word filtering achieved the most performance improvement. ICD narrative enrichment boosted the recall of detection. Combining the three preprocessing methods led to additional performance gains.","Hypoglycemia, Adverse safety events detection, Diabetes, Text preprocessing, Clinical notes"
"Nayantara PV,Kamath S,Manjunath KN,Rajagopal KV",Computer-aided diagnosis of liver lesions using CT images: A systematic review,2020,"Background Medical image processing has a strong footprint in radio diagnosis for the detection of diseases from the images. Several computer-aided systems were researched in the recent past to assist the radiologist in diagnosing liver diseases and reducing the interpretation time. The aim of this paper is to provide an overview of the state-of-the-art techniques in computer-assisted diagnosis systems to predict benign and malignant lesions using computed tomography images. Methods The research articles published between 1998 and 2020 obtained from various standard databases were considered for preparing the review. The research papers include both conventional as well as deep learning-based systems for liver lesion diagnosis. The paper initially discusses the various hepatic lesions that are identifiable on computed tomography images, then the computer-aided diagnosis systems and their workflow. The conventional and deep learning-based systems are presented in stages wherein the various methods used for preprocessing, liver and lesion segmentation, radiological feature extraction and classification are discussed. Conclusion The review suggests the scope for future, work as efficient and effective segmentation methods that work well with diverse images have not been developed. Furthermore, unsupervised and semi-supervised deep learning models were not investigated for liver disease diagnosis in the reviewed papers. Other areas to be explored include image fusion and inclusion of essential clinical features along with the radiological features for better classification accuracy.","Computer-aided detection/diagnosis, Liver diseases, Hemangioma, Hepatocellular carcinoma, Liver/lesion segmentation, Feature extraction, Classification, Deep learning"
Thuraisingham RA,Preprocessing RR interval time series for heart rate variability analysis and estimates of standard deviation of RR intervals,2006,"Heart rate variability is concerned with the analysis of the fluctuations in the interval between heart beats known as RR intervals. The long time RR time series obtained suffer from non-stationarity and the presence of ectopic beats, which prevents extraction of useful statistical information. The paper describes a wavelet-based technique for trend removal and a nonlinear filter to remove ectopic beats. This attempts to correct the limitations observed in a recent advanced heart rate toolkit [J. Niskanen, M.P. Tarvainen, P.O. Ranta-aho P.A. Karjalainen, Software for advanced HRV analysis, Comput. Meth. Prog. Biomed.,76 (2004) 73–81] when preprocessing. The results are encouraging. The preprocessed data are then used to obtain the standard deviation of RR interval time series (SDRR) of 15 healthy patients and 15 patients suffering from congestive heart failure. The results demonstrate the importance of preprocessing. The analysis show that the SDRR values of congestive heart failure patients are depressed compared to the healthy group.","Detrending, Artifact removal, Standard deviation of RR intervals"
"Idri A,Benhar H,Fernández-Alemán JL,Kadi I",A systematic map of medical data preprocessing in knowledge discovery,2018,"Background and objective Datamining (DM) has, over the last decade, received increased attention in the medical domain and has been widely used to analyze medical datasets in order to extract useful knowledge and previously unknown patterns. However, historical medical data can often comprise inconsistent, noisy, imbalanced, missing and high dimensional data. These challenges lead to a serious bias in predictive modeling and reduce the performance of DM techniques. Data preprocessing is, therefore, an essential step in knowledge discovery as regards improving the quality of data and making it appropriate and suitable for DM techniques. The objective of this paper is to review the use of preprocessing techniques in clinical datasets. Methods We performed a systematic map of studies regarding the application of data preprocessing to healthcare and published between January 2000 and December 2017. A search string was determined on the basis of the mapping questions and the PICO categories. The search string was then applied in digital databases covering the fields of computer science and medical informatics in order to identify relevant studies. The studies were initially selected by reading their titles, abstracts and keywords. Those that were selected at that stage were then reviewed using a set of inclusion and exclusion criteria in order to eliminate any that were not relevant. This process resulted in 126 primary studies. Results Selected studies were analyzed and classified according to their publication years and channels, research type, empirical type and contribution type. The findings of this mapping study revealed that researchers have paid a considerable amount of attention to preprocessing in medical DM in last decade. A significant number of the selected studies used data reduction and cleaning preprocessing tasks. Moreover, the disciplines in which preprocessing have received most attention are: cardiology, endocrinology and oncology. Conclusions Researchers should develop and implement standards for an effective integration of multiple medical data types. Moreover, we identified the need to perform literature reviews.","Medical datamining, Data preprocessing, Clinical data, Mapping study, Electronic heath records"
"Liu Y,Nie F,Wu J,Chen L",Efficient semi-supervised feature selection with noise insensitive trace ratio criterion,2013,"Feature selection is an effective method to deal with high-dimensional data. While in many applications such as multimedia and web mining, the data are often high-dimensional and very large scale, but the labeled data are often very limited. On these kind of applications, it is important that the feature selection algorithm is efficient and can explore labeled data and unlabeled data simultaneously. In this paper, we target on this problem and propose an efficient semi-supervised feature selection algorithm to select relevant features using both labeled and unlabeled data. First, we analyze a popular trace ratio criterion in the dimensionality reduction, and point out that the trace ratio criterion tends to select features with very small variance. To solve this problem, we propose a noise insensitive trace ratio criterion for feature selection with a re-scale preprocessing. Interestingly, the feature selection with the noise insensitive trace ratio criterion can be much more efficiently solved. Based on the noise insensitive trace ratio criterion, we propose a new semi-supervised feature selection algorithm. The algorithm fully explores the distribution of the labeled and unlabeled data with a special label propagation method. Experimental results verify the effectiveness of the proposed algorithm, and show improvement over traditional supervised feature selection algorithms.","Feature selection, Semi-supervised, Trace ratio, Graph based learning, Re-scale preprocessing"
"Wu B,Zhu W,Shi F,Zhu S,Chen X",Automatic detection of microaneurysms in retinal fundus images,2017,"Diabetic retinopathy (DR) is one of the leading causes of new cases of blindness. Early and accurate detection of microaneurysms (MAs) is important for diagnosis and grading of diabetic retinopathy. In this paper, a new method for the automatic detection of MAs in eye fundus images is proposed. The proposed method consists of four main steps: preprocessing, candidate extraction, feature extraction and classification. A total of 27 characteristic features which contain local features and profile features are extracted for KNN classifier to distinguish true MAs from spurious candidates. The proposed method has been evaluated on two public database: ROC and e-optha. The experimental result demonstrates the efficiency and effectiveness of the proposed method, and it has the potential to be used to diagnose DR clinically.","Microaneurysms (MAs), Diabetic retinopathy (DR), Local features, Profile features, Classifier, Eye fundus images"
"Vostatek P,Claridge E,Uusitalo H,Hauta-Kasari M,Fält P,Lensu L",Performance comparison of publicly available retinal blood vessel segmentation methods,2017,"Retinal blood vessel structure is an important indicator of many retinal and systemic diseases, which has motivated the development of various image segmentation methods for the blood vessels. In this study, two supervised and three unsupervised segmentation methods with a publicly available implementation are reviewed and quantitatively compared with each other on five public databases with ground truth segmentation of the vessels. Each method is tested under consistent conditions with two types of preprocessing, and the parameters of the methods are optimized for each database. Additionally, possibility to predict the parameters of the methods by the linear regression model is tested for each database. Resolution of the input images and amount of the vessel pixels in the ground truth are used as predictors. The results show the positive influence of preprocessing on the performance of the unsupervised methods. The methods show similar performance for segmentation accuracy, with the best performance achieved by the method by Azzopardi et al. (Acc 94.0) on ARIADB, the method by Soares et al. (Acc 94.6, 94.7) on CHASEDB1 and DRIVE, and the method by Nguyen et al. (Acc 95.8, 95.5) on HRF and STARE. The method by Soares et al. performed better with regard to the area under the ROC curve. Qualitative differences between the methods are discussed. Finally, it was possible to predict the parameter settings that give performance close to the optimized performance of each method.","Fundus, Retinal imaging, Vessel segmentation"
"Cui S,Wang D,Wang Y,Yu PW,Jin Y",An improved support vector machine-based diabetic readmission prediction,2018,"Background and objective In healthcare systems, the cost of unplanned readmission accounts for a large proportion of total hospital payment. Hospital-specific readmission rate becomes a critical issue around the world. Quantification and early identification of unplanned readmission risks will improve the quality of care during hospitalization and reduce the occurrence of readmission. In clinical practice, medical workers generally use LACE score method to evaluate patient readmission risks, but this method usually performs poorly. With this in mind, this study presents a novel method combining support vector machine and genetic algorithm to build the risk prediction model, which simultaneously involves feature selection and the processing of imbalanced data. This model aims to provide decision support for clinicians during the discharge management of patients with diabetes. Method The experiments were conducted from a set of 8756 medical records with 50 different features about diabetic readmission. After preprocessing the data, an effective SMOTE-based method was proposed to solve the imbalance data problem. Further, in order to improve prediction performance, a hybrid feature selection mechanism was devised to select the important features. Subsequently, an improved support vector machine-based (SVM-based) method was developed and the genetic algorithm was used to tune the sensitive parameter of the algorithm. Finally, the five-fold cross-validation method was applied to compare the performance of proposed method with other methods (LACE score, logistic regression, naïve bayes, decision tree and feed forward neural networks). Results Experimental results indicate that the proposed SVM-based method achieves an accuracy of 81.02%, a sensitivity of 82.89%, a specificity of 79.23%, and outperforms other popular algorithms in identifying diabetic patients who may be readmitted. Conclusions Our research can improve the performance of clinic decision support systems for diabetic readmission, by which the readmission possibility as well as the waste of medical resources can be reduced.","Hospital readmission, Diabetes, Support vector machine, Synthetic minority over-sampling, Feature selection"
"Rodrigues LF,Naldi MC,Mari JF",Comparing convolutional neural networks and preprocessing techniques for HEp-2 cell classification in immunofluorescence images,2020,"Autoimmune diseases are the third highest cause of mortality in the world, and the identification of an anti-nuclear antibody via an immunofluorescence test for HEp-2 cells is a standard procedure to support diagnosis. In this work, we assess the performance of six preprocessing strategies and five state-of-the-art convolutional neural network architectures for the classification of HEp-2 cells. We also evaluate enhancement methods such as hyperparameter optimization, data augmentation, and fine-tuning training strategies. All experiments were validated using a five-fold cross-validation procedure over the training and test sets. In terms of accuracy, the best result was achieved by training the Inception-V3 model from scratch, without preprocessing and using data augmentation (98.28%). The results suggest the conclusions that most CNNs perform better on non-preprocessed images when trained from scratch on the analyzed dataset, and that data augmentation can improve the results from all models. Although fine-tuning training did not improve the accuracy compared to training the CNNs from scratch, it successfully reduced the training time.","Convolutional neural networks, HEp-2 cells, Staining pattern classification, Preprocessing, Data augmentation, Hyperparameters, Fine-tuning"
"Benhar H,Idri A,Fernández-Alemán JL",Data preprocessing for heart disease classification: A systematic literature review,2020,"Context Early detection of heart disease is an important challenge since 17.3 million people yearly lose their lives due to heart diseases. Besides, any error in diagnosis of cardiac disease can be dangerous and risks an individual's life. Accurate diagnosis is therefore critical in cardiology. Data Mining (DM) classification techniques have been used to diagnosis heart diseases but still limited by some challenges of data quality such as inconsistencies, noise, missing data, outliers, high dimensionality and imbalanced data. Data preprocessing (DP) techniques were therefore used to prepare data with the goal of improving the performance of heart disease DM based prediction systems. Objective The purpose of this study is to review and summarize the current evidence on the use of preprocessing techniques in heart disease classification as regards: (1) the DP tasks and techniques most frequently used, (2) the impact of DP tasks and techniques on the performance of classification in cardiology, (3) the overall performance of classifiers when using DP techniques, and (4) comparisons of different combinations classifier-preprocessing in terms of accuracy rate. Method A systematic literature review is carried out, by identifying and analyzing empirical studies on the application of data preprocessing in heart disease classification published in the period between January 2000 and June 2019. A total of 49 studies were therefore selected and analyzed according to the aforementioned criteria. Results The review results show that data reduction is the most used preprocessing task in cardiology, followed by data cleaning. In general, preprocessing either maintained or improved the performance of heart disease classifiers. Some combinations such as (ANN + PCA), (ANN + CHI) and (SVM + PCA) are promising terms of accuracy. However the deployment of these models in real-world diagnosis decision support systems is subject to several risks and limitations due to the lack of interpretation.","Datamining, Data preprocessing, Cardiology, Literature review, Cardiac datasets"
"Christy A,Gandhi GM,Vaithyasubramanian S",Cluster Based Outlier Detection Algorithm for Healthcare Data,2015,"Outliers has been studied in a variety of domains including Big Data, High dimensional data, Uncertain data, Time Series data, Biological data, etc. In majority of the sample datasets available in the repository, atleast 10% of the data may be erroneous, missing or not available. In this paper, we utilize the concept of data preprocessing for outlier reduction. We propose two algorithms namely Distance-Based outlier detection and Cluster-Based outlier algorithm for detecting and removing outliers using a outlier score. By cleaning the dataset and clustering based on similarity, we can remove outliers on the key attribute subset rather than on the full dimensional attributes of dataset. Experiments were conducted using 3 built-in Health care dataset available in R package and the results show that the cluster-based outlier detection algorithm providing better accuracy than distance based outlier detection algorithm.","Cluster-Based, Outlier Detection, Outlier Score, F-Measure, Likelihood Ratio, etc."
"Muns IW,Lad Y,Guardiola IG,Thimgan M",Classification of Rest and Active Periods in Actigraphy Data Using PCA,2017,"In this paper we highlight a clustering algorithm for the purpose of identifying sleep and wake periods directly from actigraphy signals. The paper makes use of statistical Principal Component Analysis to identify periods of rest and activity. The aim of the proposed methodology is to develop a quick and efficient method to determine the sleep duration of an individual. In addition, a robust method that can identify sleep periods in the accelerometer data when duration, time of day varies by individual. A selected group of 10 individual’s sensor data consisting of actigraphy from an accelerometer (3-axis), near body temperature, and lux sensors from a single GENEActiv watch worn on the non-dominant hand. The actigraphy of each individual was collected 24 hours a day for a period spanning 80 days. We highlight that a simple data preprocessing stage followed with a 2 phase clustering method provides results that align with previously validated methodologies.","Clustering, Actigraphy, Principal Component Analysis"
"Deng Y,Wang Y,Shen Y",An automated diagnostic system of polycystic ovary syndrome based on object growing,2011,"Objective Polycystic ovary syndrome (PCOS) is a complex endocrine disorder that seriously affects women's health. The disorder is characterized by the formation of many follicles in the ovary. Currently the predominant diagnosis is to manually count the number of follicles, which may lead to inter-observer and intra-observer variability and low efficiency. A computer-aided PCOS diagnostic system may overcome these problems. However the methods reported in recently published literature are not very effective and often need human interaction. To overcome these problems, we propose an automated PCOS diagnostic system based on ultrasound images. Methods and materials The proposed system consists of two major functional blocks: preprocessing phase and follicle identification based on object growing. In the preprocessing phase, speckle noise in the input image is removed by an adaptive morphological filter, then contours of objects are extracted using an enhanced labeled watershed algorithm, and finally the region of interest is automatically selected. The object growing algorithm for follicle identification first computes a cost map to distinguish between the ovary and its external region and assigns each object a cost function based on the cost map. The object growing algorithm initially selects several objects that are likely to be follicles with very high probabilities and dynamically update the set of possible follicles based on their cost functions. The proposed method was applied to 31 real PCOS ultrasound images obtained from patients and its performance was compared with those of three other methods, including level set method, boundary vector field (BVF) method and the fuzzy support vector machine (FSVM) classifier. Results Based on the judgment of subject matter experts, the proposed diagnostic system achieved 89.4% recognition rate (RR) and 7.45% misidentification rate (MR) while the RR and MR of the level set method, the BVF method and the FSVM classifier are around 65.3% and 2.11%, 76.1% and 4.53%, and 84.0% and 16.3%, respectively. The proposed diagnostic system also achieved better performance than those reported in recently published literature. Conclusion The paper proposed an automated diagnostic system for the PCOS using ultrasound images, which consists of two major functional blocks: preprocessing phase and follicle identification based on object growing. Experimental results showed that the proposed system is very effective in follicle identification for PCOS diagnosis.","Object growing, Automated detection of follicles, Polycystic ovary syndrome, Ultrasound images"
"Nithya A,Appathurai A,Venkatadri N,Ramji DR,Anna Palagan C",Kidney disease detection and segmentation using artificial neural network and multi-kernel k-means clustering for ultrasound images,2020,"The main aim of this paper is to design and develop an approach for kidney disease detection and segmentation using a combination of clustering and classification approach. Nowadays, kidney stone detection and segmentation is one of the crucial procedures in surgical and treatment planning for ultrasound images. However, at present, kidney stone segmentation in ultrasound images is mostly performed manually in clinical practice. Apart from being time-consuming, manual stone delineation is difficult and depends on the individual operator. Therefore, in this work, we proposed a kidney stone detection using artificial neural network and segmentation using multi-kernel k-means clustering algorithm. Normally, the system comprises of four modules like (i) preprocessing, (ii) feature extraction, (iii) classification and (iv) segmentation. Primarily, we eliminate the noise present in the input image using median filter. Then, we extract the important GLCM features from the image. After that, we classify the image as normal or abnormal using neural network classifier. Finally, the abnormal images are given to the segmentation stage to segment the stone and tumor part separately using multi. Kernel K-means clustering algorithm. The experimentation results show that the proposed system as linear + quadratic based segmentation achieves the maximum accuracy of 99.61%, compare with all other methods.","Ultrasound image, Neural network, Multi-kernel k-means clustering, GLCM features, Segmentation, Classification, Bilateral filter"
"Hayward J,Alvarez SA,Ruiz C,Sullivan M,Tseng J,Whalen G",Machine learning of clinical performance in a pancreatic cancer database,2010,"Objective We consider predictive models for clinical performance of pancreatic cancer patients based on machine learning techniques. The predictive performance of machine learning is compared with that of the linear and logistic regression techniques that dominate the medical oncology literature. Methods and materials We construct predictive models over a clinical database that we have developed for the University of Massachusetts Memorial Hospital in Worcester, Massachusetts, USA. The database contains retrospective records of 91 patient treatments for pancreatic tumors. Classification and regression targets include patient survival time, Eastern Cooperative Oncology Group (ECOG) quality of life scores, surgical outcomes, and tumor characteristics. The predictive performance of several techniques is described, and specific models are presented. Results We show that machine learning techniques attain a predictive performance that is as good as, or better than, that of linear and logistic regression, for target attributes that include tumor N and T stage, survival time, and ECOG quality of life scores. Bayesian techniques are found to provide the best performance overall. For tumor size as the target attribute, however, logistic regression (respectively linear regression in the case of a numerical as opposed to discrete target) performs best. Preprocessing in the form of attribute selection and supervised attribute discretization improves predictive performance for most of the predictive techniques and target attributes considered. Conclusion Machine learning provides techniques for improved prediction of clinical performance. These techniques therefore merit consideration as valuable alternatives to traditional multivariate regression techniques in clinical medical studies.","Machine learning, Predictive modeling, Clinical performance, Quality of life, Pancreatic cancer"
"Riquelme JC,Aguilar-Ruiz JS,Toro M",Finding representative patterns with ordered projections,2003,"This paper presents a new approach to finding representative patterns for dataset editing. The algorithm patterns by ordered projections (POP), has some interesting characteristics: important reduction of the number of instances from the dataset; lower computational cost (?(mnlogn)) with respect to other typical algorithms due to the absence of distance calculations; conservation of the decision boundaries, especially from the point of view of the application of axis-parallel classifiers. POP works well in practice with both continuous and discrete attributes. The performance of POP is analysed in two ways: percentage of reduction and classification. POP has been compared to IB2, ENN and SHRINK concerning the percentage of reduction and the computational cost. In addition, we have analysed the accuracy of k-NN and C4.5 after applying the reduction techniques. An extensive empirical study using datasets with continuous and discrete attributes from the UCI repository shows that POP is a valuable preprocessing method for the later application of any axis-parallel learning algorithm.","Data mining, Preprocessing techniques, Pattern analysis, Axis-parallel classifiers"
"Yazdani S,Shanbehzadeh J,Hadavandi E",MBCGP-FE: A modified balanced cartesian genetic programming feature extractor,2017,"Many data sets are represented by low-level or primitive features. This makes it difficult to discover relevant information via learning algorithm. Changing the way primitive data is represented can be advantageous. This can be performed using data preprocessing algorithms. A successful preprocessing algorithm should be capable of revealing the relationships among features to improve learners. These hidden relations among features can make the relevancy of the aspects of the data opaque to the learner. Automatic feature extraction is a solution to overcome this problem. This article introduces a Modified Balanced Cartesian Genetic Programming Feature Extractor (MBCGP-FE) for transforming the feature space to a smaller one composed of highly informative features through modifying the representation and operators of Balanced Cartesian Genetic Programming (BCGP). The new feature space is composed from original relevant and new constructed features which are created by discovering and compacting hidden relations among features. The size of the new feature space is determined during the optimization process. Experimental results on real data sets show that the MBCGP-FE improves the performance of learners and it is effective in reducing the dimension of data sets through the construction of new informative features. In addition, obtained results indicate the effectiveness of our proposed method in comparison with other feature extraction methods.","Feature interaction, Feature extraction, Balanced cartesian genetic programming, Dimensionality reduction"
"Berg J,Järvisalo M",Cost-optimal constrained correlation clustering via weighted partial Maximum Satisfiability,2017,"Integration of the fields of constraint solving and data mining and machine learning has recently been identified within the AI community as an important research direction with high potential. This work contributes to this direction by providing a first study on the applicability of state-of-the-art Boolean optimization procedures to cost-optimal correlation clustering under constraints in a general similarity-based setting. We develop exact formulations of the correlation clustering task as Maximum Satisfiability (MaxSAT), the optimization version of the Boolean satisfiability (SAT) problem. For obtaining cost-optimal clusterings, we apply a state-of-the-art MaxSAT solver for solving the resulting MaxSAT instances optimally, resulting in cost-optimal clusterings. We experimentally evaluate the MaxSAT-based approaches to cost-optimal correlation clustering, both on the scalability of our method and the quality of the clusterings obtained. Furthermore, we show how the approach extends to constrained correlation clustering, where additional user knowledge is imposed as constraints on the optimal clusterings of interest. We show experimentally that added user knowledge allows clustering larger datasets, and at the same time tends to decrease the running time of our approach. We also investigate the effects of MaxSAT-level preprocessing, symmetry breaking, and the choice of the MaxSAT solver on the efficiency of the approach.","Boolean optimization, Boolean satisfiability, Maximum satisfiability, Correlation clustering, Cost-optimal clustering, Constrained clustering"
"Kasambe PV,Rathod SS",VLSI Wavelet Based Denoising of PPG Signal,2015,"Wavelet denoising represents a common preprocessing step for several biomedical applications exposing low SNR. These applica- tions require real time processing along with minimization of power and area, only custom VLSI implementations can be adopted for this fulfillment. In this paper, Photoplethysmography (PPG) signal is used as a biomedical signal as an example. PPG is a non-invasive method in which relative blood volume changes in the blood close to skin is measured. The “pulse waveform” never underwent intensive investigation. Active investigation efforts are opening to reveal its effectiveness beyond oxygen saturation and determination of heart rate. With the introduction of pulse oximeter, this is one of the important waveforms that are normally dis- played in the clinical settings nowadays. But, the acquired PPG signal using PPG sensors are usually corrupted with different kinds of interference like Motion Artifacts, Power Line Noise, etc. We consider Power Line Noise for the performance evaluation of VLSI Wavelet based denoising of PPG signal. Different kinds of Wavelets such as db4, Coif1, Haar for denoising. Also, standard deviation and mean absolute deviation are used as evaluation criteria. Xilinx System Generator for DSP is exploited for the design of the architecture and simulation of proposed denoising method.","Wavelet Denoising, FPGA, Xilinx System Generator."
"Chen Y,Xiao F,Huang H,Sun L",RF-IDH: An intelligent fall detection system for hemodialysis patients via COTS RFID,2020,"Unhealthy habits lead to a growing population of hemodialysis patients. The single treatment of hemodialysis is about four hours long. Therefore, patients usually go to the toilet during treatment and need to be checked for safety. However, existing fall detection techniques are often limited by factors such as privacy, signal interference, and the like. In this paper, we propose RF-IDH tackle the above issues, a dedicated system for detecting falls caused by complications in hemodialysis patients using RF signal. In RF-IDH, after collecting the signal, we process the collected data by three functional module clusters, namely signal preprocessing, residual feature extraction, hemodialysis patient’s fall detection, all of which are well-designed to achieve high performance in patient’s fall detection. In particular, we design a residual feature extraction (RFE) algorithm based on the hemodialysis patient safety process model, and the fall detection of hemodialysis patients is treated as a machine learning problem where four classification models are built via learning residual feature space. We implement our system on commercial off-the-shelf RFID devices and compared the evaluation metrics of four different methods in terms of system performance, efficiency, robustness, and latency. The evaluation results show that our proposed RF-IDH that optimizes the 2NN–RFE method achieves superior performance compared to other methods.","Fall detection, Patient monitoring, Intelligent RFID, Machine learning in IoT"
"Escorcia-Gutierrez J,Torrents-Barrena J,Gamarra M,Romero-Aroca P,Valls A,Puig D",Convexity shape constraints for retinal blood vessel segmentation and foveal avascular zone detection,2020,"Diabetic retinopathy (DR) has become a major worldwide health problem due to the increase in blindness among diabetics at early ages. The detection of DR pathologies such as microaneurysms, hemorrhages and exudates through advanced computational techniques is of utmost importance in patient health care. New computer vision techniques are needed to improve upon traditional screening of color fundus images. The segmentation of the entire anatomical structure of the retina is a crucial phase in detecting these pathologies. This work proposes a novel framework for fast and fully automatic blood vessel segmentation and fovea detection. The preprocessing method involved both contrast limited adaptive histogram equalization and the brightness preserving dynamic fuzzy histogram equalization algorithms to enhance image contrast and eliminate noise artifacts. Afterwards, the color spaces and their intrinsic components were examined to identify the most suitable color model to reveal the foreground pixels against the entire background. Several samples were then collected and used by the renowned convexity shape prior segmentation algorithm. The proposed methodology achieved an average vasculature segmentation accuracy exceeding 96%, 95%, 98% and 94% for the DRIVE, STARE, HRF and Messidor publicly available datasets, respectively. An additional validation step reached an average accuracy of 94.30% using an in-house dataset provided by the Hospital Sant Joan of Reus (Spain). Moreover, an outstanding detection accuracy of over 98% was achieved for the foveal avascular zone. An extensive state-of-the-art comparison was also conducted. The proposed approach can thus be integrated into daily clinical practice to assist medical experts in the diagnosis of DR.","Diabetic retinopathy, Blood vessel segmentation, Convexity shape prior, Foveal avascular zone detection"
"Winder RJ,Morrow PJ,McRitchie IN,Bailie JR,Hart PM",Algorithms for digital image processing in diabetic retinopathy,2009,"This work examined recent literature on digital image processing in the field of diabetic retinopathy. Algorithms were categorized into 5 steps (preprocessing; localization and segmentation of the optic disk; segmentation of the retinal vasculature; localization of the macula and fovea; localization and segmentation of retinopathy). The variety of outcome measures, use of a gold standard or ground truth, data sample sizes and the use of image databases is discussed. It is intended that our classification of algorithms into a small number of categories, definition of terms and discussion of evolving techniques will provide guidance to algorithm designers for diabetic retinopathy.","Diabetic retinopathy, Computer-aided diagnosis, Digital imaging, Image processing"
"Grissa D,Comte B,Pétéra M,Pujos-Guillot E,Napoli A",A hybrid and exploratory approach to knowledge discovery in metabolomic data,2020,"In this paper, we propose a hybrid and exploratory knowledge discovery approach for analyzing metabolomic complex data based on a combination of supervised classifiers, pattern mining and Formal Concept Analysis (FCA). The approach is based on three main operations, preprocessing, classification, and postprocessing. Classifiers are applied to datasets of the form individuals × features and produce sets of ranked features which are further analyzed. Pattern mining and FCA are used to provide a complementary analysis and support for visualization. A practical application of this framework is presented in the context of metabolomic data, where two interrelated problems are considered, discrimination and prediction of class membership. The dataset is characterized by a small set of individuals and a large set of features, in which predictive biomarkers of clinical outcomes should be identified. The problems of combining numerical and symbolic data mining methods, as well as discrimination and prediction, are detailed and discussed. Moreover, it appears that visualization based on FCA can be used both for guiding knowledge discovery and for interpretation by domain analysts.","Hybrid knowledge discovery, Pattern mining, Formal concept analysis, Data and pattern exploration, Metabolomic data, Classification, Visualization, Interpretation"
"Saha SK,Xiao D,Bhuiyan A,Wong TY,Kanagasingam Y",Color fundus image registration techniques and applications for automated analysis of diabetic retinopathy progression: A review,2019,"Diabetic retinopathy (DR) is one of the leading cause of visual impairments in the working age population in the developed world. It is a complication of both types of diabetes mellitus, which affects the light perception part of the retina; and without timely treatment patients could lose their sight and eventually become blind. Automated methods for the detection and progression analysis of DR are considered as potential health-care need to stop disease propagation and to ensure improved management for DR. Aiming for the detection and progression analysis of DR, color fundus photography is considered as one of the best candidates for non-invasive imaging of the eye fundus. A list of methods has already been developed to analyse DR related changes in the retina using color fundus photographs. In this manuscript we review those automated methods. In order to accurately compare the evolution of DR over time, retinal images that are typically collected on an annual or biennial basis must be perfectly superimposed. However, in reality, for two separate photographic-eye examinations the patient is never in exactly the same position and also the camera may vary. Therefore, a registration method is applied prior to evolution computation. Knowing registration as a fundamental preprocessing step for longitudinal (over time) analysis, we also reviewed state-of-the art methods for the registration of color fundus images. The review summarizes the achievement so far and also identifies potential study areas for further improvement and future research toward more efficient and accurate DR progression analysis.","Diabetic retinopathy, Registration, Longitudinal registration, Retinopathy progression, Color fundus image"
"Zhong H,Loukides G,Gwadera R",Clustering datasets with demographics and diagnosis codes,2020,"Clustering data derived from Electronic Health Record (EHR) systems is important to discover relationships between the clinical profiles of patients and as a preprocessing step for analysis tasks, such as classification. However, the heterogeneity of these data makes the application of existing clustering methods difficult and calls for new clustering approaches. In this paper, we propose the first approach for clustering a dataset in which each record contains a patient’s values in demographic attributes and their set of diagnosis codes. Our approach represents the dataset in a binary form in which the features are selected demographic values, as well as combinations (patterns) of frequent and correlated diagnosis codes. This representation enables measuring similarity between records using cosine similarity, an effective measure for binary-represented data, and finding compact, well-separated clusters through hierarchical clustering. Our experiments using two publicly available EHR datasets, comprised of over 26,000 and 52,000 records, demonstrate that our approach is able to construct clusters with correlated demographics and diagnosis codes, and that it is efficient and scalable.","Clustering, Demographics, Diagnosis codes, Pattern mining"
"Jebaseeli TJ,Durai CA,Peter JD",Segmentation of retinal blood vessels from ophthalmologic Diabetic Retinopathy images,2019,"The most prominent ophthalmic cause of blindness is Diabetic Retinopathy (DR). This retinal disease is characterized by variation in diameter of the retinal blood vessel and the new blood vessel growth inside the retina. A system to enhance the quality of the segmentation result over the pathological retinal images has been proposed. The proposed method uses Contrast Limited Adaptive Histogram Equalization (CLAHE) for preprocessing and Tandem Pulse Coupled Neural Network (TPCNN) model for automatic feature vectors generation then classification and extraction of the retinal blood vessels via Deep Learning Based Support Vector Machine (DLBSVM). The proposed approach is assessed over the standard public fundus image databases to evaluate the performance. The results render that these techniques improve the segmentation results with an average value of 74.45% sensitivity, 99.40% specificity, and 99.16% accuracy. The results evoke that the proposed method is a suitable alternative for supervised techniques.","Diabetic Retinopathy, Fundus image, Retina, Image segmentation, Feature extraction, Deep learning, SVM, Blood vessel, Ophthalmology, Neural network"
"Datta NS,Banerjee R,Dutta HS,Mukhopadhyay S",Hardware Based Analysis on Automated Early Detection of Diabetic-Retinopathy,2012,"This paper discusses primarily the hardware based issues on early detection of diabetic retinopathy. Software based algorithms for preprocessing, segmentation, and, classification stages are initially analyzed. Later those techniques were customized and implemented using TMS320C6713 based DSP Kits of Texas instruments with code composer studio for the early detection of diabetic retinopathy through the fundus images of retina. The hardware based implementation shows more effective results as compared to other existing approaches.","Diabetic Retinopathy, Fundus image, Adaptive histogram equalization, Color-space conversion"
Bollegala D,Dynamic feature scaling for online learning of binary classifiers,2017,"Scaling feature values is an important step in numerous machine learning tasks. Different features can have different value ranges and some form of a feature scaling is often required in order to learn an accurate classifier. However, feature scaling is conducted as a preprocessing task prior to learning. This is problematic in an online setting because of two reasons. First, it might not be possible to accurately determine the value range of a feature at the initial stages of learning when we have observed only a handful of training instances. Second, the distribution of data can change over time, which render obsolete any feature scaling that we perform in a pre-processing step. We propose a simple but an effective method to dynamically scale features at train time, thereby quickly adapting to any changes in the data stream. We compare the proposed dynamic feature scaling method against more complex methods for estimating scaling parameters using several benchmark datasets for classification. Our proposed feature scaling method consistently outperforms more complex methods on all of the benchmark datasets and improves classification accuracy of a state-of-the-art online classification algorithm.","Feature scaling, Online learning, Classification"
"Guo Y,Budak Ü,?engür A",A novel retinal vessel detection approach based on multiple deep convolution neural networks,2018,"Background and objective Computer aided detection (CAD) offers an efficient way to assist doctors to interpret fundus images. In a CAD system, retinal vessel (RV) detection is a crucial step to identify the retinal disease regions. However, RV detection is still a challenging problem due to variations in morphology of the vessels on noisy and low contrast fundus images. Methods In this paper, we formulate the detection task as a classification problem and solve it using a multiple classifier framework based on deep convolutional neural networks. The multiple deep convolutional neural network (MDCNN) is constructed and trained on fundus images with limited image quantity. The MDCNN is trained using an incremental learning strategy to improve the networks’ performance. The final classification results are obtained from the voting procedure on the results of MDCNN. Results The MDCNN achieves better performance and significantly outperforms the state-of-the-art for automatic retinal vessel segmentation on the DRIVE dataset with 95.97% and 96.13% accuracy and 0.9726 and 0.9737 AUC (area below the operator receiver character curve) score on training and testing sets, respectively. Another public dataset, STARE, is also used to evaluate the proposed network. The experimental results demonstrate that the proposed MDCNN network achieves 95.39% accuracy and 0.9539 AUC score in STARE dataset. We further compare our result with several state-of-the-art methods based on AUC values. The comparison is shown that our proposal yields the third best AUC value. Conclusions Our method yields the better performance in the compared the state of the art methods. In addition, our proposal has no preprocessing stage, and the input color fundus images are fed into the CNN directly.","Retinal vessels segmentation, Multiple deep convolution neural network, Image segmentation"
"Mo J,Zhang L,Feng Y",Exudate-based diabetic macular edema recognition in retinal images using cascaded deep residual networks,2018,"Diabetic macular edema (DME), one of the leading causes of visual impairment and blindness, is usually diagnosed by the presence of exudates. However, exudate detection is challenging due to the large intraclass variation and high interclass similarity. To overcome these challenges, we propose the cascaded deep residual networks to recognize DME. Specifically, we first design a fully convolutional residual network that fuses multi-level hierarchical information to segment exudates accurately with a fast speed. Compared with previous methods, our approach avoids a wide range of preprocessing or postprocessing steps, reducing the impact of subjective factors. Then based on the segmentation results, the region centered on the pixel with the maximum probability is cropped and fed into the other deep residual network (for classification) to distinguish DME from its hard mimics. This makes the classification network to extract more representative features based on the segmentation results instead of the original images, further reducing the influence of complicated background. We evaluate the proposed method on two publicly available databases, the HEI-MED and e-ophtha EX databases. Extensive experiments demonstrate that our approach achieves better performance than the state-of-the-art methods with a fast processing speed, making it suitable for real-world clinical applications.","Diabetic macular edema recognition, Fully convolutional network, Residual learning, Retinal image, Exudate segmentation"
"Zhou X,Chen S,Liu B,Zhang R,Wang Y,Li P,Guo Y,Zhang H,Gao Z,Yan X",Development of traditional Chinese medicine clinical data warehouse for medical knowledge discovery and decision support,2010,"Objective Traditional Chinese medicine (TCM) is a scientific discipline, which develops the related theories from the long-term clinical practices. The large-scale clinical data are the core empirical knowledge source for TCM research. This paper introduces a clinical data warehouse (CDW) system, which incorporates the structured electronic medical record (SEMR) data for medical knowledge discovery and TCM clinical decision support (CDS). Materials and methods We have developed the clinical reference information model (RIM) and physical data model to manage the various information entities and their relationships in TCM clinical data. An extraction-transformation-loading (ETL) tool is implemented to integrate and normalize the clinical data from different operational data sources. The CDW includes online analytical processing (OLAP) and complex network analysis (CNA) components to explore the various clinical relationships. Furthermore, the data mining and CNA methods are used to discover the valuable clinical knowledge from the data. Results The CDW has integrated 20,000 TCM inpatient data and 20,000 outpatient data, which contains manifestations (e.g. symptoms, physical examinations and laboratory test results), diagnoses and prescriptions as the main information components. We propose a practical solution to accomplish the large-scale clinical data integration and preprocessing tasks. Meanwhile, we have developed over 400 OLAP reports to enable the multidimensional analysis of clinical data and the case-based CDS. We have successfully conducted several interesting data mining applications. Particularly, we use various classification methods, namely support vector machine, decision tree and Bayesian network, to discover the knowledge of syndrome differentiation. Furthermore, we have applied association rule and CNA to extract the useful acupuncture point and herb combination patterns from the clinical prescriptions. Conclusion A CDW system consisting of TCM clinical RIM, ETL, OLAP and data mining as the core components has been developed to facilitate the tasks of TCM knowledge discovery and CDS. We have conducted several OLAP and data mining tasks to explore the empirical knowledge from the TCM clinical data. The CDW platform would be a promising infrastructure to make full use of the TCM clinical data for scientific hypothesis generation, and promote the development of TCM from individualized empirical knowledge to large-scale evidence-based medicine.","Clinical data warehouse, Traditional Chinese medicine, Clinical data mining, Clinical decision support"
"Abdar M,Ksi??ek W,Acharya UR,Tan RS,Makarenkov V,P?awiak P",A new machine learning technique for an accurate diagnosis of coronary artery disease,2019,"Background and objective Coronary artery disease (CAD) is one of the commonest diseases around the world. An early and accurate diagnosis of CAD allows a timely administration of appropriate treatment and helps to reduce the mortality. Herein, we describe an innovative machine learning methodology that enables an accurate detection of CAD and apply it to data collected from Iranian patients. Methods We first tested ten traditional machine learning algorithms, and then the three-best performing algorithms (three types of SVM) were used in the rest of the study. To improve the performance of these algorithms, a data preprocessing with normalization was carried out. Moreover, a genetic algorithm and particle swarm optimization, coupled with stratified 10-fold cross-validation, were used twice: for optimization of classifier parameters and for parallel selection of features. Results The presented approach enhanced the performance of all traditional machine learning algorithms used in this study. We also introduced a new optimization technique called N2Genetic optimizer (a new genetic training). Our experiments demonstrated that N2Genetic-nuSVM provided the accuracy of 93.08% and F1-score of 91.51% when predicting CAD outcomes among the patients included in a well-known Z-Alizadeh Sani dataset. These results are competitive and comparable to the best results in the field. Conclusions We showed that machine-learning techniques optimized by the proposed approach, can lead to highly accurate models intended for both clinical and research use.","Coronary artery disease (CAD), Machine learning, Normalization, Genetic algorithm, Particle swarm optimization, Feature selection, Classification"
"Tavakoli M,Shahri RP,Pourreza H,Mehdizadeh A,Banaee T,Bahreini Toosi MH",A complementary method for automated detection of microaneurysms in fluorescein angiography fundus images to assess diabetic retinopathy,2013,"Early detection of microaneurysms (MAs), the first sign of Diabetic Retinopathy (DR), is an essential first step in automated detection of DR to prevent vision loss and blindness. This study presents a novel and different algorithm for automatic detection of MAs in fluorescein angiography (FA) fundus images, based on Radon transform (RT) and multi-overlapping windows. This project addresses a novel method, in detection of retinal land marks and lesions to diagnose the DR. At the first step, optic nerve head (ONH) was detected and masked. In preprocessing stage, top-hat transformation and averaging filter were applied to remove the background. In main processing section, firstly, we divided the whole preprocessed image into sub-images and then segmented and masked the vascular tree by applying RT in each sub-image. After detecting and masking retinal vessels and ONH, MAs were detected and numbered by using RT and appropriated thresholding. The results of the proposed method were evaluated on three different retinal images databases, the Mashhad Database with 120 FA fundus images, Second Local Database from Tehran with 50 FA retinal images and a part of Retinopathy Online Challenge (ROC) database with 22 images. Automated DR detection demonstrated a sensitivity and specificity of 94% and 75% for Mashhad database and 100% and 70% for the Second Local Database respectively.","Computer aided diagnosis, Diabetic retinopathy, Fluorescein angiography, Fundus images, Radon transform, Microaneurysms"
"Bowen RM,Sahin F,Radomski A",Systemic health evaluation of RF generators using Gaussian mixture models,2016,We propose an application of specific machine learning techniques capable of evaluating systemic health of a Radio Frequency (RF) power generator. System signatures or fingerprints are collected from multivariate time-series data samples of sensor values under typical operational loads. These fingerprints are transformed into feature vectors using standard scaling/translation methods and the Fast Fourier Transform (FFT). The number of features per fingerprint are reduced by banding neighboring features and Principal Component Analysis (PCA). The reduced feature vectors are used with the Expectation Maximization (EM) algorithm to learn parameters for a Gaussian Mixture Model (GMM) to represent normal operation. One-class classification of normal fingerprints is achieved by thresholding the likelihood of a fingerprint feature vectors. Fingerprints were collected from normal operational conditions and seeded non-normal conditions. Preprocessing methods and algorithmic parameters have been selected using an iterative grid search. Average robust true positive rate achieved was 94.76% and best specificity reported is 86.56%.,"Health monitoring, Mixture models, Gaussian mixtures, One-class classification, RF power generators"
"Qiao Y,Li Z,Wang Q,Zeng Y,Liang K",Identification of palm print using dermatoglyphics analysis and detection system,2005,"This paper investigated the biological characteristics of palm print. The preprocessing plays an important role in identifying the ridge characteristics of palm due to the complexity and poor quality of the images. As a functional plug-in of the dermatoglyphics analysis and detection system, the template-based image preprocessing was proposed in this study, including histogram redistribution, ridge orientation, and skeletonization. Using this system, the automatic identification of ridges and triradiuses was accomplished with an effective result. The study demonstrated the feasibility of the method and the potential of the system for being applied as an auxiliary diagnostic tool for heredity diseases (e.g. mammary cancer and neurofibromatosis).","Dermatoglyphics, Palm print, Automatic identification, Image processing"
"Ghadiri N,Ghaffari M,Nikbakht MA","BigFCM: Fast, precise and scalable FCM on hadoop",2017,"Clustering plays an important role in mining big data both as a modeling technique and a preprocessing step in many data mining process implementations. Fuzzy clustering provides more flexibility than non-fuzzy methods by allowing each data record to belong to more than one cluster to some degree. However, a serious challenge in fuzzy clustering is the lack of scalability. Massive datasets in emerging fields such as geosciences, biology, and networking do require parallel and distributed computations with high performance to solve real-world problems. Although some clustering methods are already improved to execute on big data platforms, their execution time is highly increased for gigantic datasets. In this paper, a scalable Fuzzy C-Means (FCM) clustering method named BigFCM is proposed and designed for the Hadoop distributed data platform. Based on the MapReduce programming model, the proposed algorithm exploits several mechanisms including an efficient caching design to achieve several orders of magnitude reduction in execution time. The BigFCM performance compared with Apache Mahout K-Means and Fuzzy K-Means through an evaluation framework developed in this research. Extensive evaluation using over multi-gigabyte datasets including SUSY and HIGGS shows that BigFCM is scalable while it preserves the quality of clustering.","MapReduce algorithms, Unsupervised learning and clustering, Data mining, Clustering, Vagueness and fuzzy logic, Big data"
"Ksi??ek W,Abdar M,Acharya UR,P?awiak P",A novel machine learning approach for early detection of hepatocellular carcinoma patients,2019,"Liver cancer is quite common type of cancer among individuals worldwide. Hepatocellular carcinoma (HCC) is the malignancy of liver cancer. It has high impact on individual’s life and investigating it early can decline the number of annual deaths. This study proposes a new machine learning approach to detect HCC using 165 patients. Ten well-known machine learning algorithms are employed. In the preprocessing step, the normalization approach is used. The genetic algorithm coupled with stratified 5-fold cross-validation method is applied twice, first for parameter optimization and then for feature selection. In this work, support vector machine (SVM) (type C-SVC) with new 2level genetic optimizer (genetic training) and feature selection yielded the highest accuracy and F1-Score of 0.8849 and 0.8762 respectively. Our proposed model can be used to test the performance with huge database and aid the clinicians.","Machine learning, Data mining, Hepatocellular carcinoma (HCC), Genetic algorithm, Normalization, Feature selection"
"Sacchi L,Capozzi D,Bellazzi R,Larizza C",JTSA: An open source framework for time series abstractions,2015,"Background and objective The evaluation of the clinical status of a patient is frequently based on the temporal evolution of some parameters, making the detection of temporal patterns a priority in data analysis. Temporal abstraction (TA) is a methodology widely used in medical reasoning for summarizing and abstracting longitudinal data. Methods This paper describes JTSA (Java Time Series Abstractor), a framework including a library of algorithms for time series preprocessing and abstraction and an engine to execute a workflow for temporal data processing. The JTSA framework is grounded on a comprehensive ontology that models temporal data processing both from the data storage and the abstraction computation perspective. The JTSA framework is designed to allow users to build their own analysis workflows by combining different algorithms. Thanks to the modular structure of a workflow, simple to highly complex patterns can be detected. The JTSA framework has been developed in Java 1.7 and is distributed under GPL as a jar file. Results JTSA provides: a collection of algorithms to perform temporal abstraction and preprocessing of time series, a framework for defining and executing data analysis workflows based on these algorithms, and a GUI for workflow prototyping and testing. The whole JTSA project relies on a formal model of the data types and of the algorithms included in the library. This model is the basis for the design and implementation of the software application. Taking into account this formalized structure, the user can easily extend the JTSA framework by adding new algorithms. Results are shown in the context of the EU project MOSAIC to extract relevant patterns from data coming related to the long term monitoring of diabetic patients. Conclusions The proof that JTSA is a versatile tool to be adapted to different needs is given by its possible uses, both as a standalone tool for data summarization and as a module to be embedded into other architectures to select specific phenotypes based on TAs in a large dataset.","Temporal abstractions, Time series analysis, Data analysis workflow, Temporal pattern discovery, Biomedical data mining software tool"
"Khalifa A,Meystre S",Adapting existing natural language processing resources for cardiovascular risk factors identification in clinical notes,2015,"The 2014 i2b2 natural language processing shared task focused on identifying cardiovascular risk factors such as high blood pressure, high cholesterol levels, obesity and smoking status among other factors found in health records of diabetic patients. In addition, the task involved detecting medications, and time information associated with the extracted data. This paper presents the development and evaluation of a natural language processing (NLP) application conceived for this i2b2 shared task. For increased efficiency, the application main components were adapted from two existing NLP tools implemented in the Apache UIMA framework: Textractor (for dictionary-based lookup) and cTAKES (for preprocessing and smoking status detection). The application achieved a final (micro-averaged) F1-measure of 87.5% on the final evaluation test set. Our attempt was mostly based on existing tools adapted with minimal changes and allowed for satisfying performance with limited development efforts.","Natural language processing, Information extraction, Clinical narrative, Risk factors, Cardiovascular disease, Text mining, Medical records, Machine learning"
"Romero-Oraá R,García M,Oraá-Pérez J,López MI,Hornero R",A robust method for the automatic location of the optic disc and the fovea in fundus images,2020,"Background and objective The location of the optic disc (OD) and the fovea is usually crucial in automatic screening systems for diabetic retinopathy. Previous methods aimed at their location often fail when these structures do not have the standard appearance. The purpose of this work is to propose novel, robust methods for the automatic detection of the OD and the fovea. Methods The proposed method comprises a preprocessing stage, a method for retinal background extraction, a vasculature segmentation phase and the computation of various novel saliency maps. The main novelty of this work is the combination of the proposed saliency maps, which represent the spatial relationships between some structures of the retina and the visual appearance of the OD and fovea. Another contribution is the method to extract the retinal background, based on region-growing. Results The proposed methods were evaluated over a proprietary database and three public databases: DRIVE, DiaretDB1 and Messidor. For the OD, we achieved 100% accuracy for all databases except Messidor (99.50%). As for the fovea location, we also reached 100% accuracy for all databases except Messidor (99.67%). Conclusions Our results suggest that the proposed methods are robust and effective to automatically detect the OD and the fovea. This way, they can be useful in automatic screening systems for diabetic retinopathy as well as other retinal diseases.","Diabetic retinopathy, Fundus image, Computer-assisted diagnostic systems, Optic disc, Fovea"
"Ramesh T,Santhi V",Exploring big data analytics in health care,2020,"Health care Industries are facing lot of challenges in maintaining patient information across various databases due to storage issues. In order to extract patient information, preprocessing techniques can be applied in the process of data mining across databases. But as the data is growing enormously with rapid speed, data mining techniques are becoming obsolete due to issues such as Storage, Speed. So, cost optimization has become one of the major requirements in health industry as there is huge burden in maintaining large volumes of patient’s information using traditional databases. Here Big Data plays a vital role in storing huge volumes of patient information using storage mechanisms such as HDFS, HBase. Many issues in health care are discussed in this paper such as prediction of diseases, getting patients information across databases as a single view.","Data mining, Cost optimization, Big data, Patient management, Knowledge management"
"Sun D,Cao F,Wang H,Guan S,Su A,Xu W,Xu S",SERS hydrogel pellets for highly repeatable and reliable detections of significant small biomolecules in complex samples without pretreatment,2021,"The detections of significant small molecules in biological fluids is always challenging due to the complicated sample pretreatment. Here, a universal SERS-hydrogel micropellet was developed for pretreatment-free, reliable detections of small molecules (glucose and melamine) in complex sample (whole blood and milk). The SERS-hydrogel micropellet has an adjustable pore size, which is acquired by the ultraviolet light solidification of the water-in-oil microdroplets in which the hydrogel monomers and the SERS-active metal nanoparticles (MNPs) were encapsulated. These micropellets have a pore size selectivity to allow small molecules to access in and exclude larger molecules, which is helpful for the highly selective, label-free/labeling SERS determinations of small molecules. This SERS substrate ensures high reproducibility of SERS detections since MNPs are uniformly dispersed in each micropellet. The hydrogel matrix can well protect MNPs from the surrounding environments to guarantee long-term stability. The lowest detectable concentration is 10 ?M for glucose in whole blood and 10 nM for melamine in milk, and the linear ranges are 0.1-20 mM and 10-8-10-3 M, respectively. This method avoids the complicated preprocessing steps, requires a small volume of samples, has a fast response time and low-cost, which provides the possibility for multiplex SERS detections in liquid biopsy.","Surface-enhanced Raman scattering, hydrogel micropellets, pretreatment-free, blood glucose, melamine"
"Nayak KR,Skupin A,Schempp T,Garberich R,Bhavnani SP,Henry T",Machine learning for holistic visualization of STEMI registry data,2021,"Background Widespread adoption of evidence-based guidelines and treatment pathways in ST-Elevation Myocardial Infarction (STEMI) patients has considerably improved cardiac survival and decreased the risk of recurrent myocardial infarction. However, survival outcomes appear to have plateaued over the last decade. The hope underpinning the current study is to engage data visualization to develop a more holistic understanding of the patient space, supported by principles and techniques borrowed from traditionally disparate disciplines, like cartography and machine learning. Methods and Results The Minnesota Heart Institute Foundation (MHIF) STEMI database is a large prospective regional STEMI registry consisting of 180 variables of heterogeneous data types on more than 5000 patients spanning 15 years. Initial assessment and preprocessing of the registry database was undertaken, followed by a first proof-of-concept implementation of an analytical workflow that involved machine learning, dimensionality reduction, and data visualization. 38 pre-admission variables were analyzed in an all-encompassing representation of pre-index STEMI event data. We aim to generate a holistic visual representation — a map of the multivariate patient space — by training a high-resolution self-organizing neural network consisting of several thousand neurons. The resulting 2-D lattice arrangement of n-dimensional neuron vectors allowed patients to be represented as point locations in a 2-D display space. Patient attributes were then visually examined and contextualized in the same display space, from demographics to pre-existing conditions, event-specific procedures, and STEMI outcomes. Data visualizations implemented in this study include a small-multiple display of neural component planes, composite visualization of the multivariate patient space, and overlay visualization of non-training attributes. Conclusion Our study represents the first known marriage of cartography and machine learning techniques to obtain visualizations of the multivariate space of a regional STEMI registry. Combining cartographic mapping techniques and artificial neural networks permitted the transformation of the STEMI database into novel, two-dimensional visualizations of patient characteristics and outcomes. Notably, these visualizations also drive the discovery of anomalies in the data set, informing corrections applied to detected outliers, thereby further refining the registry for integrity and accuracy. Building on these advances, future efforts will focus on supporting further understanding of risk factors and predictors of outcomes in STEMI patients. More broadly, the thorough visual exploration of display spaces generated through a conjunction of dimensionality reduction with the mature technology base of geographic information systems appears a promising direction for biomedical research.","Machine learning, Data visualization, STEMI outcomes, Artificial neural network, Self-organizing maps"
"Ming LK,Kiong LC,Soong LW",Autonomous and deterministic supervised fuzzy clustering with data imputation capabilities,2011,"A fuzzy model based on enhanced supervised fuzzy clustering algorithm is presented in this paper. Supervised fuzzy clustering algorithm by Janos Abonyi and Ferenc Szeifert in the year 2003 allows each rule to represent more than one output with different probabilities for each output. This algorithm implements k-means to initialize the fuzzy model. The main drawbacks of this approach are the number of clusters is unknown and the initial positions of clusters are randomly generated. In this work, the initialization is performed by global k-means algorithm [1] which can autonomously determine the actual number of clusters needed and give deterministic clustering result. In addition, fast global k-means [1] is presented to improve the computation time. Besides that, when collecting input data in a feature vector way, it might occur that some of the feature values are lost for a particular vector due to a faulty reading sensor. To deal with missing values in enhanced supervised fuzzy clustering, the efficient way is imputation during data preprocessing. The modified of optimal completion strategy is presented to solve this problem. This method allows imputation of missing data with high reliability and accuracy. The autonomous and deterministic enhanced supervised fuzzy clustering using supervised Gath–Geva clustering method and the modified of optimal completion strategy can be derived from the unsupervised Gath–Geva algorithm. The proposed algorithm is successfully justified based on benchmark data sets and a real vibration data which was collected from U.S. Navy CH-46E helicopter aft gearbox called Westland.","Supervised fuzzy clustering, Global -means, Optimal completion strategy, Fault diagnosis, Data imputation"
"Kiziloz HE,Deniz A",An evolutionary parallel multiobjective feature selection framework,2021,"Feature selection has become an indispensable preprocessing step in data mining problems as high amount of data become prevalent with the advances in technology. The objective of feature selection is twofold: reducing data amount and improving learning performance. In this study, we leverage the multi-core nature of a regular PC to build a robust framework for feature selection. This framework executes the feature selection algorithm on four processors, in parallel. As per the No Free Lunch Theorem, we facilitate 40 different execution settings for the processors by employing two multiobjective selection algorithms, four initial population generation methods, and five machine learning techniques. Besides, we introduce six setting selection schemes to decide the most fruitful setting for each processor. We carry out extensive experiments on 11 UCI benchmark datasets and analyze the results with statistical tests. Finally, we compare our proposed method with state-of-the-art studies and record remarkable improvement in terms of maximum accuracy.","Feature selection, Multiobjective optimization, Parallel processing, Evolutionary computation"
"Zhang X,Thibault G,Decencière E,Marcotegui B,Laÿ B,Danno R,Cazuguel G,Quellec G,Lamard M,Massin P,Chabouis A,Victor Z,Erginay A",Exudate detection in color retinal images for mass screening of diabetic retinopathy,2014,"The automatic detection of exudates in color eye fundus images is an important task in applications such as diabetic retinopathy screening. The presented work has been undertaken in the framework of the TeleOphta project, whose main objective is to automatically detect normal exams in a tele-ophthalmology network, thus reducing the burden on the readers. A new clinical database, e-ophtha EX, containing precisely manually contoured exudates, is introduced. As opposed to previously available databases, e-ophtha EX is very heterogeneous. It contains images gathered within the OPHDIAT telemedicine network for diabetic retinopathy screening. Image definition, quality, as well as patients condition or the retinograph used for the acquisition, for example, are subject to important changes between different examinations. The proposed exudate detection method has been designed for this complex situation. We propose new preprocessing methods, which perform not only normalization and denoising tasks, but also detect reflections and artifacts in the image. A new candidates segmentation method, based on mathematical morphology, is proposed. These candidates are characterized using classical features, but also novel contextual features. Finally, a random forest algorithm is used to detect the exudates among the candidates. The method has been validated on the e-ophtha EX database, obtaining an AUC of 0.95. It has been also validated on other databases, obtaining an AUC between 0.93 and 0.95, outperforming state-of-the-art methods.","Diabetic retinopathy screening, Exudates segmentation, Mathematical morphology, e-Ophtha EX database"
"Wu S,Liu S,Sohn S,Moon S,Wi CI,Juhn Y,Liu H",Modeling asynchronous event sequences with RNNs,2018,"Sequences of events have often been modeled with computational techniques, but typical preprocessing steps and problem settings do not explicitly address the ramifications of timestamped events. Clinical data, such as is found in electronic health records (EHRs), typically comes with timestamp information. In this work, we define event sequences and their properties: synchronicity, evenness, and co-cardinality; we then show how asynchronous, uneven, and multi-cardinal problem settings can support explicit accountings of relative time. Our evaluation uses the temporally sensitive clinical use case of pediatric asthma, which is a chronic disease with symptoms (and lack thereof) evolving over time. We show several approaches to explicitly incorporating relative time into a recurrent neural network (RNN) model that improve the overall classification of patients into those with no asthma, those with persistent asthma, those in long-term remission, and those who have experienced relapse. We also compare and contrast these results with those in an inpatient intensive care setting.","Temporal data, Deep learning, Electronic health records, Asthma"
"Cho I,Lee M,Kim Y",What are the main patient safety concerns of healthcare stakeholders: a mixed-method study of Web-based text,2020,"Objectives Various healthcare stakeholders define quality of care in different ways. Public policy could advocate all these concerns. This study was conducted to identify the main themes on patient safety of stakeholders expressed before and after the Patient Safety Act was enacted in Korea in 2015. Design Longitudinal observational study of the interests of healthcare stakeholders generated between January 2014 and September 2018. Materials and methods Text data were collected from 2,487 documents on 18 websites that were identified as representative healthcare stakeholder groups of consumers, providers, government, and researchers. A Korean natural language processing (NLP) package, manual review, and synonym dictionary were used for data preprocessing, and we adopted the unsupervised NLP method of probabilistic topic modeling and latent Dirichlet allocation. A linear trend analysis over time, a qualitative step involving two external experts, and original text reviews were performed to validate the identified topics. Results Forty-one topics were identified, and the most common concerns of stakeholders were institutional infection control as triggered by the Middle East respiratory syndrome outbreak in early 2015, and infusion-related infection from late 2017 until the middle of 2018. The other top-three concerns of the stakeholder groups were highly similar, while research topics were limited to the perceptions of providers and the activities and culture of hospitals. Five topics showed statistically significant increasing trends over time, while another five showed decreasing trends (both P < 0.05). In the qualitative step, we confirmed 35 themes and revised the other 6. Conclusions A common concern among stakeholders was hospital infection control, ranging from nosocomial infections to those brought in by family visiting patients. Government policies and systemic approaches to patient safety were highlighted by different stakeholders. Researchers were focused on hospital sociocultural factors at both the organizational and clinician levels. These identified concerns all should be advocated by the public health policy.","Patient safety, Web-based text, Healthcare stakeholders, Natural language processing, Topic modeling"
"Yim J,Kim H,Ryu S,Song S,Kim HO,Hyun KA,Jung HI,Joo C",Photothermal spectral-domain optical coherence reflectometry for direct measurement of hemoglobin concentration of erythrocytes,2014,"A novel optical detection method for hemoglobin concentration is described. The hemoglobin molecules consisting mainly of iron generate heat upon their absorption of light energy at 532nm, which subsequently changes the refractive index of the blood. We exploit this photothermal effect to determine the hemoglobin concentration of erythrocytes without any preprocessing of blood. Highly sensitive measurement of refractive index alteration of blood samples is enabled by a spectral-domain low coherence reflectometric sensor with subnanometer-level optical path-length sensitivity. The performance and validity of the sensor are presented by comparing the measured results against the reference data acquired from an automatic hematology analyzer.","Photothermal effect, Hemoglobin concentration, Erythrocytes, Low coherence interferometry, Refractive index"
"Matsopoulos GK,Asvestas PA,Delibasis KK,Mouravliansky NA,Zeyen TG",Detection of glaucomatous change based on vessel shape analysis,2008,"Glaucoma, a leading cause of blindness worldwide, is a progressive optic neuropathy with characteristic structural changes in the optic nerve head and concomitant visual field defects. Ocular hypertension (i.e. elevated intraocular pressure without glaucoma) is the most important risk factor to develop glaucoma. Even though a number of variables, including various optic disc and visual field parameters, have been used in order to identify early glaucomatous damage, there is a need for computer-based methods that can detect early glaucomatous progression so that treatment to prevent further progression can be initiated. This paper is focused on the description of a system based on image processing and classification techniques for the estimation of quantitative parameters to define vessel deformation and the classification of image data into two classes: patients with ocular hypertension who develop glaucomatous damage and patients with ocular hypertension who remain stable. The proposed system consists of the retinal image preprocessing module for vessel central axis segmentation, the automatic retinal image registration module based on a novel application of self organizing maps (SOMs) to define automatic point correspondence, the retinal vessel attributes calculation module to select the vessel shape attributes and the data classification module, using an artificial neural network classifier, to perform the necessary subject classification. Implementation of the system to optic disc data from 127 subjects obtained by a fundus camera at regular intervals provided a classification rate of 87.5%, underscoring the value of the proposed system to assist in the detection of early glaucomatous change.","Glaucoma, Registration, Self organizing maps, Wavelet coefficients, Classification, -Nearest Neighbor classifier, Sequential float forward search, Artificial neural networks"
"Aranguren I,Valdivia A,Morales-Castañeda B,Oliva D,Abd Elaziz M,Perez-Cisneros M",Improving the segmentation of magnetic resonance brain images using the LSHADE optimization algorithm,2021,"Segmentation is an essential preprocessing step in techniques for image analysis. The automatic segmentation of brain magnetic resonance imaging has been exhaustively investigated since the accurate use of this kind of methods permits the diagnosis and identification of several diseases. Thresholding is a straightforward and efficient technique for image segmentation. Nonetheless, thresholding based approaches tend to increase the computational cost based on the number of thresholds used for the segmentation. Therefore, metaheuristic algorithms are an important tool that helps to find the optimal values in multilevel thresholding. The adaptive differential evolution, based in numerous successes through history, with linear population size reduction (LSHADE) is a robust metaheuristic algorithm that efficiently solves numerical optimization problems. The main advantage of LSHADE is its capability to adapt its internal parameters according to prior knowledge acquired along the evolutionary process. Meanwhile, the continuous reduction of the population improves the exploitation process. This article presents a multilevel thresholding approach based on the LSHADE method for the segmentation of magnetic resonance brain imaging. The proposed method has been tested using three groups of reference images— the first group consists of grayscale standard benchmark images, the second group consists of magnetic resonance T2-weighted brain images, and the third group is formed by images of unhealthy brains affected by tumors. In turn, the performance of the intended approach was compared with distinct metaheuristic algorithms and machine learning methods. The statistically verified results demonstrate that the suggested approach improves consistency and segmentation quality.","Magnetic resonance images, Metaheuristic algorithms, Minimum cross entropy, Multilevel thresholding"
"Zhang G,Zhang C,Zhang H",Improved K-means algorithm based on density Canopy,2018,"In order to improve the accuracy and stability of K-means algorithm and solve the problem of determining the most appropriate number K of clusters and best initial seeds, an improved K-means algorithm based on density Canopy is proposed. Firstly, the density of sample data sets, the average sample distance in clusters and the distance between clusters are calculated, choosing the density maximum sampling point as the first cluster center and removing the density cluster from the data sets. Defining the product of sample density, the reciprocal of the average distance between the samples in the cluster, and the distance between the clusters as weight product, the other initial seeds is determined by the maximum weight product in the remaining data sets until the data sets is empty. The density Canopy is used as the preprocessing procedure of K-means and its result is used as the cluster number and initial clustering center of K-means algorithm. Finally, the new algorithm is tested on some well-known data sets from UCI machine learning repository and on some simulated data sets with different proportions of noise samples. The simulation results show that the improved K-means algorithm based on density Canopy achieves better clustering results and is insensitive to noisy data compared to the traditional K-means algorithm, the Canopy-based K-means algorithm, Semi-supervised K-means++ algorithm and K-means-u* algorithm. The clustering accuracy of the proposed K-means algorithm based on density Canopy is improved by 30.7%, 6.1%, 5.3% and 3.7% on average on UCI data sets, and improved by 44.3%, 3.6%, 9.6% and 8.9% on the simulated data sets with noise signal respectively. With the increase of the noise ratio, the noise immunity of the new algorithm is more obvious, when the noise ratio reached 30%, the accuracy rate is improved 50% and 6% compared to the traditional K-means algorithm and the Canopy-based K-means algorithm.","Density Canopy, K-means algorithm, Weight product, Optimal value K, Initial seed"
"Amin MN,Rushdi MA,Marzaban RN,Yosry A,Kim K,Mahmoud AM",Wavelet-based computationally-efficient computer-aided characterization of liver steatosis using conventional B-mode ultrasound images,2019,"Hepatic steatosis occurs when lipids accumulate in the liver leading to steatohepatitis, which can evolve into cirrhosis and consequently may end with hepatocellular carcinoma. Several automatic classification algorithms have been proposed to detect liver diseases. However, some algorithms are manufacturer-dependent, while others require extensive calculations and consequently prolonged computational time. This may limit the development of real-time and manufacturer-independent computer-aided detection of liver steatosis. This work demonstrates the feasibility of a computationally-efficient and manufacturer-independent wavelet-based computer-aided liver steatosis detection system using conventional B-mode ultrasound (US) imaging. Seven features were extracted from the approximation part of the second-level wavelet packet transform (WPT) of US images. The proposed technique was tested on two datasets of ex-vivo mice livers with and without gelatin embedding, in addition to a third dataset of in-vivo human livers acquired using two different US machines. Using the gelatin-embedded mice liver dataset, the technique exhibited 98.8% accuracy, 97.8% sensitivity, and 100% specificity, and the frame classification time was reduced from0.4814s using original US images to 0.1444s after WPT preprocessing. When the other mice liver dataset was used, the technique showed 85.74% accuracy, 84.4% sensitivity, and 88.5% specificity, and the frame classification time was reduced from 0.5612s to 0.2903s. Using human liver image data, the best classifier exhibited 92.5% accuracy, 93.0% sensitivity, 91.0% specificity, and the classification time was reduced from 0.660s to 0.146s. This technique can be useful for developing computationally-efficient and manufacturer-independent noninvasive CAD systems for fatty liver detection.","Fatty liver disease, Steatosis, Ultrasound images, Wavelet packet transform, Computer-aided diagnosis (CAD)"
"Diniz PH,Valente TL,Diniz JO,Silva AC,Gattass M,Ventura N,Muniz BC,Gasparetto EL",Detection of white matter lesion regions in MRI using SLIC0 and convolutional neural network,2018,"Background and Objective: White matter lesions are non-static brain lesions that have a prevalence rate up to 98% in the elderly population. Because they may be associated with several brain diseases, it is important that they are detected as soon as possible. Magnetic Resonance Imaging (MRI) provides three-dimensional data with the possibility to detect and emphasize contrast differences in soft tissues, providing rich information about the human soft tissue anatomy. However, the amount of data provided for these images is far too much for manual analysis/interpretation, representing a difficult and time-consuming task for specialists. This work presents a computational methodology capable of detecting regions of white matter lesions of the brain in MRI of FLAIR modality. The techniques highlighted in this methodology are SLIC0 clustering for candidate segmentation and convolutional neural networks for candidate classification. Methods: The methodology proposed here consists of four steps: (1) images acquisition, (2) images preprocessing, (3) candidates segmentation and (4) candidates classification. Results: The methodology was applied on 91 magnetic resonance images provided by DASA, and achieved an accuracy of 98.73%, specificity of 98.77% and sensitivity of 78.79% with 0.005 of false positives, without any false positives reduction technique, in detection of white matter lesion regions. Conclusions: It is demonstrated the feasibility of the analysis of brain MRI using SLIC0 and convolutional neural network techniques to achieve success in detection of white matter lesions regions.","Computer-aided detection, Convolutional neural network, Deep learning, Medical images, SLIC0, White matter lesion"
"Andreini P,Bonechi S,Bianchini M,Garzelli A,Mecocci A",Automatic image classification for the urinoculture screening,2016,"Urinary tract infections (UTIs) are considered to be the most common bacterial infection and, actually, it is estimated that about 150 million UTIs occur world wide yearly, giving rise to roughly $6 billion in healthcare expenditures and resulting in 100,000 hospitalizations. Nevertheless, it is difficult to carefully assess the incidence of UTIs, since an accurate diagnosis depends both on the presence of symptoms and on a positive urinoculture, whereas in most outpatient settings this diagnosis is made without an ad hoc analysis protocol. On the other hand, in the traditional urinoculture test, a sample of midstream urine is put onto a Petri dish, where a growth medium favors the proliferation of germ colonies. Then, the infection severity is evaluated by a visual inspection of a human expert, an error prone and lengthy process. In this paper, we propose a fully automated system for the urinoculture screening that can provide quick and easily traceable results for UTIs. Based on advanced image processing and machine learning tools, the infection type recognition, together with the estimation of the bacterial load, can be automatically carried out, yielding accurate diagnoses. The proposed AID (Automatic Infection Detector) system provides support during the whole analysis process: first, digital color images of Petri dishes are automatically captured, then specific preprocessing and spatial clustering algorithms are applied to isolate the colonies from the culture ground and, finally, an accurate classification of the infections and their severity evaluation are performed. The AID system speeds up the analysis, contributes to the standardization of the process, allows result repeatability, and reduces the costs. Moreover, the continuous transition between sterile and external environments (typical of the standard analysis procedure) is completely avoided.","Color image processing, Clustering techniques, Artificial neural networks, Support vector machines, Urinoculture screening"
"Bania RK,Halder A",R-Ensembler: A greedy rough set based ensemble attribute selection algorithm with kNN imputation for classification of medical data,2020,"Background and Objective Retrieving meaningful information from high dimensional dataset is an important and challenging task. Normally, medical dataset suffers from several issues such as curse of dimensionality problem, uncertainty, presence of missing values, non-relevant and redundant attributes, etc. Any machine learning technique applied on such data (without any preprocessing) by and large takes a considerable amount of computational time and may degrade the performance of the model. Methods In this article, R-Ensembler, a parameter free greedy ensemble attribute selection method is proposed adopting the concept of rough set theory by using the attribute-class, attribute-significance and attribute-attribute relevance measures to select a subset of attributes which are most relevant, significant and non-redundant from a pool of different attribute subsets in order to predict the presence or absence of different diseases in medical dataset. The main role of the proposed ensembler is to combine multiple subsets of attributes produced by different rough set filters and to produce an optimal subset of attributes for subsequent classification task. A novel n number of set intersection method is also proposed to reduce the biasness during the time of attribute selection process. Before selecting the minimal attribute set from a given data by the proposed R-Ensembler method, the dataset is preprocessed by the k nearest neighbour (kNN) imputation method for missing value treatment. Results Experiments are carried out on seven benchmark medical datasets collected from University of California at Irvine (UCI) repository. The performance of the proposed ensemble method is compared with five state-of-the-art attribute selection algorithms, results of which are measured using three benchmark classifiers viz., Naïve Bayes, decision trees and random forest. Experimental results clearly justify the superiority of the proposed R-Ensembler method over other attribute selection algorithms. Results of paired t-test performed on average accuracies produced by different classifiers simulated on the reduced data sets achieved by the proposed and counter part attribute selection methods confirm the statistical significance of the better reduced attribute subsets achieved by the proposed R-Ensembler method compared to others. Conclusion The proposed ensemble method turned out to be very effective for selecting high relevant, high significant and less redundant attributes from a pool of different subsets of attributes.","Rough set, NN Imputation, Ensemble, Dependency, Classification"
"Guo Y,Budak Ü,Vespa LJ,Khorasani E,?engür A",A retinal vessel detection approach using convolution neural network with reinforcement sample learning strategy,2018,"Computer-aided detection (CAD) provides an efficient way to assist doctors to interpret fundus images. In a CAD system, retinal vessel (RV) detection is an important step to identify the retinal disease regions automatically and accurately. However, RV detection is still a challenging problem due to variations in morphology of the vessels on a noisy background. In this paper, we formulate the detection task as a classification problem and solve it using a convolutional neural network (CNN) as a two-class classifier. The proposed model has 2 convolution layers, 2 pooling layers, 1 dropout layer and 1 loss layer. The contributions of the algorithm are two-fold. First, a new model of CNN is designed to automatically extract features and classify the retinal vessel region. Compared to traditional classification procedures, it is fully automatic and does not need preprocessing and manual extraction and description of features. Second, a novel reinforcement sample learning scheme is proposed to train the CNN with fewer iterations of epochs and less training time. The proposed model is trained and tested using the Digital Retinal Images for Vessel Extraction (DRIVE) and Structured Analysis of the Retina (STARE) data sets. The proposed CNN achieves better performance and significantly outperforms the state-of-the-art for automatic retinal vessel segmentation on the DRIVE data set with 91.99% accuracy and 0.9652 AUC score (area under ROC), and on the STARE data set with 92.20% accuracy and 0.9440 AUC value. We further compare our result with several state-of-the-art methods based on AUC values. The comparison shows that our proposal yields the second best AUC value. This demonstrates the efficiency of the proposed method without pre-processing and with high accuracy and training speed.","Computer-aided detection, Retinal vessels, Convolution neural network, Image segmentation"
"Liu H,Liu L,Zhang H",A fast pruning redundant rule method using Galois connection,2011,"Besides preprocessing, post-analysis also plays an important role in knowledge discovery. It can effectively assist users to grasp the obtained knowledge. However, many of data mining algorithms merely take performance into consideration and put the post-analysis of results aside. They generate a modest number of rules for the purpose of improving accuracy. Unfortunately, most induced rules are redundant or insignificant. Their presence not only confuses end-users in post-analysis, but also degrades efficiency in future decision task. Thus, it is necessary to eliminate redundant or irrelevant rules as more as possible. In this paper, we present an efficient post-processing method to prune redundant rules by virtue of the property of Galois connection, which inherently constrains rules with respect to objects. Its advantage is that information will not be lost greatly during pruning step. The experimental evaluation shows that the proposed method is competent for discarding a large number of superfluous rules effectively and a high compression factor will be achieved. What’s more, the computational cost of our method is surprisingly lower than the Apriori method.","Data mining, Rule pruning, Galois connection, Formal concept analysis, Post-analysis"
"Kusiak A,Dixon B,Shah S",Predicting survival time for kidney dialysis patients: a data mining approach,2005,"The cost for providing care for patients on hemodialysis due to end stage kidney disease is high. Finding ways to improve patient outcomes and reduce the cost of dialysis is important. Dialysis care is intricate and multiple factors may influence patient survival. Over 50 parameters may be monitored on a regular basis in providing kidney dialysis treatments. Understanding the collective role of these parameters in determining outcomes for an individual patient and administering individualized treatments allowing specific interventions is a challenge. Individual patient survival may depend on a complex interrelationship between multiple demographic and clinical parameters, medications, medical interventions, and the dialysis treatment prescription. In this research, data preprocessing, data transformations, and a data mining approach are used to elicit knowledge about the interaction between many of these measured parameters and patient survival. Two different data mining algorithms were employed for extracting knowledge in the form of decision rules. These rules were used by a decision-making algorithm, which predicts survival of new unseen patients. Important parameters identified by data mining are interpreted for their medical significance. The concepts introduced in this research have been applied and tested using data collected at four dialysis sites. The computational results are reported in the paper.","Hemodialysis, Survival, Data mining, Data preprocessing, Data transformations, Decision making, Medical relevance, Dialysis protocol"
"Zhou L,Yu Q,Xu X,Gu Y,Yang J",Improving dense conditional random field for retinal vessel segmentation by discriminative feature learning and thin-vessel enhancement,2017,"Background and objectives As retinal vessels in color fundus images are thin and elongated structures, standard pairwise based random fields, which always suffer the “shrinking bias” problem, are not competent for such segmentation task. Recently, a dense conditional random field (CRF) model has been successfully used in retinal vessel segmentation. Its corresponding energy function is formulated as a linear combination of several unary features and a pairwise term. However, the hand-crafted unary features can be suboptimal in terms of linear models. Here we propose to learn discriminative unary features and enhance thin vessels for pairwise potentials to further improve the segmentation performance. Methods Our proposed method comprises four main steps: firstly, image preprocessing is applied to eliminate the strong edges around the field of view (FOV) and normalize the luminosity and contrast inside FOV; secondly, a convolutional neural network (CNN) is properly trained to generate discriminative features for linear models; thirdly, a combo of filters are applied to enhance thin vessels, reducing the intensity difference between thin and wide vessels; fourthly, by taking the discriminative features for unary potentials and the thin-vessel enhanced image for pairwise potentials, we adopt the dense CRF model to achieve the final retinal vessel segmentation. The segmentation performance is evaluated on four public datasets (i.e. DRIVE, STARE, CHASEDB1 and HRF). Results Experimental results show that our proposed method improves the performance of the dense CRF model and outperforms other methods when evaluated in terms of F1-score, Matthews correlation coefficient (MCC) and G-mean, three effective metrics for the evaluation of imbalanced binary classification. Specifically, the F1-score, MCC and G-mean are 0.7942, 0.7656, 0.8835 for the DRIVE dataset respectively; 0.8017, 0.7830, 0.8859 for STARE respectively; 0.7644, 0.7398, 0.8579 for CHASEDB1 respectively; and 0.7627, 0.7402, 0.8812 for HRF respectively. Conclusions The discriminative features learned in CNNs are more effective than hand-crafted ones. Our proposed method performs well in retinal vessel segmentation. The architecture of our method is trainable and can be integrated into computer-aided diagnostic (CAD) systems in the future.","Retinal vessel segmentation, Dense conditional random field, Convolutional neural network, Feature learning, Image enhancement"
"Lim S,Tucker CS,Kumara S",An unsupervised machine learning model for discovering latent infectious diseases using social media data,2017,"Introduction The authors of this work propose an unsupervised machine learning model that has the ability to identify real-world latent infectious diseases by mining social media data. In this study, a latent infectious disease is defined as a communicable disease that has not yet been formalized by national public health institutes and explicitly communicated to the general public. Most existing approaches to modeling infectious-disease-related knowledge discovery through social media networks are top-down approaches that are based on already known information, such as the names of diseases and their symptoms. In existing top-down approaches, necessary but unknown information, such as disease names and symptoms, is mostly unidentified in social media data until national public health institutes have formalized that disease. Most of the formalizing processes for latent infectious diseases are time consuming. Therefore, this study presents a bottom-up approach for latent infectious disease discovery in a given location without prior information, such as disease names and related symptoms. Methods Social media messages with user and temporal information are extracted during the data preprocessing stage. An unsupervised sentiment analysis model is then presented. Users’ expressions about symptoms, body parts, and pain locations are also identified from social media data. Then, symptom weighting vectors for each individual and time period are created, based on their sentiment and social media expressions. Finally, latent-infectious-disease-related information is retrieved from individuals’ symptom weighting vectors. Datasets and results Twitter data from August 2012 to May 2013 are used to validate this study. Real electronic medical records for 104 individuals, who were diagnosed with influenza in the same period, are used to serve as ground truth validation. The results are promising, with the highest precision, recall, and F1 score values of 0.773, 0.680, and 0.724, respectively. Conclusion This work uses individuals’ social media messages to identify latent infectious diseases, without prior information, quicker than when the disease(s) is formalized by national public health institutes. In particular, the unsupervised machine learning model using user, textual, and temporal information in social media data, along with sentiment analysis, identifies latent infectious diseases in a given location.","Latent infectious diseases, Information retrieval, Unsupervised machine learning, Sentiment analysis, Social media"
"Medhi JP,Dandapat S",An effective fovea detection and automatic assessment of diabetic maculopathy in color fundus images,2016,"Prolonged diabetes causes severe damage to the vision through leakage of blood and blood constituents over the retina. The effect of the leakage becomes more threatening when these abnormalities involve the macula. This condition is known as diabetic maculopathy and it leads to blindness, if not treated in time. Early detection and proper diagnosis can help in preventing this irreversible damage. To achieve this, the possible way is to perform retinal screening at regular intervals. But the ratio of ophthalmologists to patients is very small and the process of evaluation is time consuming. Here, the automatic methods for analyzing retinal/fundus images prove handy and help the ophthalmologists to screen at a faster rate. Motivated from this aspect, an automated method for detection and analysis of diabetic maculopathy is proposed in this work. The method is implemented in two stages. The first stage involves preprocessing required for preparing the image for further analysis. During this stage the input image is enhanced and the optic disc is masked to avoid false detection during bright lesion identification. The second stage is maculopathy detection and its analysis. Here, the retinal lesions including microaneurysms, hemorrhages and exudates are identified by processing the green and hue plane color images. The macula and the fovea locations are determined using intensity property of processed red plane image. Different circular regions are thereafter marked in the neighborhood of the macula. The presence of lesions in these regions is identified to confirm positive maculopathy. Later, the information is used for evaluating its severity. The principal advantage of the proposed algorithm is, utilization of the relation of blood vessels with optic disc and macula, which enhances the detection process. Proper usage of various color plane information sequentially enables the algorithm to perform better. The method is tested on various publicly available databases consisting of both normal and maculopathy images. The algorithm detects fovea with an accuracy of 98.92% when applied on 1374 images. The average specificity and sensitivity of the proposed method for maculopathy detection are obtained as 98.05% and 98.86% respectively.","Diabetic retinopathy, Exudate, Macula, Fovea, Diabetic maculopathy, Fundus image"
"Davoodi R,Moradi MH",Mortality prediction in intensive care units (ICUs) using a deep rule-based fuzzy classifier,2018,"Electronic health records (EHRs) contain critical information useful for clinical studies. Early assessment of patients’ mortality in intensive care units is of great importance. In this paper, a Deep Rule-Based Fuzzy System (DRBFS) was proposed to develop an accurate in-hospital mortality prediction in the intensive care unit (ICU) patients employing a large number of input variables. Our main contribution is proposing a system, which is capable of dealing with big data with heterogeneous mixed categorical and numeric attributes. In DRBFS, the hidden layer in each unit is represented by interpretable fuzzy rules. Benefiting the strength of soft partitioning, a modified supervised fuzzy k-prototype clustering has been employed for fuzzy rule generation. According to the stacked approach, the same input space is kept in every base building unit of DRBFS. The training set in addition to random shifts, obtained from random projections of prediction results of the current base building unit is presented as the input of the next base building unit. A cohort of 10,972 adult admissions was selected from Medical Information Mart for Intensive Care (MIMIC-III) data set, where 9.31% of patients have died in the hospital. A heterogeneous feature set of first 48 h from ICU admissions, were extracted for in-hospital mortality rate. Required preprocessing and appropriate feature extraction were applied. To avoid biased assessments, performance indexes were calculated using holdout validation. We have evaluated our proposed method with several common classifiers including naïve Bayes (NB), decision trees (DT), Gradient Boosting (GB), Deep Belief Networks (DBN) and D-TSK-FC. The area under the receiver operating characteristics curve (AUROC) for NB, DT, GB, DBN, D-TSK-FC and our proposed method were 73.51%, 61.81%, 72.98%, 70.07%, 66.74% and 73.90% respectively. Our results have demonstrated that DRBFS outperforms various methods, while maintaining interpretable rule bases. Besides, benefiting from specific clustering methods, DRBFS can be well scaled up for large heterogeneous data sets.","Deep learning, Fuzzy classifier, Mixed data, Mortality prediction, Intensive care units"
"Mariño C,Ortega M,Barreira N,Penedo MG,Carreira MJ,González F",Algorithm for registration of full Scanning Laser Ophthalmoscope video sequences,2011,"Abstract Fluorescein angiography is an established technique for examining the functional integrity of the retinal microcirculation for early detection of changes due to retinopathy. This paper describes a new method for the registration of large Scanning Laser Ophthalmoscope sequences (SLO), where the patient has been injected with a fluorescent dye. This allows the measurement of parameters such as the arteriovenous passage time. Due to the long time needed to acquire these sequences, there will inevitably be eye movement, which must be corrected prior to the application of quantitative analysis. The algorithm described here combines mutual information-based registration and landmark-based registration. The former will allow the alignment of the darkest frames of the sequence, where the dye has not still arrived to the retina, because of its ability to work with images without a preprocessing or segmentation, while the latter uses relevant features (the vessels) extracted by means of a robust creaseness operator, to get a very fast and accurate registration. The algorithm only detects rigid transformations but proves to be robust against the slight alterations derived from the eye location perspective during acquisition. Results were validated by expert clinicians.","Image registration, Mutual information, Crest lines, Dye–dilution curves, Artery–vein time"
"Wang Y,Ji G,Lin P,Trucco E",Retinal vessel segmentation using multiwavelet kernels and multiscale hierarchical decomposition,2013,"We propose a comprehensive method for segmenting the retinal vasculature in fundus camera images. Our method does not require preprocessing and training and can therefore be used directly on different images sets. We enhance the vessels using matched filtering with multiwavelet kernels (MFMK), separating vessels from clutter and bright, localized features. Noise removal and vessel localization are achieved by a multiscale hierarchical decomposition of the normalized enhanced image. We show a necessary condition to achieve the optimal decomposition and derive the associated value of the scale parameter controlling the amount of details captured. Finally, we obtain a binary map of the vasculature by locally adaptive thresholding, generating a threshold surface based on the vessel edge information extracted by the previous processes. We report experimental results on two public retinal data sets, DRIVE and STARE, demonstrating an excellent performance in comparison with retinal vessel segmentation methods reported recently.","Vessel detection, Retinal images, Segmentation, Matched filter, Multiwavelet, Multiscale hierarchical decomposition"
"Heneghan C,Flynn J,O'Keefe M,Cahill M",Characterization of changes in blood vessel width and tortuosity in retinopathy of prematurity using image analysis,2002,"Many retinal diseases are characterised by changes to retinal vessels. For example, a common condition associated with retinopathy of prematurity (ROP) is so-called plus disease, characterised by increased vascular dilation and tortuosity. This paper presents a general technique for segmenting out vascular structures in retinal images, and characterising the segmented blood vessels. The segmentation technique consists of several steps. Morphological preprocessing is used to emphasise linear structures such as vessels. A second derivative operator is used to further emphasise thin vascular structures, and is followed by a final morphological filtering stage. Thresholding of this image is used to provide a segmented vascular mask. Skeletonisation of this mask allows identification of points in the image where vessels cross (bifurcations and crossing points) and allows the width and tortuosity of vessel segments to be calculated. The accuracy of the segmentation stage is quite dependent on the parameters used, particularly at the thresholding stage. However, reliable measurements of vessel width and tortuosity were shown using test images. Using these tools, a set of images drawn from 23 subjects being screened for the presence of threshold ROP disease is considered. Of these subjects, 11 subsequently required treatment for ROP, 9 had no evidence of ROP, and 3 had spontaneously regressed ROP. The average vessel width and tortuosity for the treated subjects was 96.8 ?m and 1.125. The corresponding figures for the non-treated cohort were 86.4 ?m and 1.097. These differences were statistically significant at the 99% and 95% significance level, respectively. Subjects who progressed to threshold disease during the course of screening showed an average increase in vessel width of 9.6 ?m and in tortuosity of +0.008. Only the change in width was statistically significant. Applying a simple retrospective screening paradigm based solely on vessel width and tortuosity yields a screening test with a sensitivity and specificity of 82% and 75%. Factors confounding a more accurate test include poor image quality, inaccuracies in vessel segmentation, inaccuracies in measurement of vessel width and tortuosity, and limitations inherent in screening based solely on examination of the posterior pole.","Morphological processing, Retinopathy of prematurity, Segmentation, Screening"
"Liu Q,Zhou X,Wu H,Zheng B",Blocking-free and self-contained immunoassay platform for one-step point-of-care testing,2020,"This paper reports a quantitative and sensitive one-step point-of-care testing (POCT) chip built on a perfluorinated substrate patterned with polydopamine microspots array. The capture antibody was covalently immobilized on the polydopamine microspots, while the fluorescently labelled detection antibody was physically adsorbed on the perfluorinated surface. The POCT chip allowed one-step sandwich immunoassay and was able to directly detect the analytes from the whole blood without sample preprocessing. By further taking advantages of the strong fluorescence quenching ability of the polydopamine, the blocking-free substrate was able to achieve similar performance in detecting and quantifying the protein biomarkers as the substrate with the blocking treatment. The blocking-free strategy not only made the fabrication of the chip simple and convenient, but also improved the chip's sensitivity for biomarker quantification. Finally, we demonstrated that the self-contained POCT platform maintained the performance for one-step immunoassay even after long-term storage. With the POCT platform, we are one step closer to a sample-in-answer-out diagnostic system.","Microarray, Polydopamine, Excipient, Quantitative immunoassay, Fluorescence quenching, Point-of-care testing"
"Santos MS,Abreu PH,García-Laencina PJ,Simão A,Carvalho A",A new cluster-based oversampling method for improving survival prediction of hepatocellular carcinoma patients,2015,"Liver cancer is the sixth most frequently diagnosed cancer and, particularly, Hepatocellular Carcinoma (HCC) represents more than 90% of primary liver cancers. Clinicians assess each patient’s treatment on the basis of evidence-based medicine, which may not always apply to a specific patient, given the biological variability among individuals. Over the years, and for the particular case of Hepatocellular Carcinoma, some research studies have been developing strategies for assisting clinicians in decision making, using computational methods (e.g. machine learning techniques) to extract knowledge from the clinical data. However, these studies have some limitations that have not yet been addressed: some do not focus entirely on Hepatocellular Carcinoma patients, others have strict application boundaries, and none considers the heterogeneity between patients nor the presence of missing data, a common drawback in healthcare contexts. In this work, a real complex Hepatocellular Carcinoma database composed of heterogeneous clinical features is studied. We propose a new cluster-based oversampling approach robust to small and imbalanced datasets, which accounts for the heterogeneity of patients with Hepatocellular Carcinoma. The preprocessing procedures of this work are based on data imputation considering appropriate distance metrics for both heterogeneous and missing data (HEOM) and clustering studies to assess the underlying patient groups in the studied dataset (K-means). The final approach is applied in order to diminish the impact of underlying patient profiles with reduced sizes on survival prediction. It is based on K-means clustering and the SMOTE algorithm to build a representative dataset and use it as training example for different machine learning procedures (logistic regression and neural networks). The results are evaluated in terms of survival prediction and compared across baseline approaches that do not consider clustering and/or oversampling using the Friedman rank test. Our proposed methodology coupled with neural networks outperformed all others, suggesting an improvement over the classical approaches currently used in Hepatocellular Carcinoma prediction models.","Hepatocellular Carcinoma (HCC), Clustering, K-means, Oversampling, SMOTE, Survival prediction"
"Gunasundari S,Janakiraman S,Meenambal S",Multiswarm heterogeneous binary PSO using win-win approach for improved feature selection in liver and kidney disease diagnosis,2018,"Feature selection is a significant preprocessing method in the classification part of an expert system. We propose a new Multiswarm Heterogeneous Binary Particle Swarm Optimization algorithm (MHBPSO) using a Win-Win approach to improve the performance of Binary Particle Swarm Optimization algorithm (BPSO) for feature selection. MHBPSO is a cooperation algorithm, which includes BPSO and its three variants such as Boolean PSO (BoPSO), Self Adjusted Hierarchical Boolean PSO (SAHBoPSO), and Catfish Self Adjusted Hierarchical Boolean PSO (CSAHBoPSO). It performs heterogeneous search on the entire solution space using four different algorithms. Each algorithm shares global best information to another algorithm to select the preeminent global best position. A variant of BoPSO, SAHBoPSO is proposed, in which leaders are identified based on the fitness values for guiding remaining particles and thus forms the hierarchical structure of leaders and its followers. Meanwhile leaders and followers are changed dynamically and consequently changed the hierarchical structure. CSAHBoPSO, which is the version of SAHBoPSO, is also proposed to avoid stagnation in the subsequent iterations. To assess the performance of the proposed algorithms CEC 2013 benchmark functions are employed. In order to validate the proposed algorithms, comparative study with BPSO, BoPSO, VPSO (Mirjalili and Lewis, 2013), HBPSOGA (Wang et al., 2018) and CatfishBPSO (Chuang et al., 2011a) is provided. Experimental results show that SAHBoPSO and CSAHBoPSO algorithm based on BoPSO are promising and significantly better than BPSO, BoPSO, and VPSO. MHBPSO shows the superior improvement in the search ability. In addition, proposed algorithms are tested in the feature selection phase of intelligent liver and kidney cancer diagnostic systems to select elite features from the liver and kidney cancer data. Findings show that the proposed system is proficient in selecting the elite features to classify the tumor as benign or malignant with minimum error rates.","Binary Particle Swarm Optimization, Boolean particle swarm optimization, Swarm intelligence, Feature selection, Liver cancer, Kidney cancer"
"Li J,Lu J,Tobore I,Liu Y,Kandwal A,Wang L,Zhou J,Nie Z",Towards noninvasive and fast detection of Glycated hemoglobin levels based on ECG using convolutional neural networks with multisegments fusion and Varied-weight,2021,"Glycated hemoglobin A1c (HbA1c) is regarded as a gold standard to evaluate long-term blood glucose control, and it is also a crucial metric in diabetes screening, diagnosis, and management. However, thus far, the HbA1c measurement methods are invasive and painful. Considering that HbA1c levels are associated with cardiovascular autonomic neuropathy, in this paper, a novel Electrocardiogram (ECG)-based approach was presented for noninvasive and fast detection of HbA1c levels using 60-second, single-lead ECG waveform. For this purpose, a total of 317,105 ECG datasets encompassing 370 patients with diabetes were obtained using wearable devices. Furthermore, the ECG preprocessing was based on autocorrelation analysis. The convolutional neural networks with multisegment fusion and varied-weight (CNN-MFVW) were proposed to achieve ECG feature extraction and HbA1c detection. The results showed that the average accuracy, precision, recall, and F1-score of the proposed algorithm were 0.9015, 0.9051, 0.8991 and 0.9013 respectively. Moreover, the area under the curve (AUC) was up to 0.9899, which was higher than other algorithms of conventional CNN and CNN-LSTM. Therefore, we conclude that the proposed approach for noninvasive and fast detection of HbA1c levels has potentials in practical applications. © 2021 Elsevier Ltd","Autocorrelation; Chemical detection; Convolution; Feature extraction; Hemoglobin; Long short-term memory, Auto correlation; Convolutional neural network; Fast detections; Glycated hemoglobin a1c; Glycated hemoglobins; Gold standards; Haemoglobins; Hemoglobin levels; Multi-segment; Non-invasive detection, Electrocardiography"
"Muneeb M,Henschel A",Eye-color and Type-2 diabetes phenotype prediction from genotype data using deep learning methods,2021,"Background: Genotype–phenotype predictions are of great importance in genetics. These predictions can help to find genetic mutations causing variations in human beings. There are many approaches for finding the association which can be broadly categorized into two classes, statistical techniques, and machine learning. Statistical techniques are good for finding the actual SNPs causing variation where Machine Learning techniques are good where we just want to classify the people into different categories. In this article, we examined the Eye-color and Type-2 diabetes phenotype. The proposed technique is a hybrid approach consisting of some parts from statistical techniques and remaining from Machine learning. Results: The main dataset for Eye-color phenotype consists of 806 people. 404 people have Blue-Green eyes where 402 people have Brown eyes. After preprocessing we generated 8 different datasets, containing different numbers of SNPs, using the mutation difference and thresholding at individual SNP. We calculated three types of mutation at each SNP no mutation, partial mutation, and full mutation. After that data is transformed for machine learning algorithms. We used about 9 classifiers, RandomForest, Extreme Gradient boosting, ANN, LSTM, GRU, BILSTM, 1DCNN, ensembles of ANN, and ensembles of LSTM which gave the best accuracy of 0.91, 0.9286, 0.945, 0.94, 0.94, 0.92, 0.95, and 0.96% respectively. Stacked ensembles of LSTM outperformed other algorithms for 1560 SNPs with an overall accuracy of 0.96, AUC = 0.98 for brown eyes, and AUC = 0.97 for Blue-Green eyes. The main dataset for Type-2 diabetes consists of 107 people where 30 people are classified as cases and 74 people as controls. We used different linear threshold to find the optimal number of SNPs for classification. The final model gave an accuracy of 0.97%. Conclusion: Genotype–phenotype predictions are very useful especially in forensic. These predictions can help to identify SNP variant association with traits and diseases. Given more datasets, machine learning model predictions can be increased. Moreover, the non-linearity in the Machine learning model and the combination of SNPs Mutations while training the model increases the prediction. We considered binary classification problems but the proposed approach can be extended to multi-class classification. © 2021, The Author(s).","Color; Deep learning; Forecasting; Learning systems; Long short-term memory; Statistical methods, Binary classification problems; Genetic mutations; Gradient boosting; Machine learning models; Machine learning techniques; Multi-class classification; Overall accuracies; Statistical techniques, Learning algorithms, eye color; genetics; genotype; human; non insulin dependent diabetes mellitus; phenotype, Deep Learning; Diabetes Mellitus, Type 2; Eye Color; Genotype; Humans; Phenotype"
"Mathews MR,Anzar SM",A comprehensive review on automated systems for severity grading of diabetic retinopathy and macular edema,2021,"Diabetes mellitus is a major medical concern worldwide. Long-term diabetes can affect the retina of the eye and lead to diabetic retinopathy (DR) and diabetic macular edema (DME). Proper screening and consultation with an ophthalmologist are necessary to prevent avoidable vision loss. As DR and DME have become more prevalent, automated screening is essential to provide cost-effective and rapid solutions with reduced human resources requirements. This paper aims to provide a comprehensive review of the literature on computer-aided diagnosis of DR and DME. We identified the studies on automated five-class grading of DR according to International Clinical Diabetic Retinopathy severity scale and three class grading of diabetic maculopathy, using fundus images. A systematic search on research repositories was conducted, and relevant studies were scrutinized and included in the review. The studies were reported in nearly 100 different journals. We have reviewed the studies in all aspects including datasets, preprocessing, non-deep learning, and deep learning-based algorithms, and evaluation metrics. Significant contributions in developing automated tools for DR/DME grading are highlighted. We have identified and discussed research gaps and challenges. This will help researchers to get an updated summary of work done in the area. Deep learning-based algorithms have outperformed the traditional algorithms in the domain. Despite their promising performance, these algorithms reveal the potential for significant improvements to become a reliable tool in clinical settings. © 2021 Wiley Periodicals LLC.","Automation; Computer aided diagnosis; Cost effectiveness; Deep learning; Eye protection; Grading, Automated screening; Automated systems; Clinical settings; Diabetes mellitus; Diabetic retinopathy; Evaluation metrics; Learning-based algorithms; Systematic searches, Learning algorithms"
"Ponnibala M,Priyanka EB,Thangavel S",Proliferative Diabetic Retinopathy Diagnostic Investigation Using Retinal Blood Vessels Mining Technique,2021,"In clinical field, wide assortments of utilizations can be managed utilizing image handling. Recognition and screening of retinal sicknesses was one such application in picture preparing. Diabetic retinopathy is an inconvenience of diabetes. The ailment influences veins inside the retina. The retina is a region lying at the rear of the eyeball. In the most punctual phase of the infection, the little veins, or vessels, gotten slenderer, more fragile and inevitably they spill blood. A patient's sight at this stage is still acceptable yet an ophthalmologist can identify and see the irregularities in the retina. As the sickness advances, some veins are obstructed. These trigger the retina to develop fresh blood vessels, which are unusual, delicate, and effectively drain. In the later phase of the ailment, fresh blood vessels are developed ceaselessly just as scar tissue. Eventually, retina will be isolates from an eye. Another strategy for removing the retinal veins from the shading fundus retinal picture dependent on include grouping was proposed in this undertaking, to decrease the ophthalmologists' time and vitality for checking the retinal pictures. The veins are separated from the shading fundus picture by applying the preprocessing strategies and division procedures utilizing coordinated channel and adjusted nearby entropy thresholding activity. The preprocessed picture was then utilized for highlight extraction and these highlights were utilized for order reason. At long last, arrangement procedure was utilized for diagnosing the proliferative diabetic retinopathy. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC part of Springer Nature.","Blood; Diseases; Eye protection; Image processing; Ophthalmology, Diabetic retinopathy; Mining techniques; Retinal blood vessels; Scar tissues; Thresholding, Blood vessels"
"Tena F,Garnica O,Lanchares J,Hidalgo JI",Ensemble models of cutting-edge deep neural networks for blood glucose prediction in patients with diabetes,2021,"This article proposes two ensemble neural network-based models for blood glucose prediction at three different prediction horizons—30, 60, and 120 min—and compares their performance with ten recently proposed neural networks. The twelve models’ performances are evaluated under the same OhioT1DM Dataset, preprocessing workflow, and tools at the three prediction horizons using the most common metrics in blood glucose prediction, and we rank the best-performing ones using three methods devised for the statistical comparison of the performance of multiple algorithms: scmamp, model confidence set, and superior predictive ability. Our analysis provides a comparison of the state-of-the-art neural networks for blood glucose prediction, estimating the model’s error, highlighting those with the highest probability of being the best predictors, and providing a guide for their use in clinical practice. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Blood; Deep neural networks; Glucose, Blood glucose; Blood glucose prediction; Cutting edges; Deep learning; Ensemble models; Ensemble neural network; Network-based modeling; Neural-networks; Performance; Prediction horizon, Forecasting"
"Seo W,Park SW,Kim N,Jin SM,Park SM",A personalized blood glucose level prediction model with a fine-tuning strategy: A proof-of-concept study,2021,"Background: The accurate prediction of blood glucose (BG) level is still a challenge for diabetes management. This is due to various factors such as diet, personal physiological characteristics, stress, and activities influence changes in BG level. To develop an accurate BG level predictive model, we propose a personalized model based on a convolutional neural network (CNN) with a fine-tuning strategy. Methods: We utilized continuous glucose monitoring (CGM) datasets from 1052 professional CGM sessions and split them into three groups according to type 1, type 2, and gestational diabetes mellitus (T1DM, T2DM, and GDM, respectively). During the preprocessing, only CGM data points were utilized, and future BG levels of four different prediction horizons (PHs, 15, 30, 45, and 60 min) were used as output. In training, we trained a general CNN and a multi-output random forest regressor using a hold-out method for each group. Next, we developed two personalized models: (1) by fine-tuning the general CNN on partial sample points of each CGM dataset, and (2) by learning a CNN from scratch on the points. Results: For all groups, the fine-tuned CNN showed the lowest average root mean squared error, average mean absolute percentage error, highest average time gain (PH = 15 and 60 min in T1DM) and highest percentage in region A of Clarke error grid analysis at all PHs. In the performance comparison between the fine-tuned CNN and other models, we found that the fine-tuned CNN improved the performance of the general CNN in most cases and outperformed the scratch CNN at all PHs in all groups, making the fine-tuning strategy was useful for accurate BG level prediction. We analyzed all cases of four predictive patterns in each group, and found that the input BG level trend and the BG level at the time of prediction were related to the future BG level trend. Conclusions: We demonstrated the efficacy of the fine-tuning method in a large number of CGM datasets and analyzed the four predictive patterns. Therefore, we believe that the proposed method will significantly contribute to the development of an accurate personalized model and the analysis for its predictions. © 2021","Blood; Convolutional neural networks; Decision trees; Errors; Forecasting; Glucose; Information management; Large dataset; Mean square error, Blood glucose level; Blood glucose management; Continuous glucose monitoring; Convolutional neural network; Data-driven approach; Fine tuning; Personalized model; Prediction modelling; Proof of concept; Tuning strategy, Deep neural networks, C peptide; carbohydrate; glucose; hemoglobin A1c, adult; Article; blood glucose monitoring; comparative study; controlled study; convolutional neural network; female; glucose blood level; human; insulin dependent diabetes mellitus; insulin release; major clinical study; male; middle aged; non insulin dependent diabetes mellitus; predictive value; pregnancy diabetes mellitus; proof of concept; random forest; blood glucose monitoring; diet; forecasting, Blood Glucose; Blood Glucose Self-Monitoring; Diet; Forecasting; Neural Networks, Computer"
"Jeyafzam F,Vaziri B,Suraki MY,Hosseinabadi AA,Slowik A",Improvement of grey wolf optimizer with adaptive middle filter to adjust support vector machine parameters to predict diabetes complications,2021,"In medical science, collecting and classifying data from various diseases is a vital task. The confused and large amounts of data are problems that prevent us from achieving acceptable results. One of the major problems for diabetic patients is a failure to properly diagnose the disease. As a result of this mistake in diagnosis or failure in early diagnosis, the patient may suffer from complications such as blindness, kidney failure, and cutting off the toes. Nowadays, doctors diagnose the disease by relying on their experience and knowledge and performing complex and time-consuming tests. One of the problems with current diabetic, diagnostic methods is the lack of appropriate features to diagnose the disease and consequently the weakness in its diagnosis, especially in its early stages. Since diabetes diagnosis relies on large amounts of data with many parameters, it is necessary to use machine learning methods such as support vector machine (SVM) to predict the complications of diabetes. One of the disadvantages of SVM is its parameter adjustment, which can be accomplished using metaheuristic algorithms such as particle swarm optimization algorithm (PSO), genetic algorithm, or grey wolf optimizer (GWO). In this paper, after preprocessing and preparing the dataset for data mining, we use SVM to predict complications of diabetes based on selected parameters of a patient acquired by laboratory test using improved GWO. We improve the selection process of GWO by employing dynamic adaptive middle filter, a nonlinear filter that assigns appropriate weight to each value based on the data value. Comparison of the final results of the proposed algorithm with classification methods such as a multilayer perceptron neural network, decision tree, simple Bayes, and temporal fuzzy min–max neural network (TFMM-PSO) shows the superiority of the proposed method over the comparable ones. © 2021, The Author(s).","Adaptive filtering; Adaptive filters; Data mining; Decision trees; Diagnosis; Filtration; Forecasting; Genetic algorithms; Large dataset; Learning systems; Multilayer neural networks; Particle swarm optimization (PSO); Statistical tests; Trees (mathematics), Classification methods; Diabetes diagnosis; Large amounts of data; Machine learning methods; Meta heuristic algorithm; Multi-layer perceptron neural networks; Parameter adjustments; Particle swarm optimization algorithm, Support vector machines"
"Shivappriya SN,Rajaguru H,Ramya M,Asiyabegum U,Prasanth D",Disease Prediction based on Retinal Images,2021,"The paper's major goal is to create a basic framework for recognising disorders including diabetes, hypertension, and heart attacks. In the retinal fundus image shows two types of blood vessels that is arteries and veins. To diagnosis the different types of diseases, it is more important to distinguish the vessels into arteries veins, which are highly correlated with brain and heart functioning. Preprocessing steps are introduced for the segmentation vessel using median filter algorithm. After pre-processing the images are undergone with Convolution Neural Network (CNN) approach. CNN is used to recognize the key feature of the images and they are differentiated based on the key feature. When we give the input of retinal images the difference in the retinal eye was observed based on their diseases. There are numerous diseases like heart attack, diabetics etc, which kills the people. With the help of this project some of the diseases are predicted with the help of the retinal eye. Retinal eye is very important which consists of retinal nerves which are connected to the brain. The VGG 16 architecture is used to find the diseases using retinal images. © 2021 IEEE.","Blood vessels; Diagnosis; Median filters; Network architecture, Convolution neural network; Heart attack; Highly-correlated; Key feature; Prediction-based; Preprocessing; Retina; Retinal fundus images; Retinal image; VGG16 architecture, Ophthalmology"
"Yasin S,Iqbal N,Ali T,Draz U,Alqahtani A,Irfan M,Rehman A,Glowacz A,Alqhtani S,Proniewska K,Brumercik F,Wzorek L",Severity grading and early retinopathy lesion detection through hybrid inception-resnet architecture,2021,"Diabetic retinopathy (DR) is a diabetes disorder that disturbs human vision. It starts due to the damage in the light-sensitive tissues of blood vessels at the retina. In the beginning, DR may show no symptoms or only slight vision issues, but in the long run, it could be a permanent source of impaired vision, simply known as blindness in the advanced as well as in developing nations. This could be prevented if DR is identified early enough, but it can be challenging as we know the disease frequently shows rare signs until it is too late to deliver an effective cure. In our work, we recommend a framework for severity grading and early DR detection through hybrid deep learning Inception-ResNet architecture with smart data preprocessing. Our proposed method is composed of three steps. Firstly, the retinal images are preprocessed with the help of augmentation and inten-sity normalization. Secondly, the preprocessed images are given to the hybrid Inception-ResNet architecture to extract the vector image features for the categorization of different stages. Lastly, to identify DR and decide its stage (e.g., mild DR, moderate DR, severe DR, or proliferative DR), a classification step is used. The studies and trials have to reveal suitable outcomes when equated with some other previously deployed approaches. However, there are specific constraints in our study that are also discussed and we suggest methods to enhance further research in this field. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Blood vessels; Deep learning; Grading; Image processing; Ophthalmology, Data preprocessing; Deep learning; Developing nations; Diabetic retinopathy; Fundus image; Human vision; Impaired vision; Lesion detection; Retinal image; SMART datum, Eye protection, blindness; diabetic retinopathy; diagnostic imaging; eye fundus; human; methodology; retina, Blindness; Diabetic Retinopathy; Fundus Oculi; Humans; Research Design; Retina"
"Nugroho A,Fanani AZ,Shidik GF",Evaluation of Feature Selection Using Wrapper for Numeric Dataset with Random Forest Algorithm,2021,"Preprocessing is more than half of machine learning process. Dimensionality reduction is one of the preprocessing task, which included feature extraction and selection. Feature selection used for identify relevant and remove not relevant feature. The goal of this research is to select relevant feature using wrapper method for early diabetes prediction dataset which has been transformed to numeric dataset previously. Forward and backward selection are used in wrapper method, that's combine with random forest and cross validation. Random forest is decision tree enhancement, which is group of trees that can produce difference or same result at each tree. The most results are made as final result. The final result from feature selection with wrapper method can make higher accuracy than without feature selection for numeric dataset and the number of feature can be reduced. With features selection which is sequential forward selection it has 98.84 % accuracy with 11 feature selected and with sequential backward selection, it has 99.03 % accuracy with same number of features selected. With reduced features, will reduces complexity of trees and time required in mining process.. © 2021 IEEE.","Decision trees; Random forests, Backward selection; Dimensionality reduction; Feature extraction and selection; Features selection; Forward selection; Random forest algorithm; Random forests; Relevant features; Wrapper; Wrapper methods, Feature extraction"
"Li J,Tobore I,Liu Y,Kandwal A,Wang L,Nie Z",Non-invasive Monitoring of Three Glucose Ranges Based on ECG by Using DBSCAN-CNN,2021,"Autonomic nervous system (ANS) can maintain homeostasis through the coordination of different organs including heart. The change of blood glucose (BG) level can stimulate the ANS, which will lead to the variation of Electrocardiogram (ECG). Considering that the monitoring of different BG ranges is significant for diabetes care, in this paper, an ECG-based technique was proposed to achieve non-invasive monitoring with three BG ranges: low glucose level, moderate glucose level, and high glucose level. For this purpose, multiple experiments that included fasting tests and oral glucose tolerance tests were conducted, and the ECG signals from 21 adults were recorded continuously. Furthermore, an approach of fusing density-based spatial clustering of applications with noise and convolution neural networks (DBSCAN-CNN) was presented for ECG preprocessing of outliers and classification of BG ranges based ECG. Also, ECG's important information, which was related to different BG ranges, was graphically visualized. The result showed that the percentages of accurate classification were 87.94% in low glucose level, 69.36% in moderate glucose level, and 86.39% in high glucose level. Moreover, the visualization results revealed that the highlights of ECG for the different BG ranges were different. In addition, the sensitivity of prediabetes/diabetes screening based on ECG was up to 98.48%, and the specificity was 76.75%. Therefore, we conclude that the proposed approach for BG range monitoring and prediabetes/diabetes screening has potentials in practical applications. © 2013 IEEE.","Glucose, Autonomic nervous system; Blood glucose; Convolution neural network; Density based spatial clustering of applications with noise; ECG preprocessing; Non-invasive monitoring; Oral glucose tolerance tests; Visualization results, Electrocardiography, adrenergic system; adult; Article; autonomic nervous system; blood glucose monitoring; cholinergic system; clinical article; controlled study; convolutional neural network; diabetes mellitus; diabetes screening; diagnostic test accuracy study; electrocardiogram; glucose blood level; heart beat; homeostasis; human; human experiment; impaired glucose tolerance; mass screening; nerve cell network; oral glucose tolerance test; QRS interval; QT interval; sensitivity and specificity; blood glucose monitoring; electrocardiography; glucose blood level; glucose tolerance test, glucose, Adult; Blood Glucose; Blood Glucose Self-Monitoring; Electrocardiography; Glucose; Glucose Tolerance Test; Humans"
"Abokhzam AA,Gupta NK,Bose DK",Efficient diabetes mellitus prediction with grid based random forest classifier in association with natural language processing,2021,"Human body turns the food consumed into energy, but when insulin doesn’t act in its way to convert the blood glucose into energy, then the glucose remains in the bloodstream and causes a life-threatening health issue called Diabetes Mellitus or Diabetes. According to the growing morbidity in recent years, in 2040, the world’s diabetic patients will reach 642 million, which means that one of the ten adults in the future will be suffering from diabetes. With the rapid development of machine learning, it has been applied to many aspects of medical health. So, for efficiently and effectively diagnosing the Diabetes Mellitus, a method is proposed using the ML Grid Search algorithm. In this method, Pima Indian Diabetic Dataset is used. This system has two phases: The training phase includes preprocessing, feature selection and instance evaluation is done and the test phase includes preprocessing, instance evaluation and disease prediction is done. For feature selection, the random forest feature selection is used and for classification, support vector regression, logistic regression and grid based random forest classifier is used. The proposed method of predicting the diabetes, the accuracy is almost 95.7% which is higher when compared to previous methods. Additionally, the proposed system provides an ability to the users to understand the resulting scenario over any language with the help of language processing in results. The Natural Language Processing concept is adapted over the proposed approach to identify the features of the resulting text and perform the language processing and display the exact language-oriented data to the users without any hurdle. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Artificial life; Blood; Decision trees; Diagnosis; Feature extraction; Forecasting; Glucose; Logistic regression; Random forests; Support vector regression, Diabetes mellitus; Diabetic patient; Grid-search algorithm; Language processing; Medical health; NAtural language processing; Random forest classifier; Training phase, Natural language processing systems"
"Xu X,Huang X,Ma J,Luo X",Prediction of Diabetes with its Symptoms Based on Machine Learning,2021,"As the destruction of diabetes is significant to the whole world, we want to focus on it and extract useful information from the correlation between symptoms and disease. The dataset obtained from UCI is the fundamental resource for the research. In order to ensure the accuracy of the project conclusions, three different approaches were used to verify each other: literature analysis, data analysis and machine learning. Literature part mainly contains previous work and large quantities of medical research done on diabetes. Data analysis included data preprocessing and visualization so as to unfold the concealed information of the dataset. Machine learning is to use the inspiration from the previous two parts to attain a suitable model for diabetes prediction. The project finally provides knowledge of different symptoms of diabetes and their relation with diabetes. It also elaborates how symptoms can be used to predict disease. Finally, we put forward suggestions for the prevention of diabetes and monitoring of potential disease. © 2021 IEEE.","Data handling; Data visualization; Information analysis; Machine learning, Data preprocessing; Literature analysis; Machine-learning; Medical research; On-machines, Forecasting"
"Basri KN,Tuhaime NA,Hisham MH,Laili MH,Yusof ZM,Mazni FS,Yusof AR,Mustafa N,Yusof HM",PLS Predictive Model for In-Vivo Non-Invasive Finger Touch Blood Glucose NIR Spectrosensor,2021,Diabetes is one of the non-communicable disease that has high prevalence trends. The use of finger pricking to monitor the glucose level is painful thus non-invasive alternative is needed. Non-invasive finger touch blood glucose NIR spectrosensor was utilized for the in-vivo glucose monitoring on patients at Hospital Universiti Kebangsaan Malaysia (HUKM). The development of predictive model for the glucose monitoring was based on partial least square (PLS) algorithm. Different type of preprocesses were selected to check the performance of the model with different method of signal preprocessing. The optimum number of variable when performing variable selection is 744. The R2C and R2p acquired were 0.2492 and 0.1734 respectively. The RMSEC and RMSEP for the model were 3.0324 and 2.9901 for the combination of preprocessing of generalized least square (Gls) weighting and autoscale (As). Interval PLS (iPLS) was implemented for the wavelength extraction to enhance the predictive model. R2p for 500 variables (wavelength points) shown the best result with a value of 0.2390. RMSEP also has decreased by to 2.8221 from the previous model 2.9956. © 2021 IEEE.,"Blood; Glucose; Infrared devices; Nanoelectronics, Generalized least square; Glucose monitoring; Non-communicable disease; Optimum number; Partial least square algorithms; Predictive modeling; Signal preprocessing; Variable selection, Predictive analytics"
"Ouyang C,Gan Z,Zhen J,Guan Y,Zhu X,Zhou P",Inter-Patient Classification with Encoded Peripheral Pulse Series and Multi-Task Fusion CNN: Application in Type 2 Diabetes,2021,"Diabetes mellitus, a chronic disease associated with elevated accumulation of glucose in the blood, is generally diagnosed through an invasive blood test such as oral glucose tolerance test (OGTT). An effective method is proposed to test type 2 diabetes using peripheral pulse waves, which can be measured fast, simply and inexpensively by a force sensor on the wrist over the radial artery. A self-designed pulse waves collection platform includes a wristband, force sensor, cuff, air tubes, and processing module. A dataset was acquired clinically for more than one year by practitioners. A group of 127 healthy candidates and 85 patients with type 2 diabetes, all between the ages of 45 and 70, underwent assessments in both OGTT and pulse data collection at wrist arteries. After preprocessing, pulse series were encoded as images using the Gramian angular field (GAF), Markov transition field (MTF), and recurrence plots (RPs). A four-layer multi-task fusion convolutional neural network (CNN) was developed for feature recognition, the network was well-trained within 30 minutes based on our server. Compared to single-task CNN, multi-task fusion CNN was proved better in classification accuracy for nine of twelve settings with empirically selected parameters. The results show that the best accuracy reached 90.6% using an RP with threshold $\epsilon$ of 6000, which is competitive to that using state-of-the-art algorithms in diabetes classification. © 2013 IEEE.","Blood; Convolutional neural networks; Glucose, Classification accuracy; Diabetes mellitus; Feature recognition; Oral glucose tolerance tests; Processing modules; Recurrence plot; State-of-the-art algorithms; Transition fields, Multilayer neural networks, algorithm; Article; computer model; controlled study; convolutional neural network; event related potential; feature extraction; female; gene expression; glucose tolerance test; Gramian angular field; human; information science; machine learning; major clinical study; male; Markov decision process; Markov transition field; non insulin dependent diabetes mellitus; oral glucose tolerance test; phenotype; physician; radial artery; receiver operating characteristic; recurrence plots; time series analysis; wrist; aged; middle aged; non insulin dependent diabetes mellitus, Aged; Algorithms; Diabetes Mellitus, Type 2; Humans; Middle Aged; Neural Networks, Computer"
"Zhao H,Peng H,Gao Z,Zheng S",Mask Region-oriented Diabetic Retinopathies Detection in Ophthalmic Medical Images via Non-local Attention,2021,"Accurate lesions detection on retinopathy images is crucial for the diagnosis of diabetes. However, it is always hampered by various characteristics of lesions such as shape, color, texture, and similarities. Most advanced algorithms still cannot automatically detect common lesions, e.g. exudate, hemorrhage, and cotton-wool spots, being used for comprehensive analysis of disease state. To this end, we present a multi-functional detection model for diabetic retinopathies and further analyze disease mechanisms overall. Specifically, this paper attempts to implement a multi-lesion detector via modified Mask region-oriented CNN, which can be used for the aforementioned retinopathies. Meanwhile, a non-local attention module is introduced to the detector as a spatial attention mechanism for handling the global information missing problem. In addition, to boost the effectiveness of the detector, the dilated operation is implemented for dataset preprocessing. Improvement is achieved both algorithmically and architecturally, via investigating thoroughly the most probable lesion category with a novel ensemble learning framework. Extensive experiments on standard datasets for three different tasks evidence the superior performance of the proposed method over state-of-the-art methods. © 2021 IEEE.","Diagnosis; Medical imaging; Textures, Color similarity; Color textures; Cotton-wool spots; Diabetic retinopathy; Haemorrage; Lesion detection; Mask region-oriented CNN; Multi-lesion detection; Non-local attention; Nonlocal, Eye protection"
"Appavu alias Balamurugan S,Salomi M",A predictive risk level classification of diabetic patients using deep learning modified neural network,2021,"In health care firm, data mining (DM) has an effectual role in predicting the diseases. Today, diabetes is the chief global health issue. Several algorithms are introduced for predicting the diabetes disease and its accuracy estimation. Yet, there is no effectual algorithm for providing the severity of diabetes in respect of ratio which interprets the impact of diabetes on different organs of the human body. To overcome such drawbacks, predictive and risk level classification of diabetes patients using DLMNN and Naïve Bayes (NB) classification methods is system model. This system model system comprises 2 phases namely, phase-1: diabetic disease prediction model, and phase-2: risk analysis. In phase-1, the patient data are taken as of the dataset. Then, from this patient dataset repeated data are removed using HDFS Map Reduce (). Next, as the preprocessing stage, the missing attributes are replaced by averaging the considered data. After that, from the preprocessed data the disease is predicted using DLMNN classification method which results in obtaining the diabetic patient data. Then, the diabetic patient data are sent to phase-2. In phase 2, the missing attributes are replaced using the same average method. Next, the patient data is sorted centered on age utilizing recursive K-means clustering algorithm. Finally, the clustered patient data is classified using the NB classifier algorithm. Experiential results contrasted the system model modified deep learning algorithm with the existing IKMC algorithm in rapports of precision, accuracy, F-measure, and recall. The outcomes confirmed that the system model diabetes prediction and analysis model shows better results on considering the existent methods. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Barium compounds; Data mining; Deep learning; File organization; Forecasting; Hospital data processing; Learning algorithms; Learning systems; Risk analysis; Risk assessment, Deep learning modified neural network; Distributed file systems; Hadoop distributed file system; Improved K-mean clustering algorithm; K-mean clustering; K-means clustering algorithms; K-means++ clustering; Modified neural networks; Naive baye; Naive bayes, K-means clustering"
"Zhang F,Miao J,Wang W,Xiao Z,Xu X",Automatic Discrimination of Fundus DR Based on Improved Residual Dense Block Network,2021,"Diabetic retinopathy is the most serious complication of diabetes. In hospital treatment or telemedicine, experts analyze and treat patients with Diabetic Retinopathy (DR) based on the retinal images captured by the fundus camera. However, large number of non-pathological fundus images occupy too much time for the ophthalmologist to diagnose, and delay the timely treatment of patients with fundus DR. Therefore, it is a very urgent task to automatically and objectively screen whether the fundus has DR. Based on deep learning, we proposes an improved residual-dense module convolutional neural network structure (Modified Residual Dense Block Convolution Neural Network, MRDB-CNN). DR fundus images and non-DR fundus images are used for model training and the overall accuracy of the network structure is assessed by test set. Experiments have proved that the module can extract the detailed features of the fundus DR. The MRDB-CNN network structure can obtain a better generalization ability and a higher-precision network classification model while avoiding the complex image preprocessing. The accuracy of DR discrimination reached 94.90%, which reaches the needs of initial screening of fundus DR in hospital treatment and telemedicine. © 2021 ACM.","Convolution; Convolutional neural networks; Deep learning; Diagnosis; Hospitals; Image enhancement; Ophthalmology; Patient treatment; Telemedicine, Convolution neural network; Deep learning; Diabetic retinopathy; Expert analysis; Fundus camera; Fundus diabetic retinopathy discrimination; Fundus image; Modified residual dense block convolution neural network; Network structures; Retinal image, Eye protection"
"García-Ordás MT,Benavides C,Benítez-Andrades JA,Alaiz-Moretón H,García-Rodríguez I",Diabetes detection using deep learning techniques with oversampling and feature augmentation,2021,"Background and objective: Diabetes is a chronic pathology which is affecting more and more people over the years. It gives rise to a large number of deaths each year. Furthermore, many people living with the disease do not realize the seriousness of their health status early enough. Late diagnosis brings about numerous health problems and a large number of deaths each year so the development of methods for the early diagnosis of this pathology is essential. Methods: In this paper, a pipeline based on deep learning techniques is proposed to predict diabetic people. It includes data augmentation using a variational autoencoder (VAE), feature augmentation using an sparse autoencoder (SAE) and a convolutional neural network for classification. Pima Indians Diabetes Database, which takes into account information on the patients such as the number of pregnancies, glucose or insulin level, blood pressure or age, has been evaluated. Results: A 92.31% of accuracy was obtained when CNN classifier is trained jointly the SAE for featuring augmentation over a well balanced dataset. This means an increment of 3.17% of accuracy with respect the state-of-the-art. Conclusions: Using a full deep learning pipeline for data preprocessing and classification has demonstrate to be very promising in the diabetes detection field outperforming the state-of-the-art proposals. © 2021 Elsevier B.V.","Blood pressure; Classification (of information); Convolutional neural networks; Diagnosis; Learning systems; Pathology; Pipelines, Data augmentation; Data preprocessing; Diabetes detection; Early diagnosis; Health status; Learning techniques; Over sampling; State of the art, Deep learning, glucose; insulin, age; Article; blood pressure; convolutional neural network; data accuracy; decision tree; deep learning; diabetes mellitus; feature extraction; glucose level; human; Indian; insulin level; k nearest neighbor; multilayer perceptron; oversampling; prediction; pregnancy; random forest; sparse autoencoder; support vector machine; variational autoencoder; factual database, Databases, Factual; Deep Learning; Diabetes Mellitus; Humans; Neural Networks, Computer"
"Anishfathima B,Gautham P,Gowri Mahalakshmi B,Jahangir Jamadar SK",Smart Architecture for Diabetic Patients Using Machine Learning,2021,"Because of its constantly expanding event, an increasing number of Diabetes mellitus infected households. Nearly all diabetic patients care little about their quality of prosperity or the risk factors that they face when examining them. In this evaluation, we suggested a novel paradigm for predicting type 2 diabetes mellitus subject to data mining techniques (T2DM). The major challenges we are trying to solve are enhancing the consistency of the Figure model, and to make more than one dataset adaptable to the model. The model is comprised of two regions, the enhanced SMO with RF estimation, given the movement of preprocessing systems. To learn about our findings and the findings of other researchers, the Dataset from PIMA Indians Dataset for Diabetes study and the Waikato Setting for Knowledge Analysis instrument compartment were utilized. Results reveals that a 3.04 percent higher conjecture accuracy was reached by the model than those of different scientists. Also, our model makes sure that the accuracy of the dataset is adequate. We extended it to two other diabetes datasets to better test the introduction of our model. The two examinations' outcomes show acceptable execution. Subsequently, the model is demonstrated to be helpful for the reasonable wellbeing the executives of diabetes. © 2021 IEEE.","Machine learning, Diabetes mellitus; Diabetic patient; Knowledge analysis; Predicting types; Preprocessing systems; Risk factors; Smart architectures; Wellbeing, Data mining"
"Zaman SM,Paul SK,Paul RR,Hamid ME",Detecting Diabetes in Human Body using Different Machine Learning Techniques,2021,"One of the most widespread and chronic diseases in our world today is diabetes. Human suffers from an increased amount of blood glucose in the body caused due to inadequate insulin production. Early detection of diabetes is thus now become a must to combat and take preventive actions against the potential risks of this disease. In this paper, we present a methodology for the classification of diabetics using different machine learning models (Decision Tree, K-Nearest Neighbors, Naïve Bayes, Random Forest) to analyze diabetes patients and detect diabetes in human bodies. The proposed methodology is evaluated on Diabetes Dataset namely Pima Indians Diabetes (PIMA) Dataset. Initially, we apply the different preprocessing techniques to prepare data for the experiment. The extracted training data are passed through each model. For measuring the performance of the classifiers, we apply the measurements of sensitivity, precision, f1-score, and overall accuracy. However, in the experiment, we see that the Random Forest model is achieved the highest score with an accuracy of 86%. We hope that these classification techniques as per our study can be combined with real-time data with the help of the 'Internet of Things' to make real-time devices for health care applications. © 2021 IEEE.","Classification (of information); Decision trees; Machine learning; Nearest neighbor search, Blood glucose; Chronic disease; Human bodies; Machine learning models; Machine learning techniques; Machine-learning; Modeling (decision tree); PIMA dataset; Potential risks; Preventive action, Insulin"
"Monteiro CA,De Paula Neto FM",Diabetes Prediction Using Quantum Neurons with Preprocessing Based on Hypercomplex Numbers,2021,"The use of properties that are intrinsic to quantum mechanics has made it possible to build quantum algorithms with greater efficiency than classical algorithms to solve problems whose classically efficient solution either does not exist or is not known. There are quantum neurons that can carry an exponential amount of information to a linear number of quantum information units (qubits) using the quantum property of superposition. In this paper, we compare the performance of three of these quantum neuron models applied to the diabetes classification problem. We also propose the use of different data preprocessing strategies. Quantum neurons were simulated using the IBM Qiskit tool. We compare the preprocessing approaches applied to two toy problems (1) simulating the XOR operator and (2) solving a generic nonlinear problem. The results of the experiments shows that a single quantum neuron is capable of achieving an accuracy rate of 100% in the XOR problem and an accuracy rate of 100% in a non-linear dataset, demonstrating that the quantum neurons with real weights are capable of modeling non-linearly separable problems. In the problem of diagnosing diabetes, quantum neurons achieved an accuracy rate of 76% and AUC-ROC of 88%, while its classic version, the perceptron, reached only 63% accuracy and the artificial neural network reached 80% AUC-ROC. These results indicate that a single quantum neuron performs better than its classical version and even the artificial neural network for AUC-ROC, demonstrating potential for use in healthcare applications in the near future. © 2021 IEEE.","Learning algorithms; Machine learning; Neural networks; Neurons; Quantum efficiency; Quantum optics, Accuracy rate; Diabetes prediction; Hypercomplex number; Machine-learning; Quantum Computing; Quantum machine learning; Quantum machines; Quantum neuron; Single quantum, Health care"
"Jian Y,Pasquier M,Sagahyroon A,Aloul F",Using Machine Learning to Predict Diabetes Complications,2021,"Diabetes Mellitus (DM) is a chronic disease that is considered to be life threatening. It can affect any part of the body over time, resulting in more serious complications such as Dyslipidemia, Neuropathy and Retinopathy. In this work, different supervised classification algorithms were applied to build several models to predict and diagnose eight diabetes complications. The complications include: Metabolic Syndrome, Dyslipidemia, Neuropathy, Nephropathy, Diabetic Foot, Hypertension, Obesity, and Retinopathy. For this study, a dataset collected by the Rashid Centre for Diabetes and Research (RCDR) located in Ajman, UAE, was utilized. The dataset contains 884 records with 79 features. Some essential preprocessing steps were applied to handle the missing values and unbalanced data problems. Multiple solutions were tested and evaluated. © 2021 IEEE.","Eye protection; Supervised learning, Chronic disease; Classification algorithm; Diabetes complication; Diabetes mellitus; Diabetes prediction; Diabetic retinopathy; Dyslipidemias; Machine-learning; Metabolic syndromes; Supervised classification, Forecasting"
"Swain D,Bijawe SS,Akolkar PP,Shinde A,Mahajani MV",Diabetic retinopathy using image processing and deep learning,2021,"Diabetic retinopathy is one of the most non-uniform and confront regions to diagnose as it is exceptionally perplexing. In the circle of retinopathy, the number of times intensive assessments are required to be done to determine upon the diabetes mellitus or blindness that patient might be facing. Various professionals may take different amount of time to recognise diabetic retinopathy. So, a framework is required that can effectively and precisely analyse the retinal conditions with no of such limitations. This paper presents a two- stage method to effectively predict the level grading of diabetic retinopathy. The first stage involves preprocessing the retinal image and reducing the noise from an image. The second stage involves building a convolutional neural network architecture for predicting diabetic retinopathy level. It is a hurdle of diabetes that can affect the retinal nervous and lead to total or partial loss of vision. © 2021 Inderscience Enterprises Ltd.","Convolution; Convolutional neural networks; Deep learning; Diagnosis; Eye protection; Grading; Image processing; K-means clustering; Network architecture; Ophthalmology, CNN; Convolutional neural network; Deep learning; Diabetic retinopathy; Disease diagnosis; Gaussian blur; Gaussian blur filter; Images processing; K-means++ clustering; Machine intervention; Softmax, Gabor filters"
"Umasha HE,Ranaweera RD,Wijayakulasooriya JV",A Customized Preprocessing Framework for Ayurvedic Nadi Signals,2021,"Nadi pulse sensed at the radial artery of a human wrist is a rich source of information not just on the heart but also on many internal organs, hence being ideal for disease diagnosis. Still, it easily gets distorted by many noise artifacts from physiological movements, noise added by hardware circuitry used in the signal acquisition, and other electromagnetic interference in the surrounding. Thus, it is essential to develop a preprocessing framework that can effectively remove these artifacts prior to signal analysis. In this paper, we propose an efficient and effective five-stage preprocessing method for Nadi. Then using the features extracted from preprocessed Nadi, an experiment on diabetes diagnosis gave 88.9 % accuracy proving the proposed preprocessing method to be effective on Nadi. © 2021 IEEE.","Diagnosis; Signal processing, Diabetes diagnosis; Disease diagnosis; Internal organs; Nadi; Pre-processing method; Preprocessing; Pulse segmentation; Radial artery; Sources of informations; Wrist pulse, Electromagnetic pulse"
"Paradisa RH,Bustamam A,Victor AA,Yudantha AR,Sarwinda D",Diabetic Retinopathy Detection using Deep Convolutional Neural Network with Visualization of Guided Grad-CA,2021,"One of the complications of diabetes that represents a serious threat to world health is Diabetic Retinopathy (DR). High blood sugar levels in people with diabetes can damage the blood vessels in the retina and causing blindness. DR can be detected by examining the fundus image by an ophthalmologist. However, the limited number of ophthalmologists who can analyze fundus image is an obstacle because the number of DR sufferers continues to increase. Therefore, an automated system is needed to help doctors diagnose the disease. Researchers have developed deep learning techniques as Artificial Intelligence (AI) approach to finding DR in fundus images. In this research, we use the Deep Convolutional Neural Networks method with InceptionV3 structure and various optimizers such as the Stochastic Gradient Descent with Momentum (SGDM), Root Mean Square Propagation (RMSprop), and Adaptive Moment Estimation (Adam). The fundus image dataset previously through the augmentation and preprocessing steps to make it easier for the model to recognize the image. The InceptionV3 model with the Adam optimizer gave the best results in detecting DR lesions from the Kaggle dataset with 96% accuracy. This paper also presents a Grad-CAM guided activation map that can describe the position of the suspicious lesion to explain the results of DR detection. © 2021 IEEE.","Backpropagation; Blood vessels; Convolution; Convolutional neural networks; Eye protection; Gradient methods; Health risks; Image segmentation; Optimization; Stochastic systems, Automated systems; Blood sugar levels; Diabetic retinopathy; Fundus image; Guided grad-cam; Learning techniques; Moment estimation; Neural network method; Optimizers; Stochastic gradient descent, Deep neural networks"
"Sagi SL,Narsapuram M,Nakarikanti P,Sane S,Vadisina SS,Uddagiri C",Comparative Analysis of Data Preparation Methods Employed in Prediction of Diabetes Mellitus Diagnosis using eICU-CRD Dataset,2021,"In any classification system it's necessary to preprocess the source data in order to draw useful insights. In this paper, two different preprocessing approaches on WiDS Datathon 2021 Data were compared and analyzed deeply to account for the difference between resultant prediction accuracies.A comparative analysis was conducted on the preprocessing steps of both the approaches The steps applied are but not limited to - handling missing values, Feature scaling, Standardization, etc. in the process of determining whether a patient has been diagnosed with Diabetes Mellitus before. The readings in the first 24 hours from the patient's stay in ICU were used here and all the readings were acquired through invasive and noninvasive methods. LightGBM Classifier was used for the purpose of classifying the target variable.An attempt to determine the probability that a patient who is admitted to an ICU has been diagnosed with Diabetes Mellitus was made using two approaches with different machine learning pipelines. The first pipeline resulted in an accuracy score of 0.87242 and the second one gave a score of 0.86471. The boosting algorithms used in both the methods were the same but due to the differences in the missing values handling techniques and feature engineering steps, their prediction accuracies were different. © 2021 IEEE.","Classification (of information); Computer aided diagnosis; Forecasting; Pipelines, Analysis of data; Comparative analyzes; Cross validation; Data preprocessing; Diabetes mellitus; EICU-CRD dataset; Feature engineerings; Lightgbm classifier; MIT GOSSIS; Prediction accuracy, Noninvasive medical procedures"
"Kibria HB,Matin A,Jahan N,Islam S",A Comparative Study with Different Machine Learning Algorithms for Diabetes Disease Prediction,2021,"Diabetic is a disease that occurred when the level of blood glucose is higher than usual, which is also known as hyperglycemia. When the human body is incapable of producing enough insulin(a hormone that produces glucose from food), then this situation leads to diabetes. The rapid increase of this disease makes the researchers work much harder in this area to build a model for diagnosing diabetes efficiently. As in healthcare, the availability of data is high, so it is easy to extract information from those data to diagnose disease and develop a new model for better results. This paper aims to introduce a model that can predict diabetes efficiently with the help of machine learning algorithms. Here logistic regression, SVM, and k nearest neighbor algorithms have been used for the classification of diabetics. After data preprocessing and training, those algorithms gave a good result. Logistic regression provided the best accuracy of 83% for test data. Also, SVM and knn both performed well and showed an accuracy of 82% and 79%, respectively. The proposed model has demonstrated improved results compared with previous work. © 2021 IEEE.","Diagnosis; Glucose; Learning algorithms; Logistic regression; Motion compensation; Nearest neighbor search, Blood glucose; Comparatives studies; Diagnose disease; Extract informations; Human bodies; Hyperglycaemia; K near neighbor; Machine learning algorithms; Nearest-neighbour; Support vectors machine, Support vector machines"
"Rivera MA,Carpio JT,Vinluan AA",Identifying Latent Classes of Non-Communicable Disease Comorbidities in Clinical Laboratory Data,2021,"Non-communicable diseases (NCDs) make up 7 of the world's top 10 causes of mortality. Detecting these diseases in patient populations can allow early intervention, prevention, and management. This study is a work-in-progress that intends to identify latent classes of potential NCD comorbidities without other clinical criteria by detecting patterns in clinical laboratory data. The latent classes will be determined using Latent Class Analysis (LCA). The first phase included data extraction and preprocessing. The second phase will consist of model selection and evaluation and system development. Log-likelihood, Bayesian Information Criterion (BIC), and Akaike Information Criterion (AIC)) fit measures will be used in model selection. Model evaluation will use posterior probability and entropy scores. The chosen model will be used in a system to help identify comorbidity patterns in new patient records. Preliminary experiments on a model selection with diabetes mellitus (DM) indicators revealed three distinct latent classes, wherein one of the classes indicated its presence. The researchers hope that primary care physicians and local government health centers could use this system to tailor comorbidity treatment and management programs for their patients. Future work includes the integration of this study's results into a customized laboratory information system. © 2021 IEEE.","Clustering algorithms; Diseases; Epidemiology, Clinical laboratory data; Clusterings; Comorbidities; Laboratory datum; Latent class; Latent class analysis; Model evaluation; Model Selection; Non-communicable disease, Patient treatment"
"Karimah S,Setiawan EB,Kurniawan I",Implementation of Random Forest in Classification Model of Diabetes Prediction based on Drug Review Content,2021,"Diabetes is a disease that causes abnormally high glucose levels in the blood and is considered the main factor of damage to blood vessels. This disease can affect the heart, eyes, kidneys, and nerves and cause various complications. The risks of diabetes can be reduced with proper treatment in the early stage. Early identification of diabetes can be made by implementing a machine learning model to predict or diagnose diabetes. In this study, we utilized Random Forest (RF) to develop a classification model to predict people with diabetes. Random Forest is known as an ensemble method that combines the prediction of each basic model. The model development was performed by using drug reviews content retrieved from the UCI Machine Learning repository. The data set consists of the review and confirmed patient condition. We performed preprocessing step to obtain the important feature from the text. Then the feature extraction was done by using N-gram and term frequency-inverse document frequency (TF-IDF). We utilized six N-gram methods, i.e., unigram, bigram, trigram, unigram-bigram, bigram-trigram, and unigram-big ram-trigram. The best result of the experiments is obtained from the model developed by using a unigram feature with F-1 score is 0.952. © 2021 IEEE.","Blood; Blood vessels; Forecasting; Inverse problems; Machine learning; Random forests; Text processing, Bigrams; Classification models; Glucose level; High glucose; N-grams; Prediction-based; Random forests; Review contents; Term frequencyinverse document frequency (TF-IDF); Tri grams, Decision trees"
"Gupta S,Namdev U,Gupta V,Chheda V,Bhowmick K","Data-driven Preprocessing Techniques for Early Diagnosis of Diabetes, Heart and Liver Diseases",2021,"The emergence of machine learning in medicine has revolutionized the entire procedure of detecting and treating ailments. For knowledge extraction and decision support, machine learning models have been adapted in healthcare research. The significance of data preprocessing is often overlooked in mainstream health informatics research, which focuses more on generating accurate models. This paper focuses on building robust classification models for the prediction of diabetes, heart, and liver disease using a variety of preprocessing techniques to achieve optimal results. The implementation of the models is carried out on datasets sourced from the University of California, Irvine (UCI) Machine Learning Repository. Numerous preprocessing techniques such as feature engineering, data pruning, oversampling for skewed datasets, imputation of missing values, encoding categorical variables, and feature scaling are used in this paper. These techniques help considerably augment the performance of the classification algorithms used, which include Random Forest, K-Nearest Neighbours (KNN), and Support Vector Machine (SVM) among others. The performance of these algorithms is further improved by hyperparameter tuning, significantly improving the accuracy scores. The maximum accuracies obtained for heart disease, liver disease and diabetes prediction are 90.16%, 73% and 93.23% respectively. The paper also showcases the advantages of detection of these diseases at an early stage, which could make a substantial difference in numerous cases. The performance of different classifiers has been documented using metrics such as Accuracy, Balanced Accuracy, and F-1 score. Further visualization and comparison of the performance of the classification algorithms are carried out to find the best results. © 2021 IEEE.","Cardiology; Computer aided diagnosis; Decision support systems; Diseases; Heart; Medical informatics; Nearest neighbor search; Support vector machines, Classification algorithm; Data driven; Data preprocessing; Disease classification; Early diagnosis; Heart disease; Liver disease; Machine-learning; Performance; Pre-processing techniques, Decision trees"
"Al-Moosawi NM,Khudeyer RS",ResNet-34/DR: A Residual Convolutional Neural Network for the Diagnosis of Diabetic Retinopathy,2021,"Diabetic retinopathy (DR) is an eye complication associated with diabetes, resulting in blurred vision or blindness. The early diagnosis and treatment of DR can decrease the risk of vision loss dramatically. However, such diagnosis is a tedious and complicated task due to the variability of retinal changes across the stages of the diseases, and due to the high number of undiagnosed and untreated DR cases. In this paper, we develop a computationally efficient and scalable deep learning model using convolutional neural networks (CNN), for diagnosing DR automatically. Various preprocessing algorithms are utilized to improve accuracy, and a transfer learning strategy is adopted to speed up the process. Our experiment used the fundus image set available on online Kaggle datasets. As an ultimate conclusion of applicable performance metrics, our computational simulation achieved a relatively-high F1 score of 93.2% for stage-based DR classification. © 2021 Slovene Society Informatika. All rights reserved.","Convolution; Convolutional neural networks; Deep learning; Diagnosis; Transfer learning, Convolutional neural network; Deep learning; Diabetic retinopathy; Early diagnosis; Resnet-34; Transfer learning; Vision loss, Eye protection"
"Shen Q,Wang L",Machine Learning-Based Gynecologic Tumor Diagnosis and Its Postoperative Incisional Infection Influence Factor Analysis,2021,"Various factors influencing postoperative incisional infection in gynecologic tumors were analyzed, and the value of quality nursing intervention was studied. In this study, 74 surgically treated gynecologic tumor patients were randomly selected from within the hospital as the study population and were divided into study and control groups. For this purpose, the whole-group random sampling method is utilized to compare the postoperative incisional infection rates of the two groups, analyze their influencing factors, and develop quality nursing interventions. In this paper, a breast cancer diagnosis prediction model was developed by combining the self-attentive mechanism. The preprocessing work such as data quantification and normalization was performed first which is followed by adding the preprocessed data to the self-attentive mechanism. This model has solved the problem that recurrent neural networks (RNNs) could not extract and calculate the features at the same time. Likewise, it has solved the drawback that the RNN could not consider global features at the same time when extracting the features, and then, the feature matrix extracted by the self-attentive mechanism was added to the adaptive neural network. The adaptive neural network model for breast cancer diagnosis prediction was constructed and, finally, relevant parameters of the adaptive neural network model were adjusted according to different tasks to make the model performance optimal. Experimental results showed that the postoperative incision infection rate of patients in the study group was 2.70%, which was significantly lower than that of 21.62% in the control group (P<0.05). Likewise, operation time, operation method, hospitalization time, preoperative fever, diabetes mellitus, and anemia were the main influencing factors of postoperative incision infection in women with gynecologic tumors. The time of surgery, surgical method, long hospital stay, preoperative fever, diabetes, and anemia are the main factors that lead to postoperative incisional infection in female gynecologic tumor patients. © 2021 Qian Shen and Ling Wang.","Diagnosis; Diseases; Nursing; Recurrent neural networks; Surgery; Tumors, Adaptive neural network models; Breast cancer diagnosis; Control groups; Gynecologic tumors; Infection rates; Machine-learning; Nursing interventions; Study Groups; Tumor diagnosis; Tumor patient, Hospitals, anemia; Article; artificial neural network; breast cancer; cancer surgery; data mining; diabetes mellitus; diagnostic accuracy; female genital tract tumor; fever; hospitalization; human; incisional hernia; infection rate; length of stay; machine learning; natural language processing; operation duration; Parkinson disease; postoperative care; receiver operating characteristic; recurrent neural network; support vector machine; tumor diagnosis; controlled study; factor analysis; female; female genital tract tumor; machine learning; randomized controlled trial; retrospective study; surgical infection, Factor Analysis, Statistical; Female; Genital Neoplasms, Female; Humans; Machine Learning; Retrospective Studies; Surgical Wound Infection"
"Adelberger D,Reiterer F,Schrangl P,Ringemann C,Huschto T,Re LD",Prediction of postprandial glucose excursions in type 1 diabetes using control-oriented process models,2021,"Reliable prediction of future blood glucose (BG) values is of high relevance for diabetes patients, since it enables the use of predictive glucose alarms (warning the patient about impending situations with dangerously low or high BG), as well as of model-based algorithms for smart glucose control. Control-oriented graybox process models have proven very suitable for such tasks, especially when identified on data from clinical trials under well-defined conditions. The current paper analyzes how such models can also be reliably parametrized using outpatient data of patients on multiple daily injection (MDI) therapy. A dedicated preprocessing algorithm is presented to look for suitable (i.e. complete and sensible) data segments that allow for a reliable system identification. The focus of the current paper is on the prediction of postprandial glucose trajectories, more specifically on predictions made exactly at the time of meal ingestion. This corresponds to a particularly challenging task, but one with high importance for the model-based optimization of insulin doses. It is demonstrated that the identified process models are a suitable choice for predicting such postprandial glucose excursions. © 2021 The Authors.","Glucose; Patient treatment; Process control, 'current; Blood glucose; Diabetes patients; Gray-box models; Grey-box models; Identification; Oriented process; Process-models; Type 1 diabetes; Validation, Forecasting"
"Bernardini M,Romeo L,Mancini A,Frontoni E",A Clinical Decision Support System to Stratify the Temporal Risk of Diabetic Retinopathy,2021,"Diabetic Retinopathy (DR) is the most common and insidious microvascular complication of diabetes, and can progress asymptomatically until a sudden loss of vision occurs. Although DR is prevalent nowadays, its prevention remains challenging. The multiple aim of this study was to predict the risk of developing DR as diabetic complication (task 1) and, subsequently, temporally stratify the DR risk (task 2) using electronic health records data. To perform these objectives, a novel preprocessing procedure was designed to select both control and pathological patients, and moreover, a novel fully annotated/standardized 120K dataset from multiple diabetologic centers was provided. Globally, although the Extreme Gradient Boosting model offers satisfying predictive performance, the Random Forest model obtained the best predictive performance to solve task 1 and task 2, reaching the best Area Under the Precision-Recall Curve of 72.43 % and 84.38 %, respectively. Also the features importance extracted from the best Machine Learning (ML) models is provided. The proposed Artificial Intelligence-based solution was proven to be capable of generalizing across different diabetologic centers while ensuring high-interpretability. Moreover, the proposed ML solution is currently being adopted as a Clinical Decision Support System in several diabetologic centers for DR screening and follow-up purposes. © 2013 IEEE.","Decision support systems; Decision trees; Diagnosis; E-learning; Health risks; Machine learning; Records management; Risk assessment, Clinical decision support systems; Code; Diabetic retinopathy; Gradient boosting; Machine-learning; Microvascular; Predictive medicine; Predictive models; Predictive performance; Task analysis, Eye protection"
"Sumathi A,Meganathan S,Ravisankar BV",An Intelligent Gestational Diabetes Diagnosis Model Using Deep Stacked Autoencoder,2021,"Gestational Diabetes Mellitus (GDM) is one of the commonly occurring diseases among women during pregnancy. Oral Glucose Tolerance Test (OGTT) is followed universally in the diagnosis of GDM diagnosis at early pregnancy which is costly and ineffective. So, there is a need to design an effective and automated GDMdiagnosis and classification model. The recent developments in the field of Deep Learning (DL) are useful in diagnosing different diseases. In this view, the current research article presents a new outlier detection with deep-stacked Autoencoder (OD-DSAE) model forGDMdiagnosis and classification. The goal of the proposed OD-DSAE model is to find out those mothers with high risks and make them undergo earlier diagnosis, monitoring, and treatment compared to low-risk women. The presented ODDSAE model involves three major processes namely, preprocessing, outlier detection, and classification. In the first step i.e., data preprocessing, there exists three stages namely, format conversion, class labelling, andmissing value replacement using k-nearest neighbors (KNN) model. Outliers are superior values which considerably varies from other data observations. So, it might represent the variability in measurement, experimental errors or novelty too. So, Hierarchical Clustering (HC)-based outlier detection technique is incorporated in OD-DSAE model, and thereby classification performance can be improved. The proposed model was simulated using Python 3.6.5 on a dataset collected by the researcher themselves. A series of experiments was conducted and the results were investigated under different aspects. The experimental outcomes inferred that the OD-DSAE model has outperformed the compared methods and achieved high precision of 96.17%, recall of 98.69%, specificity of 89.50%, accuracy of 96.18%, and F-score of 97.41%. © 2021 Tech Science Press. All rights reserved.","Anomaly detection; Classification (of information); Computer aided diagnosis; Computer software; Data handling; Deep learning; Nearest neighbor search; Statistics, Auto encoders; Data classification; Deep learning; Diabetes diagnosis; Diabetes mellitus; Gestational diabetes; Gestational diabetes mellitu; Hier-archical clustering; Hierarchical Clustering; Outlier Detection, Obstetrics"
"Annamalai R,Nedunchelian R",Diabetes Mellitus Prediction and Severity Level Estimation Using OWDANN Algorithm,2021,"Today, diabetes is one of the most prevalent, chronic, and deadly diseases in the world owing to some complications. If accurate early diagnosis is feasible, the risk factor and incidence of diabetes may be greatly decreased. Diabetes prediction is stable and reliable, since there are only minimal labelling evidence and outliers found in the datasets of diabetes. Numerous works coped with diabetes disease prediction and provided the solution. But the existing methods proffered low accuracy detection and consumed more training time. So, this paper proposed an OWDANN algorithm for diabetes mellitus disease prediction and severity level estimation. The proposed system mainly consists of two phases, namely, disease prediction and severity level estimation phase. In the disease prediction phase, the preprocessing is performed for the Pima dataset. Then, the features are extracted from the preprocessed data, and finally, the classification step is performed by using OWDANN. In the severity level estimation phase, the diabetes positive dataset is preprocessed first. Then, the features are extracted, and lastly, the severity level is predicted using GDHC. The extensive experimental results showed that the proposed system outperforms with 98.97% accuracy, 94.98% sensitivity, 95.62% specificity, 97.02% precision, 93.84% recall, 9404% f-measure, 0.094% FDR, and 0.023% FPR compared with the state-of-the-art methods. © 2021 Annamalai R and Nedunchelian R.","Forecasting, Diabetes mellitus; Early diagnosis; F measure; Pre-processed data; Risk factors; State-of-the-art methods; Training time, Diagnosis"
"Ramadhan NG,Adiwijaya,Romadhony A",Preprocessing Handling to Enhance Detection of Type 2 Diabetes Mellitus based on Random Forest,2021,"Diabetes is a non-communicable disease that has a death rate of 70% in the world. Majority of diabetes cases, 90–95%, are of diabetes cases are type 2 diabetes which is caused by an unhealthy lifestyle. Type 2 diabetes can be detected earlier by using examination that contains diabetes-related parameters. However, the dataset does not always contain complete information, the distribution between positive and negative classes is mostly imbalanced, and some parameters have low importance to the decision class. To overcome the problems, this study needs to carry out preprocessing to improve detection precision and recall. In this paper, propose an approach on dataset preprocessing, which is applied to diabetes prediction. The preprocessing approach consists of the following process: missing value process, imbalanced data process, feature importance process, and data augmentation process. The data preprocessing process uses the median for missing value, random oversampling for imbalanced data, the Gini score in the random forest for feature importance, and posterior distribution for data augmentation. This research used random forest and logistic regression as classification algorithms. The experimental results show that the classification increased by 20% precision and 24% recall by applying proposed method and random forest method compared to without proposed method and random forest method. © 2021. All Rights Reserved.","Logistic regression; Random forests, Data augmentation; Data preprocessing; Diabetes mellitus; Imbalanced data; Missing values; Non-communicable disease; Random forest methods; Random forests; Type 2 diabetes mellitus; Type-2 diabetes, Decision trees"
"Chowdary PB,Kumar R.U D",An Effective Approach for Detecting Diabetes using Deep Learning Techniques based on Convolutional LSTM Networks,2021,"The most common disorder affecting millions of population worldwide due to insufficient release of insulin by pancreas is diabetes. Early detection or precaution of diabetes is necessary, otherwise leads to many complicated problems. Predicting diabetes at early stages with appropriate treatment, individuals can maintain a happy life. If the conventional diabetes detection method is tedious, the identification of diabetes from clinical and physical data requires an automated system. This paper proposes an approach to enhance diabetes prediction using deep learning techniques. Based on the Convolutional Long Short-term Memory (CLSTM), we developed a diabetes classification model and compared with the existing methods on the Pima Indians Diabetes Database (PIDD). We assessed the findings of various classification approaches in this study. The proposed approach is further improved by an efficient preprocessing mechanism called multivariate imputation by chained equations. The outcomes are promising compared to existing machine learning approaches and other research models. © 2021","Automation; Brain; Classification (of information); Convolution; Convolutional neural networks; Forecasting; Learning algorithms, Automated systems; Clinical data; Convolutional long short-term memory; Detection methods; Diabetes detection; Diabetes prediction; Effective approaches; Learning techniques; Physical data; Pre-processing, Long short-term memory"
"Jiang K,Shang Y,Wang L,Zhang Z,Zhou S,Dong J,Wu H",A framework for meaningful use of clinical decision model: A diabetic nephropathy prediction modeling based on real world data,2021,"This study aims to propose a framework for developing a sharable predictive model of diabetic nephropathy (DN) to improve the clinical efficiency of automatic DN detection in data intensive clinical scenario. Different classifiers have been developed for early detection, while the heterogeneity of data makes meaningful use of such developed models difficult. Decision tree (DT) and random forest (RF) were adopted as training classifiers in de-identified electronic medical record dataset from 6,745 patients with diabetes. After model construction, the obtained classification rules from classifier were coded in a standard PMML file. A total of 39 clinical features from 2159 labeled patients were included as risk factors in DN prediction after data preprocessing. The mean testing accuracy of the DT classifier was 0.8, which was consistent to that of the RF classifier (0.823). The DT classifier was choose to recode as a set of operable rules in PMML file that could be transferred and shared, which indicates the proposed framework of constructing a sharable prediction model via PMML is feasible and will promote the interoperability of trained classifiers among different institutions, thus achieving meaningful use of clinical decision making. This study will be applied to multiple sites to further verify feasibility. © 2021 - IOS Press. All rights reserved.","Classification (of information); Decision making; Decision trees; Diseases; Forecasting; Medical computing, Classification rules; Clinical decision making; Clinical efficiency; Data preprocessing; Diabetic nephropathy; Electronic medical record; Model construction; Predictive modeling, Predictive analytics"
"Gurcan OF,Beyca OF,Dogan O",A comprehensive study of machine learning methods on diabetic retinopathy classification,2021,"Diabetes is one of the emerging threats to public health all over the world. According to projections by the World Health Organization, diabetes will be the seventh foremost cause of death in 2030 (WHO, Diabetes, 2020. https://www.afro.who.int/healthtopics/diabetes). Diabetic retinopathy (DR) results from long-lasting diabetes and is the fifth leading cause of visual impairment, worldwide. Early diagnosis and treatment processes are critical to overcoming this disease. The diagnostic procedure is challenging, especially in low-resource settings, or time-consuming, depending on the ophthalmologist’s experience. Recently, automated systems now address DR classification tasks. This study proposes an automated DR classification system based on preprocessing, feature extraction, and classification steps using deep convolutional neural network (CNN) and machine learning methods. Features are extracted from a pretrained model by the transfer learning approach. DR images are classified by several machine learning methods. XGBoost outperforms other methods. Dimensionality reduction algorithms are applied to obtain a lowerdimensional representation of extracted features. The proposed model is trained and evaluated on a publicly available dataset. Grid search and calibration are used in the analysis. This study provides researchers with performance comparisons of different machine learning methods. The proposed model offers a robust solution for detecting DR with a small number of images. We used a transfer learning approach, which differs from other studies in the literature, during the feature extraction. It provides a data-driven, cost-effective solution, which includes comprehensive preprocessing and fine-tuning processes. © 2021 The Authors. Published by Atlantis Press B.V.","Automation; Classification (of information); Convolutional neural networks; Cost effectiveness; Deep neural networks; Diagnosis; Dimensionality reduction; Extraction; Eye protection; Feature extraction; Health risks; Transfer learning, Classification system; Cost-effective solutions; Diagnostic procedure; Dimensionality reduction algorithms; Low-resource settings; Machine learning methods; Performance comparison; World Health Organization, Learning systems"
"Mansour RF,Amraoui AE,Nouaouri I,DIaz VG,Gupta D,Kumar S",Artificial Intelligence and Internet of Things Enabled Disease Diagnosis Model for Smart Healthcare Systems,2021,"The recent advancements in Internet of Things (IoT), cloud computing, and Artificial Intelligence (AI) transformed the conventional healthcare system into smart healthcare. By incorporating key technologies such as IoT and AI, medical services can be improved. The convergence of IoT and AI offers different opportunities in healthcare sector. In this view, the current research article presents a new AI and IoT convergence-based disease diagnosis model for smart healthcare system. The major goal of this article is to design a disease diagnosis model for heart disease and diabetes using AI and IoT convergence techniques. The presented model encompasses different stages namely, data acquisition, preprocessing, classification, and parameter tuning. IoT devices such as wearables and sensors permit seamless data collection while AI techniques utilize the data in disease diagnosis. The proposed method uses Crow Search Optimization algorithm-based Cascaded Long Short Term Memory (CSO-CLSTM) model for disease diagnosis. In order to achieve better classification of the medical data, CSO is applied to tune both 'weights' and 'bias' parameters of CLSTM model. Besides, isolation Forest (iForest) technique is employed in this research work to remove the outliers. The application of CSO helps in considerable improvement in the diagnostic outcomes of CLSTM model. The performance of CSO-LSTM model was validated using healthcare data. During the experimentation, the presented CSO-LSTM model accomplished the maximum accuracies of 96.16% and 97.26% in diagnosing heart disease and diabetes respectively. Therefore, the proposed CSO-LSTM model can be employed as an appropriate disease diagnosis tool for smart healthcare systems. © 2013 IEEE.","Cardiology; Classification (of information); Data acquisition; Diagnosis; Diseases; Health care; Long short-term memory, Disease diagnosis; Health-care system; Healthcare sectors; Internet of Things (IOT); Key technologies; Maximum accuracies; Search optimization; Smart healthcare systems, Internet of things"
"Li X,Zhang J,Safara F",Improving the Accuracy of Diabetes Diagnosis Applications through a Hybrid Feature Selection Algorithm,2021,"Artificial intelligence is a future and valuable tool for early disease recognition and support in patient condition monitoring. It can increase the reliability of the cure and decision making by developing useful systems and algorithms. Healthcare workers, especially nurses and physicians, are overworked due to a massive and unexpected increase in the number of patients during the coronavirus pandemic. In such situations, artificial intelligence techniques could be used to diagnose a patient with life-threatening illnesses. In particular, diseases that increase the risk of hospitalization and death in coronavirus patients, such as high blood pressure, heart disease and diabetes, should be diagnosed at an early stage. This article focuses on diagnosing a diabetic patient through data mining techniques. If we are able to diagnose diabetes in the early stages of the disease, we can force patients to stay home and care for their health, so the risk of being infected with the coronavirus would be reduced. The proposed method has three steps: preprocessing, feature selection and classification. Several combinations of Harmony search algorithm, genetic algorithm, and particle swarm optimization algorithm are examined with K-means for feature selection. The combinations have not examined before for diabetes diagnosis applications. K-nearest neighbor is used for classification of the diabetes dataset. Sensitivity, specificity, and accuracy have been measured to evaluate the results. The results achieved indicate that the proposed method with an accuracy of 91.65% outperformed the results of the earlier methods examined in this article. © 2021, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Artificial intelligence; Blood pressure; Classification (of information); Condition monitoring; Data mining; Decision making; Diseases; Feature extraction; Genetic algorithms; Health risks; Home health care; K-means clustering; Nearest neighbor search; Particle swarm optimization (PSO), Artificial intelligence techniques; Feature selection and classification; Harmony search algorithms; Healthcare workers; High blood pressures; Hybrid feature selections; K-nearest neighbors; Particle swarm optimization algorithm, Diagnosis"
"Sierra-Sosa D,Arcila-Moreno JD,Garcia-Zapirain B,Elmaghraby A",Diabetes Type 2: Poincaré data preprocessing for quantum machine learning,2021,"Quantum Machine Learning (QML) techniques have been recently attracting massive interest. However reported applications usually employ synthetic or well-known datasets. One of these techniques based on using a hybrid approach combining quantum and classic devices is the Variational Quantum Classifier (VQC), which development seems promising.Albeit being largely studied, VQC implementations for real-world datasets are still challenging on Noisy Intermediate Scale Quantum devices (NISQ). In this paper we propose a preprocessing pipeline based on Stokes parameters for data mapping. This pipeline enhances the prediction rates when applying VQC techniques, improving the feasibility of solving classification problems using NISQ devices. By including feature selection techniques and geometrical transformations, enhanced quantum state preparation is achieved.Also, a representation based on the Stokes parameters in the Poincare Sphere is possible for visualizing the data.Our results showthat by using the proposed techniques we improve the classification score for the incidence of acute comorbid diseases in Type 2 Diabetes Mellitus patients. We used the implemented version of VQC available on IBM s framework Qiskit, and obtained with two and three qubits an accuracy of 70% and 72% respectively. © 2021 Tech Science Press. All rights reserved.","Classification (of information); Machine learning; Mathematical transformations; Pipelines; Variational techniques, Data preprocessing; Geometrical transformation; Hybrid approach; Quantum machines; Quantum state preparation; Selection techniques; Stokes parameters; Type 2 diabetes mellitus, Quantum theory"
"Khaled O,ElSahhar M,El-Dine MA,Talaat Y,Hassan YM,Hamdy A",Automatic Classification of Preliminary Diabetic Retinopathy Stages using CNN,2021,"Diabetes Mellitus is one of the modern world’s most prominent and dominant maladies. This condition later on leads to a menacing eye disease called Diabetic Retinopathy (DR). Diabetic Retinopathy is a retinal disease that is caused by high blood sugar levels in the retina, and can naturally progress to irreversible vision loss (blindness). The primary purpose of this imperative research is the early detection and classification of this hazardous condition, to try and prevent any threatening complications in the future. In the course of recent years, Convolutional Neural Networks (CNNs) turned out to be exceptionally famous and fruitful in solving and unraveling image processing and object detection problems for enormous datasets. Throughout this pivotal research, a model was proposed to detect the presence of (DR) and classify it into 5 distinct stages, factoring in an immense and substantial dataset. The model starts by applying preprocessing techniques such as normalization, to maintain the same dimensions for all the images before proceeding to the main processing stage. Furthermore, diverse sampling methods such as “Resize & Crop”, “Rotation”, and “Flipping” have been tested out, so as to pinpoint the best augmentation technique. Finally, the normalized images were fed into a Convolutional Neural Network (CNN), to predict whether a person suffers from DR or not, and classify the level/stage of the disease. The proposed method was utilized on 88,700 retinal fundus images, which are a parcel of the full (EyePACS) dataset, and finally achieved 81.12%, 89.16%, and 84.16% for sensitivity, specificity, and accuracy, respectively. © 2021. All Rights Reserved.","Classification (of information); Convolution; Convolutional neural networks; Image classification; Object detection; Ophthalmology, Automatic classification; Condition; Convolutional neural network; Diabetes mellitus; Diabetic retinopathy; Eye disease; Images processing; Retinal disease, Eye protection"
"Bibi I,Mir J,Raja G",Automated detection of diabetic retinopathy in fundus images using fused features,2020,"Diabetic retinopathy (DR) is one of the severe eye conditions due to diabetes complication which can lead to vision loss if left untreated. In this paper, a computationally simple, yet very effective, DR detection method is proposed. First, a segmentation independent two-stage preprocessing based technique is proposed which can effectively extract DR pathognomonic signs; both bright and red lesions, and blood vessels from the eye fundus image. Then, the performance of Local Binary Patterns (LBP), Local Ternary Patterns (LTP), Dense Scale-Invariant Feature Transform (DSIFT) and Histogram of Oriented Gradients (HOG) as a feature descriptor for fundus images, is thoroughly analyzed. SVM kernel-based classifiers are trained and tested, using a 5-fold cross-validation scheme, on both newly acquired fundus image database from the local hospital and combined database created from the open-sourced available databases. The classification accuracy of 96.6% with 0.964 sensitivity and 0.969 specificity is achieved using a Cubic SVM classifier with LBP and LTP fused features for the local database. More importantly, in out-of-sample testing on the combined database, the model gives an accuracy of 95.21% with a sensitivity of 0.970 and specificity of 0.932. This indicates the proposed model is very well-fitted and generalized which is further corroborated by the presented train-test curves. © 2020, Australasian College of Physical Scientists and Engineers in Medicine.","Blood vessels; Classification (of information); Database systems; Eye protection; Medical imaging; Support vector machines, Automated detection; Classification accuracy; Diabetic retinopathy; Histogram of oriented gradients (HOG); Kernel based classifiers; Local binary patterns; Local ternary patterns (LTP); Scale invariant feature transforms, Image segmentation, Article; automation; contrast enhancement; dense scale invariant feature transform; diabetic retinopathy; histogram of oriented gradient; human; image analysis; image processing; local binary pattern; local ternary pattern; mathematical computing; mathematical model; ophthalmoscopy; process design; sensitivity and specificity; support vector machine; visual system parameters; algorithm; diabetes mellitus; eye fundus; factual database, Algorithms; Databases, Factual; Diabetes Mellitus; Diabetic Retinopathy; Fundus Oculi; Humans"
"Hairani H,Innuddin M,Rahardi M",Accuracy Enhancement of Correlated Naive Bayes Method by Using Correlation Feature Selection (CFS) for Health Data Classification,2020,"The main problem of health datasets is having a lot of data attributes and irrelevant features, so that the computation of the classification method takes more time to solve it. The purpose of this study is to implement the CFS feature selection method to improve the accuracy of the Correlated Naive Bayes method. Therefore, there are some stages used in this study such as: collecting dataset of Pima Indian Diabetes, preprocessing data especially for transformation data, selection of CFS feature, classification, and then performance evaluation based on accuracy. Based on the test results using the 10-fold cross validation method, the best accuracy is about 69.4% compared without feature selection, it is obtained by a combination of Correlated Naive Bayes and CFS methods. Thus, the CFS feature selection method may increase the accuracy of the Correlated Naive Bayes method by 2.25%. © 2020 IEEE.","Barium compounds; Classifiers; Feature extraction; Metadata, 10-fold cross-validation; Accuracy enhancement; Classification methods; Correlation features; Data attributes; Feature selection methods; Health data; Pima Indian Diabetes, Classification (of information)"
"Paradisa RH,Sarwinda D,Bustamam A,Argyadiva T",Classification of Diabetic Retinopathy through Deep Feature Extraction and Classic Machine Learning Approach,2020,"Diabetic Retinopathy (DR) is a complication of diabetes, the leading cause of vision loss in working-age adults. An ophthalmologist can carry out the diagnosis of DR by examining color fundus images. However, the fundus image analysis process takes a long time. Automatic detection of DR is achallenging task. One of the deep learning approaches, Convolutional Neural Networks (CNN), is efficient in image classification tasks. In this research, a CNN architecture is used, namely ResNet-50, as feature extraction and classification. The ResNet-50 feature output at the feature extraction stage is also used as input for machine learning classifiers such as Support Vector Machine (SVM), Random Forest (RF), k-Nearest Neighbor (k-NN), and Extreme Gradient Boosting (XGBoost). The model works by using fundus images from the DIARETDBI dataset. Data augmentation and preprocessing are proposed in this study to facilitate the model in recognizing images. The performance of each classifier is evaluated based on accuracy, sensitivity, and specificity. The SVM classifier achieved 99% for accuracy and sensitivity in the 80:20 dataset composition. The k-NN classifier obtains the highest specificity for the same dataset's design by 100%. © 2020 IEEE.","Adaptive boosting; Convolutional neural networks; Decision trees; Deep learning; Extraction; Eye protection; Feature extraction; Image processing; Learning systems; Nearest neighbor search; Support vector machines; Text processing, Automatic Detection; Data augmentation; Diabetic retinopathy; Feature extraction and classification; Gradient boosting; K-nearest neighbors; Learning approach; Machine learning approaches, Classification (of information)"
"Agustin T,Sunyoto A",Optimization Convolutional Neural Network for Classification Diabetic Retinopathy Severity,2020,"Computer-Aided Diabetic Retinopathy Screening makes it easier for doctors to provide a fast and accurate diagnosis to save the vision of diabetes mellitus patients. Artificial intelligence based on Deep Learning Convolutional Neural Networks is widely used in medical image analysis because it has excellent image recognition capabilities. However, the problem that often arises in the deep learning method is overfitting. To solve this problem, we propose an Ordinary Convolutional Neural Network. Using a dropout regularization technique, data augmentation, and preprocessing before performing the four-stage classification of Diabetic Retinopathy. With our proposed approach, we obtained an accuracy of 98.02%, a sensitivity of 95.33%, and a specificity of 98.53% without overfitting. © 2020 IEEE.","Computer aided diagnosis; Convolution; Deep learning; Deep neural networks; Eye protection; Image recognition; Learning systems; Medical computing; Medical imaging, Computer aided; Data augmentation; Diabetes mellitus; Diabetic retinopathy; Diabetic retinopathy screening; Learning methods; Overfitting; Regularization technique, Convolutional neural networks"
"Khaled O,El-Sahhar M,El-Dine MA,Talaat Y,Hassan YM,Hamdy A",Cascaded Architecture for Classifying the Preliminary Stages of Diabetic Retinopathy,2020,"Diabetes Mellitus is one of the modern world's most dominant diseases. This condition leads to a dangerous eye disease called Diabetic Retinopathy (DR), which eventually causes total blindness. The purpose of this research is the early detection of this condition to prevent further complications in the future. Over the past few years, Convolutional Neural Networks (CNNs) became very popular in resolving image processing and object detection problems for huge datasets. A cascaded model was proposed to detect the presence of DR and classify it into 4 stages, taking into consideration using a large dataset. Furthermore, preprocessing techniques such as normalization are applied, and finally, the input images are fed into a multi-layer Convolutional Neural Network. This method was utilized on 61,248 retinal images, which are a portion of the (EyePACS) dataset. It achieved a specificity of 96.1% for detecting the presence of the disease and 63.1% for determining its stage. © 2020 ACM.","Classification (of information); Convolution; Convolutional neural networks; Eye protection; Large dataset; Network layers; Object detection, Cascaded models; Detection problems; Diabetes mellitus; Diabetic retinopathy; Eye disease; Input image; Preprocessing techniques; Retinal image, Multilayer neural networks"
"Fadli A,Hasibuan LS,Kusuma WA,Heryanto R",Single nucleotide polymorphism and type 2 diabetes mellitus phenotypes association using gradient boosting,2020,"Precision medicine is a medical field that aims to provide disease treatment according to an individual's genetic information, environment and lifestyle. Recently, precision medicine researchs is focusing on studying complex diseases, such as diabetes mellitus (DM). The most common form of DM is type 2 DM (T2DM). T2DM patient's genetic information can be obtained by finding an association between Single Nucleotide Polymorphism (SNP) and phenotypes of T2DM. This research aims to find SNPs which considered related to T2DM phenotypes using gradient boosting (GB) algorithm. Data were taken from Mouse Phenome Database website based on 98 protein candidates of T2DM. Preprocessing stage is conducted by deleting unused features and missing values, SNP encoding, and merging phenotypes and SNP data. Model was built using GB with decision tree base-learners and least square loss function. GB produced an average MSE value of 0.061 and MAE value of 0.171 and also obtained 30 SNPs that potentially associated with T2DM's insulin tolerance phenotype. Twenty two of 30 choosen SNPs verified to have association with T2DM phenotypes on Mouse Genome Informatics website based on SNP-protein-phenotype relationship. © 2020 IEEE.","Decision trees; Genes; Information systems; Information use; Mammals; Nucleotides; Personalized medicine; Polymorphism; Proteins; Websites, Complex disease; Diabetes mellitus; Disease treatment; Genetic information; Gradient boosting; Medical fields; Single-nucleotide polymorphisms; Type 2 diabetes mellitus, Data fusion"
"Purwanithami HA,Atika Sari C,Rachmawanto EH,Rosal Ignatius Moses Setiadi D",Hemorrhage diabetic retinopathy detection based on fundus image using neural network and FCM segmentation,2020,"Hemorrhage Diabetic Retinopathy is a type of diabetes that attacks the blood vessels of the retina. This disease can cause blindness, but early treatment can minimize this. This research proposes a method of detecting blood vessels in the retina caused by Hemorrhage Diabetic Retinopathy. Detection is based on the Fundus image based on several stages of preprocessing, segmentation, and detection. At the preprocessing stage, the fundus image with the RGB image format is taken the green channel to do a contrast enhancement operation with CLAHE and segmentation with FCM. Then the detection is done using the Neural Network method. At the experimental stage, 100 testing images are used which are divided into two classes, namely Hemorrhage and Non-Hemorrhage. Detection results showed from 100 images, only one image was detected incorrectly, so it can be concluded that the detection accuracy reached 99%. © 2020 IEEE.","Blood; Blood vessels; Eye protection; Image enhancement; Image segmentation, Contrast Enhancement; Detection accuracy; Diabetic retinopathy; Fundus image; Neural network method; RGB images, Neural networks"
"Driss K,Boulila W,Batool A,Ahmad J",A Novel approach for classifying diabetes' patients based on imputation and machine learning,2020,"Since the last decade, many research studies has been conducted on machine learning-based diabetes disease prediction using diagnostic measurement. However, the main challenge in machine learning-based diabetes disease prediction is the preprocessing of data, which contains, in most cases missing values and outliers. For data analytics and accurate prediction, data cleansing is highly desired and recommended. The goal of this study is to predict diabetic patients using realworld datasets. The proposed approach is based on three main steps: cleansing, modelling, and storytelling. In the first step, an imputation process is conducted to remove missing values. Then, k-nearest neighbor's algorithm is applied to classify patients. To evaluate the performance of the proposed approach, two criteria, namely the F1 score and the Receiver Operating Characteristic (ROC) has been used. F1 score and ROC curve show a clear distinction between diabetic and nondiabetic patients. © 2020 IEEE.","Data Analytics; Forecasting; Machine learning; Nearest neighbor search, Accurate prediction; Diagnostic measurements; Imputation process; K-nearest neighbors; Pre-processing of data; Real-world datasets; Receiver operating characteristics; Research studies, Diagnosis"
"Joshi S,Karule PT",Haemorrhages detection using geometrical techniques,2020,"Aim: With an increasing percentage of retinal pathology because of diabetes, eye screening for diabetic retinopathy (DR) is in demand throughout the world. Haemorrhages (HEs) are one of the common signs for the red lesion detection for early diagnosis of this progressive degenerative disease of the retina. The detection of HEs in early stage prevents further progression of the eye disease and reduces the risk of blindness. Methods: The proposed method is based on morphological segmentation and geometrical feature techniques for HEs extraction. This approach uses preprocessing, removal of other retinal image details, determining connected components analysis and applying a specific shape feature set which results in improving the recognition of HEs. Results: The proposed algorithm demonstrated 95.47% accuracy for a Diaretdb1 database at image level detection. Moreover, the proposed method achieved better performance results for HEs extraction when individual images were analysed and compared with the true HEs count according to the multiple expert evaluations. Conclusion: The results obtained prove the potential use of the proposed algorithm in terms of true HEs count to facilitate the DR grading criteria related to HEs. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.","Diagnosis; Extraction; Eye protection; Grading; Image analysis; Image enhancement; Ophthalmology, Degenerative disease; Diabetic retinopathy; Early diagnosis; Eye disease; Fundus image; Haemorrage; Hemorrhage detection; Lesion detection; Morphological segmentation; Red lesions, Morphology, accuracy; Article; blindness; contrast enhancement; disease exacerbation; eye axis length; eye disease; eye photography; histogram; human; image quality; image segmentation; intraocular hemorrhage; k nearest neighbor; optic nerve; priority journal; retina blood vessel; retina image; screening; sensitivity and specificity; support vector machine"
"Giri B,Ghosh NS,Majumdar R,Ghosh A",Predicting Diabetes Implementing Hybrid Approach,2020,Medically stated diabetes is the outcome when glucose/sugar level is high. Blood glucose is the key category of sugar and major foundation of energy. Hybrid approach is used to extract knowledge related diabetes from medical information source as database and helps to generate clear and understandable diagnosis of the problem as well as implementing medical diagnosis. This work orients towards the progress of a hybrid form based on Pima Indian diabetic database (PIDD).Experimental results indicate that the proposed method along with preprocessing produces better result with classification accuracy of 86%. In this study different algorithms are implemented to predict whether a patient having diabetes along its severity level. © 2020 IEEE.,"Classification (of information); Glucose, Blood glucose; Classification accuracy; Hybrid approach; Hybrid forms; Medical information, Diagnosis"
"Ishtiaq U,Abdul Kareem S,Abdullah ER,Mujtaba G,Jahangir R,Ghafoor HY",Diabetic retinopathy detection through artificial intelligent techniques: a review and open issues,2020,"Diabetic Retinopathy (DR) is the disease caused by uncontrolled diabetes that may lead to blindness among the patients. Due to the advancements in artificial intelligence, early detection of DR through an automated system is more beneficial over the manual detection. At present, there are several published studies on automated DR detection systems through machine learning or deep learning approaches. This study presents a review on DR detection techniques from five different aspects namely, datasets, image preprocessing techniques, machine learning-based approaches, deep learning-based approaches, and performance measures. Moreover, it also presents the authors’ observation and significance of the review findings. Furthermore, we also discuss nine new research challenges in DR detection. After a rigorous selection process, 74 primary publications were selected from eight academic databases for this review. From the selected studies, it was observed that many public datasets are available in the field of DR detection. In image preprocessing techniques, contrast enhancement combined with green channel extraction contributed the most in classification accuracy. In features, shape-based, texture-based and statistical features were reported as the most discriminative in DR detection. The Artificial Neural Network was proven eminent classifier compared to other machine learning classifiers. In deep learning, Convolutional Neural Network outperformed compared to other deep learning networks. Finally, to measure the classification performance, accuracy, sensitivity, and specificity metrics were mostly employed. This review presents a comprehensive summary of DR detection techniques and will be proven useful for the community of scientists working in the field of automated DR detection techniques. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Automation; Convolution; Eye protection; Image enhancement; Machine learning; Neural networks; Textures, Convolutional neural network; Diabetic retinopathy; DIARETDB1; Image preprocessing; Transfer learning, Deep learning"
"Suresh A,Kumar R,Varatharajan R",Health care data analysis using evolutionary algorithm,2020,"Assessment of huge amount of data is the difficult task in the health care industry. Hence, it here brings the important need of the data mining in identifying the relationship between the data attributes. In this research work, an assessment model for the health care analysis is developed with the preprocessing steps of performing data cleaning by applying normalization with outlier detection by applying the k-means clustering. Then, the preprocessed data are subjected to the dimensionality reduction process by performing the Feature Selection task. Then, the selected features are analyzed by the wrapper model named SVM-based improved recursive feature selection, and its accuracy is evaluated and compared with the other traditional classifiers such as Naïve Bayes. The analysis demonstrates that the planned perfect has accomplished a regular correctness of 98.79% of health care dataset such as Pima Indians diabetes. It demonstrates that the planned technique has achieved improved consequences. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Data mining; Feature extraction; Health care; K-means clustering; Support vector machines, Assessment models; Conventional classifier; Dimensionality reduction; Healthcare industry; Medical data mining; Pre-processed data; Pre-processing step; Recursive feature selection-based support vector machine (RFS-SVM), Medical computing"
"Shankar K,Sait AR,Gupta D,Lakshmanaprabu SK,Khanna A,Pandey HM",Automated detection and classification of fundus diabetic retinopathy images using synergic deep learning model,2020,"In recent days, the incidence of Diabetic Retinopathy (DR)has become high, affecting the eyes because of drastic increase in the glucose level in blood. Globally, almost half of the people under the age of 70 gets severely affected by diabetes. In the absence of earlier recognition and proper medication, the DR patients tend to lose their vision. When the warning signs are tracked down, the severity level of the disease has to be validated so to take decisions regarding appropriate treatment further. The current research paper focuses on the concept of classification of DR fundus images on the basis of severity level using a deep learning model. This paper proposes a deep learning-based automated detection and classification model for fundus DR images. The proposed method involves various processes namely preprocessing, segmentation and classification. The methods begins with preprocessing stage in which unnecessary noise that exists in the edges is removed. Next, histogram-based segmentation takes place to extract the useful regions from the image. Then, Synergic Deep Learning (SDL) model was applied to classify the DR fundus images to various severity levels. The justification for the presented SDL model was carried out on Messidor DR dataset. The experimentation results indicated that the presented SDL model offers better classification over the existing models. © 2020 Elsevier B.V.","Classification (of information); Eye protection; Image classification; Image segmentation; Learning systems, Automated detection and classification; Diabetic retinopathy; Glucose level; Histogram based segmentation; Learning models; Messidor dataset; Research papers; Warning signs, Deep learning"
"Nnamoko N,Korkontzelos I",Efficient treatment of outliers and class imbalance for diabetes prediction,2020,"Learning from outliers and imbalanced data remains one of the major difficulties for machine learning classifiers. Among the numerous techniques dedicated to tackle this problem, data preprocessing solutions are known to be efficient and easy to implement. In this paper, we propose a selective data preprocessing approach that embeds knowledge of the outlier instances into artificially generated subset to achieve an even distribution. The Synthetic Minority Oversampling TEchnique (SMOTE) was used to balance the training data by introducing artificial minority instances. However, this was not before the outliers were identified and oversampled (irrespective of class). The aim is to balance the training dataset while controlling the effect of outliers. The experiments prove that such selective oversampling empowers SMOTE, ultimately leading to improved classification performance. © 2020 The Authors","Anomaly detection; Learning systems; Machine learning, Classification performance; Data preprocessing; Efficient treatment; Imbalanced data; Over sampling; SMOTE; Synthetic minority over-sampling techniques; Training dataset, Statistics, accuracy; Article; classifier; cross validation; diabetes mellitus; human; information processing; prediction; priority journal; quantitative structure activity relation; random forest; diabetes mellitus; machine learning, Diabetes Mellitus; Humans; Machine Learning"
"Jahangir M,Afzal H,Ahmed M,Khurshid K,Amjad MF,Nawaz R,Abbas H",Auto-MeDiSine: an auto-tunable medical decision support engine using an automated class outlier detection method and AutoMLP,2020,"With advanced data analysis techniques, efforts for more accurate decision support systems for disease prediction are on the rise. According to the World Health Organization, diabetes-related illnesses and mortalities are on the rise. Hence, early diagnosis is particularly important. In this paper, we present a framework, Auto-MeDiSine, that comprises an automated version of enhanced class outlier detection using a distance-based algorithm (AutoECODB), combined with an ensemble of automatic multilayer perceptron (AutoMLP). AutoECODB is built upon ECODB by automating the tuning of parameters to optimize outlier detection process. AutoECODB cleanses the dataset by removing outliers. Preprocessed dataset is then used to train a prediction model using an ensemble of AutoMLPs. A set of experiments is performed on publicly available Pima Indian Diabetes Dataset as follows: (1) Auto-MeDiSine is compared with other state-of-the-art methods reported in the literature where Auto-MeDiSine realized an accuracy of 88.7%; (2) AutoMLP is compared with other learners including individual (focusing on neural network-based learners) and ensemble learners; and (3) AutoECODB is compared with other preprocessing methods. Furthermore, in order to validate the generality of the framework, Auto-MeDiSine is tested on another publicly available BioStat Diabetes Dataset where it outperforms the existing reported results, reaching an accuracy of 97.1%. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","Anomaly detection; Artificial intelligence; Classification (of information); Data handling; Decision support systems; Diagnosis; Forecasting; Multilayer neural networks; Multilayers; Statistics, Data analysis techniques; Distance based algorithm; Medical decision supports; Pima Indian Diabetes; Pre-processing method; State-of-the-art methods; Tuning of parameters; World Health Organization, Learning systems"
"Martinsson J,Schliep A,Eliasson B,Mogren O",Blood Glucose Prediction with Variance Estimation Using Recurrent Neural Networks,2020,"Many factors affect blood glucose levels in type 1 diabetics, several of which vary largely both in magnitude and delay of the effect. Modern rapid-acting insulins generally have a peak time after 60–90 min, while carbohydrate intake can affect blood glucose levels more rapidly for high glycemic index foods, or slower for other carbohydrate sources. It is important to have good estimates of the development of glucose levels in the near future both for diabetic patients managing their insulin distribution manually, as well as for closed-loop systems making decisions about the distribution. Modern continuous glucose monitoring systems provide excellent sources of data to train machine learning models to predict future glucose levels. In this paper, we present an approach for predicting blood glucose levels for diabetics up to 1 h into the future. The approach is based on recurrent neural networks trained in an end-to-end fashion, requiring nothing but the glucose level history for the patient. Our approach obtains results that are comparable to the state of the art on the Ohio T1DM dataset for blood glucose level prediction. In addition to predicting the future glucose value, our model provides an estimate of its certainty, helping users to interpret the predicted levels. This is realized by training the recurrent neural network to parameterize a univariate Gaussian distribution over the output. The approach needs no feature engineering or data preprocessing and is computationally inexpensive. We evaluate our method using the standard root-mean-squared error (RMSE) metric, along with a blood glucose-specific metric called the surveillance error grid (SEG). We further study the properties of the distribution that is learned by the model, using experiments that determine the nature of the certainty estimate that the model is able to capture. © 2019, The Author(s).","Blood; Closed loop systems; Glucose; Insulin; Mean square error; Recurrent neural networks, Blood glucose; Blood glucose level; Blood glucose prediction; Carbohydrate sources; Diabetics patients; Glucose level; Glycemic index; Peak time; Type 1 diabetes; Variance estimation, Forecasting"
"Pandey I,Tiwari JD",Shape-printed nanozyme coated wet tissue paper based sensor for electrochemical sensing of 8-Hydroxy-2' -deoxyguanosine,2020,"Flexible and biocompatible wearable sensors for the management of chronic diseases are in demand. The disposable, biocompatible, flexible and lightweight conductive paper-based sensing system was fabricated for 8-hydroxydeoxyguanosine. This biomolecule can biomark the early symptoms of various clinically important diseases such as cancer, diabetes, and atherosclerosis. Wet tissue paper modified with graphene nanoparticles was used for the analysis of 8-hydroxydeoxyguanosine in healthy human and patient biological samples. Here imprinted nanozymes were used as a receptor that promotes selective sensing of 8-hydroxydeoxyguanosine. Shape printed nanozyme contains hydroxyl and carboxyl groups which promote the penetration of 8-hydroxydeoxyguanosine and its selective adsorption. Graphene and nanozyme both catalyze the selective sensing of 8-hydroxydeoxyguanosine. When 8-OHdG was added the specific interaction of 8-OHdG and nanozyme was examined by current signals. The current signal was linear with 8-OHdG concentration. The fabricated shape printed nanozyme based sensor shows a biological justifiable sensitivity with linear range of 1.0-100.00 ?g mL-1 with no matrix effects. The Shape printed nanozyme modified tissue paper could be used as a wearable patch for early monitoring of oxidative stress biomarker by cancer patients itself without any preprocessing plan. © 2020 IEEE.","Biocompatibility; Biomolecules; Diseases; Graphene; Paper products; Tissue, Biological samples; Chronic disease; Conductive papers; Electrochemical sensing; Oxidative stress biomarkers; Selective adsorption; Selective sensing; Specific interaction, Wearable sensors, Conductive Papers; Diseases; Monitoring; Paper Products; Penetration; Shape; Stresses; Tissue"
"Maheswari MV,Murugeswari G",A Survey on Computer Algorithms for Retinal image Preprocessing and Vessel Segmentation,2020,"Diabetic retinopathy is one of the common eye diseases found in most of the diabetic patients. According to the latest report by the International Diabetes Federation (IDF), in the year 2045 about 84% of the Indian population will be affected by Diabetes. Automated Computer Aided Diagnosis (CAD) system helps ophthalmologists to reduce the risk of visual defects and to reduce the cost of medical resources to a greater extent. Retina is a delicate and a thin tissue that lines back of eye. It is supplied with sufficient amount of blood by a delicate network of blood vessels. Blood vessels in the retina plays an essential role for the analysis and detection of various chronicle diseases like diabetic retinopathy, glaucoma, cataract and cardio vascular risks. Manual vessel segmentation is always a difficult process in a retinal image because of varying thickness and width of a retinal blood vessels. Retinal blood vessel segmentation has become a mandatory process for any type of retinal diseases. This survey paper briefly explains preprocessing techniques for retinal image enhancement, methods used for segmentation of blood vessels and publicly available retinal databases. The goal of the paper is to provide a deep understanding and knowledge about the existing computer algorithms used for retinal image analysis and to identify the research areas for computer researchers in the field of ophthalmology. © 2020 IEEE.","Blood; Computer aided diagnosis; Eye protection; Image enhancement; Image segmentation; Ophthalmology; Risk assessment; Surveys, Computer Aided Diagnosis(CAD); Diabetic patient; Diabetic retinopathy; Preprocessing techniques; Retinal blood vessels; Retinal image analysis; Varying thickness; Vessel segmentation, Blood vessels"
"Doshi N,Oza U,Kumar P",Diabetic retinopathy classification using downscaling algorithms and deep learning,2020,"Diabetic Retinopathy (DR) is an art and science of recording and classifying the retinal images of a diabetic patient. DR classification deals with classifying retinal fundus image into five stages on the basis of severity of diabetes. One of the major issue faced while dealing with DR classification problem is the large and varying size of images. In this paper we propose and explore the use of several downscaling algorithms before feeding the image data to a Deep Learning Network for classification. For improving training and testing; we amalgamate two datasets: Kaggle and Indian Diabetic Retinopathy Image Dataset. Our experiments have been performed on a novel Multi Channel Inception V3 architecture with a unique self crafted preprocessing phase. We report results of proposed approach using accuracy, specificity and sensitivity, which outperform the previous state of the art methods. © 2020 IEEE.","Eye protection; Image classification; Image enhancement; Learning algorithms; Ophthalmology; Statistical tests, Art and science; Diabetic patient; Diabetic retinopathy; Learning network; Preprocessing phase; Retinal fundus images; State-of-the-art methods; Training and testing, Deep learning"
"Kurniastuti I,Wulan TD",Segmentation of Finger Nails Image based on Image Processing methods,2020,"This research has aim to segmentation of finger nails image using image processing methods and k-means region growing. Finger nails image could be used as early detection of diabetes mellitus. The steps in research are preprocessing step and segmentation step. Preprocessing step consist of image grayscale conversion, median filter, edge detection sobel operator and dilation. The aim of preprocessing step is to enhancement image before segmentation process is applied in image. Therefore, segmentation step using k-means region growing approach. The result show that accuracy rate of methods is 54.67%. In the next research, segmentation of finger nails image could use other methods that show better result. © 2020 IEEE.","Edge detection; Image enhancement; Image segmentation; Processing, Finger nail; Finger nail image; Image processing - methods; Images processing; K-mean region growing; K-means; Nail image; Pre-processing step; Region growing; Segmentation images, Median filters"
"Shih DH,Huang FC,Weng CL,Shih PY,Yen DC",Thirty-day re-hospitalization rate prediction of diabetic patients,2020,"Diabetes is a serious global health problem, and rehospitalization is usually associated with increased mortality and excessive medical burden. With the increasing cost of diabetes to the health care system, rehospitalization is recommended as a goal to reduce health care costs. This paper aims to use data mining technology to accurately predict the 30-day re-hospitalization of diabetic patients. We use the data set from UCI machine learning repository, preprocessing, use feature reduction method to find out the classification results of rehospitalization, and then use frequent set and Apriori algorithm to find the association rules between diabetes mellitus patients and re-hospitalization related variables. The experimental results show that the recursive feature reduction method is effective in combined with SVM can get a better prediction accuracy. © 2020 Taiwan Academic Network Management Committee. All rights reserved.","Classification (of information); Forecasting; Health care; Hospitals; Support vector machines, Apriori algorithms; Classification results; Data mining technology; Feature reduction; Health care costs; Health-care system; Prediction accuracy; UCI machine learning repository, Data mining"
"Pustozerov EA,Tkachuk AS,Vasukova EA,Anopova AD,Kokina MA,Gorelova IV,Pervunina TM,Grineva EN,Popova PV",Machine Learning Approach for Postprandial Blood Glucose Prediction in Gestational Diabetes Mellitus,2020,"Postprandial blood glucose prediction is a crucial part of diabetes management. Recently, this topic has been of great interest, resulting in many research projects and published papers. Although different input parameters that might be beneficial for blood glucose prediction models were comprehensively discussed, specific data preprocessing, feature engineering and model tuning steps were not explained in detail in many of these papers. In this work, we developed and comprehensively described a data-driven blood glucose model based on a decision tree gradient boosting algorithm to predict different characteristics of postprandial glycemic responses; the model utilized meal-related data derived from a mobile app diary (including information on the glycemic index), food context (information on previous meals), characteristics of the individual patients and patient behavioral questionnaires. A set of rules was defined and implemented to detect incorrect meal records and to filter faulty data, and analyses were conducted on the overall food diary data and in particular, the data on the current meal for which the postprandial blood glucose response was calculated. Different gradient boosting models were trained and evaluated with parameters selected via random search cross-validation. The best models for the prediction of the incremental area under the blood glucose curve two hours after food intake had the following characteristics: R=0.631, MAE=0.373 mmol/L*h for the model not using data on current blood glucose; R=0.644, MAE=0.371 mmol/L*h for the model using data on the current blood glucose levels; and R=0.704, MAE=0.341 mmol/L*h for the model utilizing data on the continuous blood glucose trends before the meal. The impact of features was evaluated using Shapley values. The meal glycemic load, amount of carbohydrates in the meal, type of meal (e.g., breakfast), amount of starch and amount of food consumed 6 hours before the current meal were the most important contributors in the models. CCBY","Behavioral research; Decision trees; Forecasting; Glucose; Machine learning; Nutrition; Predictive analytics; Surveys; Trees (mathematics), Blood glucose curves; Blood glucose level; Data preprocessing; Diabetes management; Feature engineerings; Gestational diabetes; Gradient boosting; Machine learning approaches, Blood"
"Khanum S,Ashraf MA,Karim A,Shoaib B,Khan MA,Naqvi RA,Siddique K,Alswaitti M",Gly-LysPred: Identification of lysine glycation sites in protein using position relative features and statistical moments via Chou's 5 step rule,2020,"Glycation is a non-enzymatic post-translational modification which assigns sugar molecule and residues to a peptide. It is a clinically important attribute to numerous age-related, metabolic, and chronic diseases such as diabetes, Alzheimer's, renal failure, etc. Identification of a non-enzymatic reaction are quite challenging in research. Manual identification in labs is a very costly and timeconsuming process. In this research, we developed an accurate, valid, and a robust model named as Gly-LysPred to differentiate the glycated sites from non-glycated sites. Comprehensive techniques using position relative features are used for feature extraction. An algorithm named as a random forest with some preprocessing techniques and feature engineering techniques was developed to train a computational model. Various types of testing techniques such as self-consistency testing, jackknife testing, and cross-validation testing are used to evaluate the model. The overall model's accuracy was accomplished through self-consistency, jackknife, and cross-validation testing 100%, 99.92%, and 99.88% with MCC 1.00, 0.99, and 0.997 respectively. In this regard, a user-friendly webserver is also urbanized to accumulate the whole procedure. These features vectorization methods suggest that they can play a critical role in other web servers which are developed to classify lysine glycation. © 2021 Tech Science Press. All rights reserved.","Amino acids; Decision trees; Testing, Computational model; Feature engineerings; Manual identification; Post-translational modifications; Preprocessing techniques; Self-consistency; Statistical moments; Testing technique, Glycosylation"
"Saranya P,Prabakaran S",Automatic detection of non-proliferative diabetic retinopathy in retinal fundus images using convolution neural network,2020,"Diabetic retinopathy (DR) is one of the complications of diabetes and a leading cause of blindness in the world. The tiny blood vessels inside the retina are damaged due to diabetes and result in various vision-related problems and it may lead to complete vision loss without early detection and treatment. Diabetic retinopathy may not cause any symptoms during its earlier stage of the disease and many physical tests such as visual acuity tests, pupil dilation, etc., are required to detect diabetic retinopathy disease. So, early detection of diabetic retinopathy disease is required to avoid vision loss. This work aims to automate the detection and grading of non-proliferative Diabetic Retinopathy from retinal fundus images using Convolution Neural Networks. The model was tested on two popular datasets such as MESSIDOR and IDRiD. Before applying the Convolution Neural Network (CNN) layers, the images were pre-processed and resolution was adjusted (256 × 256). The maximum accuracy achieved is 90.89% using MESSIDOR images. The research can be carried forward by applying various preprocessing techniques before putting them through different computational layers. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Blood vessels; Chemical detection; Convolution; Grading; Multilayer neural networks; Ophthalmology; Vision, Automatic Detection; Convolution neural network; Diabetic retinopathy; Maximum accuracies; Physical tests; Preprocessing techniques; Pupil dilation; Retinal fundus images, Eye protection"
"Sarno R,Izza Sabilla S,Rahman Wijaya D,Hariyanto",Electronic nose for detecting multilevel diabetes using optimized deep neural network,2020,"Diabetes is a chronic disease which is still a major issue in the world. The common testing methods generally used to detect diabetes are urine dipstick, laboratory blood tests, and blood glucose monitors. However, those testing procedures are often perceived as painful and inconvenient for the patients. In this context, this study proposes an electronic nose (e-nose) for detecting three classes of diabetes (healthy, prediabetes, and diabetes) based on a patient breath. The proposed e-nose system is called DENS, which utilizes an optimized deep neural network for the classiflcation. DENS also attempts to enhance accuracy and to reduce the error rate from previous studies. Therefore, this paper has three contributions: (i) the optimal gas sensors for capturing patient breaths; (ii) the optimal signal preprocessing; (iii) the fine-tuned parameters of deep neural network (DNN) for classifying multilevel diabetes. The proposed system successfully detected multilevel diabetes with an accuracy of 96.29% and showed a minimum classiflcation error of 0.050. © 2020, International Association of Engineers. All rights reserved.","Blood; Electronic nose; Medical problems; Testing, Blood test; Blood-glucose monitors; Chronic disease; Electronic nose (e-nose); Error rate; Optimal signals; Testing method; Testing procedure, Deep neural networks"
"Ghazal M,Ali SS,Mahmoud AH,Shalaby AM,El-Baz A",Accurate Detection of Non-Proliferative Diabetic Retinopathy in Optical Coherence Tomography Images Using Convolutional Neural Networks,2020,"Diabetic retinopathy (DR) is a disease that forms as a complication of diabetes. It is particularly dangerous since it often goes unnoticed and can lead to blindness if not detected early. Despite the clear importance and urgency of such an illness, there is no precise system for the early detection of DR so far. Fortunately, such system could be achieved using deep learning including convolutional neural networks (CNNs), which gained momentum in the field of medical imaging due to its capability of being effectively integrated into various systems in a manner that significantly improves the performance. This paper proposes a computer aided diagnostic (CAD) system for the early detection of non-proliferative DR (NPDR) using CNNs. The proposed system is developed for the optical coherence tomography (OCT) imaging modality. Throughout this paper, all aspects of deployment of the proposed system are studied starting from the preprocessing stage required to extract input retina patches to train the CNN without resizing the image, to the use of transfer learning principals and how to effectively combine features in order to optimize performance. This is done through investigating several scenarios for the system setup and then selecting the best one, which from the results revealed to be a two pre-trained CNNs based system, in which one of these CNNs is independently fed by nasal retina patches and the other one by temporal retina patches. The proposed transfer learning based CAD system achieves a promising accuracy of 94%. © 2013 IEEE.","Computer aided diagnosis; Convolution; Deep learning; Eye protection; Learning systems; Medical imaging; Optical tomography; Tomography; Transfer learning, CAD system; Computer aided diagnostics; Diabetic retinopathy; Imaging modality; System-setup, Convolutional neural networks"
"Saha PK,Patwary NS,Ahmed I",A widespread study of diabetes prediction using several machine learning techniques,2019,"Diabetes is one of the most common diseases that can affect anyone at any ages. These diseases attacked when the glucose level or sugar level is increased. Predicting diabetes is one of the most important things at this moment. There are some several techniques applied on Indian Pima Dataset. The dataset studying on woman Pima Indian population which had started in 1965. Most of the researcher trying to apply some complex techniques on dataset while many comprehensive research has many common technique missing.In our study, we have applied some very popular techniques such as Neural Network(NN), Support Vector Machine(SVM), Random Forest(RF), etc. We have applied those methods in several ways. Firstly, we have applied several algorithms in the original dataset. Then we used several preprocessing techniques to identify diabetes. Finally, we applied those techniques to compare and get the best accuracy. Neural Network was given the best accuracy(80.4%) than any other techniques. © 2019 IEEE.","Decision trees; Neural networks; Support vector machines, Common disease; Comprehensive research; Data classification; Glucose level; Machine learning techniques; Neural network (nn); Preprocessing techniques; Sugar levels, Learning systems"
"Ananda S,Kitahara D,Hirabayashi A,Udaya Kumar Reddy KR",Automatic fundus image segmentation for diabetic retinopathy diagnosis by multiple modified U-nets and segnets,2019,"Diabetes mellitus leads to damage of the retina by a high blood sugar level. This disease is called diabetic retinopathy (DR), and it is one major cause of blindness among working-aged people. DR affects about 80% of patients who have had diabetes for twenty years or more. The longer a period of diabetes is, the higher the risk of developing DR is. In order to prevent the blindness caused by DR, accurate DR diagnosis from a retinal fundus image is important. Recently, deep learning techniques play significant role in the field of computer vision. When we apply deep learning to segmentation of abnormal parts in fundus images, two major problems arise. One is that the number of available data is insufficient to train a deep neural network. The other is that the sizes of the abnormal parts are quite different depending on the type of the disease, which leads to low segmentation accuracy of small diseases. These two problems make the fundus image segmentation challenging. In this paper, we propose a segmentation method using multiple deep neural networks. To train the deep neural networks from a small number of data, we use data augmentation as preprocessing and adopt the Dice coefficient with the binary cross entropy as a loss function. Moreover, to improve the segmentation accuracy of small diseases, e.g., microaneurysms, we construct one individual network for each type of the disease. In experiments, the networks are trained from IDRiD dataset and tested for MESSIDOR dataset. We compare and discuss the accuracy of the proposed method with modified U-Nets and SegNets. © 2019 IEEE.","Deep learning; Deep neural networks; Diagnosis; Eye protection, Blood sugar levels; Diabetes mellitus; Diabetic retinopathy; Individual network; Learning techniques; Retinal fundus images; Segmentation accuracy; Segmentation methods, Image segmentation"
"Anggraeni Z,Wibawa HA",Detection of the Emergence of Exudate on the Image of Retina Using Extreme Learning Machine Method,2019,"Diabetic retinopathy is a health problem that cause damage to the retinal blood vessels and occurs in more than half of people who suffer from diabetes. It is estimated that around 28 million people experience loss of sight for this reason. Thus, the system for detecting early signs of diabetic retinopathy will be very helpful and one of first signs of the onset of symptoms of diabetic retinopathy is the appearance of exudates in the retinal image of the eye. To build an exudate emergence detection system, in this study use the method of extreme learning machine (ELM) which has a fast learning speed. This system uses the gray level co-occurrence matrix feature extraction with 6 features, namely contrast, homogeneity, correlation, ASM, energy and dissimilarity. To get the best model, six scenarios are used by distinguishing the preprocessing flow. The pre processing stage carried out by all scenarios is optic disc removal, green channel separation, contrast limited adaptive histogram equalization (CLAHE) followed by two different preprocessing lines, namely applying brightness and dilation and erosion operations. Then the second path is radon transform, top-hat filtering, discrete wavelet transform and dilation and erosion. The best model results reached the best accuracy value of 65% with a combination of multiquadric activation functions and 30 hidden neurons. © 2019 IEEE.","Blood vessels; Discrete wavelet transforms; Erosion; Knowledge acquisition; Machine learning; Ophthalmology, Activation functions; Contrast Limited Adaptive Histogram Equalization (CLAHE); Diabetic retinopathy; Dilation and erosions; Extreme learning machine; Exudate detections; Gray level co-occurrence matrix; Retinal blood vessels, Eye protection"
"Firdausy K,Wahyunggoro O,Nugroho HA,Sasongko MB,Hidayat R",Impact of Different Degree of Smoothing on Non-Local Means based Filter for Retinal Vessel Modeling,2019,"One of the complications of diabetes is the disruption of vision because of the damage to the retinal blood vessels, which is known as diabetic retinopathy (DR). The change in diameter of the retinal blood vessel is an important sign of DR. Several segmentation models have been proposed for measuring the retinal blood vessel diameter, but the results are not always satisfactory. Preprocessing steps, such as image filtering for noise reduction, can improve the result of the modeling step. This paper presents the results of applying non-local means based filter for retinal image enhancement to improve the performance of retinal vessel modeling using two-dimensional (2D) Gaussian. Various degrees of smoothing (DoS) of non-local means based filter were compared and applied to the retinal images from High-Resolution Fundus (HRF) public dataset. The results show that DoS value, which is 12, gave the highest R2 (coefficient of determination) value, which is 0,9862. The proposed filtering approach yields encouraging results for retinal vessel modeling improvement. © 2019 IEEE.","Blood; Embedded systems; Eye protection; Image denoising; Image enhancement; Noise abatement; Ophthalmology, Coefficient of determination; Diabetic retinopathy; Gaussian model; Non local means; Retinal blood vessels; Retinal fundus images; Segmentation models; Two Dimensional (2 D), Blood vessels"
"Firdausy K,Wahyunggoro O,Nugroho HA,Sasongko MB",A Study on Recent Developments for Detection of Neovascularization,2019,"Diabetes and its complications are major causes of death in most countries. One of the complications of diabetes is diabetic retinopathy, the disruption of vision because of the damage to the retinal blood vessels. Automatic screening of diabetic retinopathy is needed because of the increasing number of diabetic retinopathy patients and the limited number of ophthalmologists. Neovascularization (new abnormal blood vessel) is an indicator of proliferative diabetic retinopathy, which is the most advanced stage of diabetic retinopathy. The accurate detection of neovascularization is an important step for the early detection of proliferative diabetic retinopathy. This paper examines some of the current techniques used to detect neovascularization from retinal digital fundus images. Various algorithms include preprocessing steps, and image databases are discussed. This work can be used by researchers to conduct further research in the field of neovascularization detection. © 2019 IEEE.","Blood; Blood vessels; Diagnosis; Engineering research; Ophthalmology, Abnormal blood vessels; Automatic screening; Diabetic retinopathy; Digital fundus images; Neo-vascularization; Pre-processing step; Retinal blood vessels; Retinal fundus images, Eye protection"
"Islam N,Saeed U,Naz R,Tanveer J,Kumar K,Shaikh AA",DeepDR: An image guideddiabetic retinopathy detection technique using attention-based deep learning scheme,2019,"This paper proposes an efficient and cost effective deep learning architecture to detect the diabetic retinopathy in real time. Diabetes is a leading root cause of eye disease in patients. It illuminates eye vessels, and releases blood form vessels. Early detection of diabetic retinopathy is useful to reduce the risk of blindness or any hazard. In this paper, after some preprocessing and data augmentation, Inception V3 is used as pre-Trained model to extract the initial features set. Convolutional neural network has been used with attention layers. These additional CNN layers are added to extract the deep features to improve classification performance and accuracy. Initially, the model was proposed by Kevin Mader in Kaggle. The paper introduced additional layers in proposed model and improved the validation and testing accuracy significantly. More than 90% validation accuracy was achieved with the proposed Convolutional Neural Network model. Testing accuracy was improved up to 5%. This improvement in accuracy is very significant because the dataset is imbalanced and contains noisy images. It is concluded that global average pooling (GAP) based attention mechanism increased deep learning architecture accuracy to detect the Diabetic Retinopathy in imbalanced and noisy image dataset © 2019 IEEE.","Blood vessels; Convolution; Cost effectiveness; Deep learning; Deep neural networks; Image enhancement; Multilayer neural networks; Network architecture, attentionmechanism; Convolutional neural network; Diabetic retinopathy; global average pooling; Transfer learning, Eye protection"
"Dizdaroglu B,Corbacioglu B",Deep diagnosis of non-proliferative diabetic retinopathy in a mobile system [Bir mobil sistemde proliferatif olmayan diyabetik retinopatinin derin tanisi],2019,"In this study, a mobile based system is presented for deep diagnosis of non-proliferative diabetic retinopathy. In this system, firstly, fundus images taken sequentially via the microlens mounted on the smartphone will be sent to the server. The images will then be fused in the server and after some image preprocessing steps, the pathological regions in the fundus image will be classified. For the classification process, the deep convolutional neural network approach will be considered. The system, in its current state, performs detection of hard exudates in the moderate state of non-proliferative diabetic retinopathy in a cloud environment. In the later phases of the study, it is planned to implement a semi-automated mobile-based deep diagnostic system that performs in the cloud environment to detect other abnormalities in abnormal fundus images. © 2019 IEEE.","Biomedical engineering; Deep neural networks; Diagnosis; mHealth; Neural networks, Diabetes mellitus; Diabetic retinopathy; Hard exudates; Intraretinal hemorrhage; Mikroaneurym; Mobile systems; Nonproliferative diabetic retinopathies; Soft exudate, Eye protection"
"Ding S,Li Z,Liu X,Huang H,Yang S",Diabetic complication prediction using a similarity-enhanced latent Dirichlet allocation model,2019,"Diabetes and its complications have been recognized worldwide as a major public health threat. Predicting diabetic complications is regarded as a highly effective technique for increasing the survival rate of diabetic patients. While many studies currently use medical images and structured medical records, very limited efforts have been dedicated to applying data mining techniques for unstructured textual medical records, such as admission and discharge records. Moreover, the similarities among medical records that are overlooked by existing approaches could potentially improve the accuracy of prediction models. In this paper, we propose an approach for diabetic complication prediction based on a similarity-enhanced latent Dirichlet allocation (seLDA) model. Specifically, we first estimate the similarity between textual medical records after data preprocessing, and then we perform seLDA-based diabetic complication topic mining based on similarity constraints. Finally, we construct a prediction model by solving a multilabel classification problem with support vector machines (SVMs). The experimental results show that our approach outperforms the conventional LDA-based approach in similarity indices by 22.49%. Additionally, our approach shows significant improvements in prediction accuracy over four other representative seLDA-based approaches, including random forests (RF), k-nearest neighbors (KNN), logistic regression (LR) and deep neural networks (DNNs). © 2019","Classification (of information); Data mining; Decision trees; Deep neural networks; Forecasting; Health risks; Medical imaging; Nearest neighbor search; Statistics; Support vector machines, K nearest neighbor (KNN); Latent Dirichlet allocation; Logistic regressions; Multi-label classifications; Prediction accuracy; Similarity indices; Support vector machine (SVMs); Topic minings, Medical computing"
"Nizam K,Fauzi MF,Ahmad NN,Logeswaran R,Nair HK",Enhancement in the Identification of Slough Tissue in Chronic Wound Assessment,2019,"The prevalence of chronic ulcer wound is steadily increasing not only in predominantly rich nations but most markedly, in the world's middle-income countries. In addition to the dire consequences on the health and well-being of a patient, diabetes and its complications impact harshly on the finances of individuals and their families, and the economies of nations. The current diagnosis methods utilized by the diagnosticians are expert-oriented, vision-dependant, time-consuming, have interob-server variations and cause discomfort to the patient. Therefore, in an effort to improve capacity for diagnosis, a fully-automated wound tissue characterization system has been offered that would analyze the digital images of chronic wounds to identify the tissue types namely, granulation, slough, necrosis, and epithelial. In our previous research, the three tissue types (granulation, necrosis, and epithelial) were identified with higher accuracy in 301 images. In this paper, the slough identification has been enhanced by adding reference points and contrast enhancement to evaluate which method demonstrates better experimental results. Quantitative analysis of the results proves that preprocessing the images with Adaptable Histogram Equalization technique achieved the highest accuracy of 94.0% for the slough tissue. © 2019 IEEE.","Cell death; Granulation; Image analysis; Image enhancement; Plants (botany); Tissue engineering, Chronic wounds; Contrast Enhancement; Diagnosis methods; Digital image; Fully automated; Histogram equalizations; Middle-income countries; Reference points, Tissue"
"Nageswaran K,Nagarajan K,Bandiya R",A Novel Algorithm for Hyperspectral Image Denoising in Medical Application,2019,"The one of the preprocessing step for hyperspectral imagery is noise reduction. The images are received by the detector and this can be degraded by several factors like atmospherical things and device noises which emit temperature noise, processing noise and explosion noise. There are several strategies are developed already to cut back the signal to noise magnitude relation of the hyperspectral image. However, the stationary noise of the many denoising ways developed cannot be applied on to the gauge boson noise. Thus, the each gauge boson and thermal noise square measure gift within the captured hyperspectral image (HSI). during this paper, we tend to projected a replacement denoising framework known as tensor-based filtering employing a PARAFAC tensor decomposition methodology for scale back each noise. The proposed technique is performs higher in removing noise as compared with different strategies like Multiple linear regression (MLR) algorithm and combined algorithm called multidimensional wavelet transforms with multiway wiener filter (MWPT-MWF) technique. The performance analysis of the new denoising framework has more efficient for reducing signal dependent (PN) and signal independent noise (TN) as compared with other conventional method. Hence this novel denoising approach would be more beneficial for detection of skin allergy and also this algorithm will be very useful for detection of retinal exudates and diagnosis of diabetes mellitus and retinopathy disease in medical application. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","algorithm; Article; decomposition; diabetes mellitus; multidimensional wavelet transform; multiple linear regression analysis; noise reduction; retinopathy; skin allergy; wavelet transformation; color; human; image processing; imaging phantom; principal component analysis; procedures; signal noise ratio; statistical model; wavelet analysis, Algorithms; Color; Humans; Image Processing, Computer-Assisted; Linear Models; Phantoms, Imaging; Principal Component Analysis; Signal-To-Noise Ratio; Wavelet Analysis"
"Srividhya E,Muthukumaravel A",Diagnosis of Diabetes by Tongue Analysis,2019,"Tongue image is used to identify any disease based on its shape, color, size and texture. We proposed the image segmentation method; the segmented study of the tongue reflects the presence of diabetes of a person in addition optimization technique is used to obtain the best result. So in this paper, we are proposing computerized technique to examine the changes in tongue, which will be latter useful in diabetes diagnosis in patients. So initially we take the images of tongue and apply the image processing based on feature extraction technique to extract the two types of features named as, color features and gist features. Later on these quantifies features will be classify by using SOM Kohonen Classifier. The system architecture represents input a image, preprocessing that image, identifying the color, gist feature, implemented and identifies the problem effectively and the result achieved better performance when compared to existing techniques. © 2019 IEEE.","Color; Diagnosis; Image segmentation; Textures, Color image segmentation; Diabetes diagnosis; Diabetic diagnosis; Feature extraction techniques; Optimization techniques; Segmentation methods; System architectures; Tongue, Color image processing"
"Chakravarthy SN,Singhal H,Yadav NR",DR-NET: A Stacked Convolutional Classifier Framework for Detection of Diabetic Retinopathy,2019,"Diabetic Retinopathy is the main cause of vision impairment among people suffering from diabetes and often leads to blindness. It has no early warning signs. Hence, it is of utmost importance to detect it as early as possible in order to provide adequate treatment. Most of the current research in this field focuses on a manual process of feature extraction such as annotation of lesions and optic disk segmentation so as to detect the presence of DR. In this paper, a framework DR-NET using stacked convolutional neural networks for diabetic retinopathy detection from digital fundus images is proposed. A network consisting of convolutional layers with different filters stacked in parallel, the output of which is concatenated and global max pooling performed on it, is developed. This architecture helps extract intricate features during the classification task along with minimizing the learnable parameters and reduces overfitting, thus, improving the overall performance of the model. Various preprocessing methods were applied to further improve accuracy. Visualization techniques were also used to gain insights into the learning of the model. The experimental results were performed on about 12,000 images which were an ensemble of various online datasets, yielded an accuracy of 81% and a kappa score of 0.6. © 2019 IEEE.","Biomedical engineering; Convolution; Deep learning; Deep neural networks; Feature extraction; Flow visualization; Image classification; Neural networks; Visualization, Classification tasks; Convolutional neural network; Diabetic retinopathy; Digital fundus images; Early warning signs; Pre-processing method; Vision impairments; Visualization technique, Eye protection"
"Raja C,Balaji L",An Automatic Detection of Blood Vessel in Retinal Images Using Convolution Neural Network for Diabetic Retinopathy Detection,2019,"Abstract: Diabetes is a typical chronic disease that may remind to numerous complications. Since the diabetic patients, the diabetic retinopathy (DR) is standout amongst the most serious of these inconveniences and also most steady reasons of vision loss. Automatic detection of diabetic retinopathy at early stage is helping the ophthalmologist to treat the affected patient and avoid vision loss. Therefore, in this paper, we develop an efficient automatic diabetic detection in retinal images using convolution neural network. The suggested system mainly comprises of five modules such as (i) preprocessing, (ii) blood vessel segmentation, (iii) exudates segmentation, (iv) texture feature extraction, and (v) diabetic detection. At first, the preprocessing step is carried out using adaptive histogram equalization (AHE) for enhancing the input retinal image. Consequently, blood vessel segmentation and exudates segmentation are done using convolution neural network (CNN) and fuzzy c-means clustering (FCM) respectively. Then, texture features are extracted from blood vessel and exudates. After the feature extraction, the diabetic classification is done with the help of support vector machine. The experimental results demonstrate that the proposed approach accomplishes better diabetic detection result (accuracy, sensitivity, and specificity) compared to other approaches. © 2019, Pleiades Publishing, Ltd.","Blood; Blood vessels; Classification (of information); Convolution; Equalizers; Extraction; Eye protection; Fuzzy inference; Fuzzy neural networks; Fuzzy systems; Graphic methods; Image enhancement; Image segmentation; Ophthalmology; Support vector machines; Textures; Vision, Adaptive histogram equalization; Adaptive histogram equalizations (AHE); Blood vessel segmentation; Convolution neural network; Diabetic retinopathy; Fuzzy C means clustering; Pre-processing step; Texture feature extraction, Feature extraction"
"Chowdhury MS,Taimy FR,Nahid AA,Ali MY,Bin Ali F",Retinal Fundus Identification Utilizing Supervised and Unsupervised Nature of Deep Neural Network,2019,"Eye disease has become serious concern to people, specially who have been suffering from diabetes. Systematic eye diseases are manifest in around the retina of an eye. Digital photography of the retinal images provide a significant information about the disease. This kind of retinal images work as a powerful source for the doctors and ophthalmologist to take meaningful decision about the disease. This kind of Computer Aided Diagnosis(CAD) allow both the doctors and patient to take a second layer of satisfaction. Considering this issues, this paper segmented the retinal vessel images using the state-of-the- art Deep Neural Network(DNN) such as a combination of U-Net and Generative Adversarial Network (GAN) model. As the retinal images suffers due to the Contrast and Illumination problems, this paper also proposed two preprocessing algorithms to reduce this effect. © 2019 IEEE.","Computer aided diagnosis; Image segmentation; Medical computing; Ophthalmology; Robotics, Accuracy; Adversarial networks; Augmentation; CLAHE; Computer Aided Diagnosis(CAD); Digital photography; Pre-processing algorithms; State of the art, Deep neural networks"
"Shalini R,Sasikala S",A survey on detection of diabetic retinopathy,2019,"Visual perception is very important for human life. Although several medical conditions can cause retinal disease, the most common cause is diabetes. Diabetic Retinopathy (DR) can be identified using retinal fundus images. Detection and classification of deformation in Diabetic retinopathy is a challenging task since it is symptomless. Several algorithms were analyzed for the identification of abnormality. The analysis of different models in detecting the abnormalities from the image is done which includes various preprocessing techniques to standardize the image and post-processing techniques are applied for morphological adjustments, segmentation algorithms for segmenting the Lesion of Interest(LOI ) namely white lesions and red lesions, further feature extraction methods extracts the features like Micro Aneurysms, Hemorrhages, Exudates and Cotton Wool Spots and so on finally, classification methods were utilized which concludes the presence or absence of DR symptoms along with the severity based on the count of the features extracted in the given retinal image. This survey study aims to develop a novel algorithm to identify and detect types of above mentioned diseases and find out the severity of those diseases also examine with 100% accuracy. © 2018 IEEE.","Cotton; Eye protection; Feature extraction; Internet of things; Ophthalmology; Surveys; Wool; Yarn, Cotton-wool spots; Diabetic retinopathy; Exudates; Hemorrhages; Lesion of Interest; Micro Aneurysms, Image segmentation"
"Yang X,Fang T,Li Y,Guo L,Li F,Huang F,Li L",Pre-diabetes diagnosis based on ATR-FTIR spectroscopy combined with CART and XGBoots,2019,"A rapid diagnosis model of pre-diabetes was established by using Attenuated total reflectance (ATR)-Fourier transform infrared spectroscopy (FTIR) combined with Classification and Regression Trees (CART) and eXtreme Gradient Boosting (XGBoost) ensemble learning algorithm. First, we collected peripheral blood samples of 112 volunteers and then measured the fasting blood glucose and 2h blood glucose levels of the oral glucose tolerance test, and determined the control group and the disease group according to the WHO diagnostic criteria (including impaired fasting glucose (IFG). Impaired glucose tolerance (IGT).In addition, ATR-FTIR spectra of peripheral blood samples were collected at the same time. The whole spectrum mid-infrared region (4000–600 cm?1) was used as the research object of diagnosis model of pre-diabetes. Second, preprocessing step, Savitzky-Golay (SG) smoothing pretreatment was performed and used PCA to extract spectral features. Finally, a rapid diagnosis model of pre-diabetes was established by using CART and XGBoost. CART model results were: Specificity: 80.00% (20/25), Sensitivity: 95.00% (19/20), Accuracy: 86.67% (39/45); XGBoost model results: Specificity: 100.00% (25/25), Sensitivity were: 85.00% (17/20)), Accuracy: 93.33% (42/45).The results show that the rapid diagnosis model of pre-diabetes was established by SG-PCA-XGBoost which has the best effect. Hence, the model established by ATR-FTIR spectra combined with SG-PCA-XGBoost in the experiment can more effectively diagnose pre-diabetes. This model needs no sample preprocessing; it is characterized by simple operation and time efficiency. Furthermore, the established model provides a fast accurate method for pre-diabetes diagnosis. © 2018","Blood; Computer aided diagnosis; Disease control; Glucose; Supersaturation; Trees (mathematics), ATR FTIR; Attenuated total reflectance; CART; Classification and regression tree; Diabetes diagnosis; Impaired glucose tolerances; Oral glucose tolerance tests; XGBoots, Fourier transform infrared spectroscopy"
"Zhang H,Hung CL,Chu WC,Chiu PF,Tang CY",Chronic Kidney Disease Survival Prediction with Artificial Neural Networks,2019,"The main objective of this work is to investigate the performance of Artificial Neural Network (ANN) models while applying to the survivability prediction on Chronic Kidney Disease (CKD) patients. Chronic kidney disease patients suffer from losing the primary function of the kidney, i.e., blood filtration, gradually over time. At the end stage, regular hemodialysis or kidney transplant are required to survive. During the process of disease development, patients may also suffer from complications of acidosis, anemia, diabetes, high blood pressure or neuropathy, etc., which in turn affects patients' quotidian life. It is reported that the median survival time of late-stage patients is only about 3 years. Evaluating precisely the condition of patients is of great importance as it would greatly help to decide appropriate care, medications or medical interventions needed, which among them have a complex interrelationship and influence the outcome of the individual patient. An accurate prediction model would hopefully be able to fit into that role and may be used to revise current treatment. However, due to the complex nature of the problem, as multiple interrelated factors may influence the patient's survival, finding such a model is a challenging task. Recently, artificial intelligence (AI), especially the deep learning technique has become a thriving field, owing to the rise of computational capability. As the approach needs no human specialist in specifying explicit knowledge in advance, but gathers knowledge automatically from amounts of data by building a hierarchy of concepts with complicated ones upon simpler ones, it has already been applied successfully in intuitive problems, like understanding speeches or images, making diagnoses in medicine or self-driving cars, etc. And conversely, technological advancements have been made available through practical applications, profiting from which we may develop prediction models for chronic kidney disease survivability. In this research, data preprocessing, data transformations, and artificial neural networks are used to establish the mapping from many clinical factors to the patient's survival. The computational results are also reported in the paper. © 2018 IEEE.","Bioinformatics; Blood pressure; Classification (of information); Clinical research; Complex networks; Deep learning; Forecasting; Neural networks; Patient treatment, Artificial neural network models; Chronic kidney disease; Computational capability; Computational results; High blood pressures; LASSO; Medical intervention; Technological advancement, Diagnosis"
"Qureshi I,Ma J,Shaheed K",A Hybrid Proposed Fundus Image Enhancement Framework for Diabetic Retinopathy,2019,"Diabetic retinopathy (DR) is a complication of diabetes and is known as visual impairment, and is diagnosed in various ethnicities of the working-age population worldwide. Fundus angiography is a widely applicable modality used by ophthalmologists and computerized applications to detect DR-based clinical features such as microaneurysms (MAs), hemorrhages (HEMs), and exudates (EXs) for early screening of DR. Fundus images are usually acquired using funduscopic cameras in varied light conditions and angles. Therefore, these images are prone to non-uniform illumination, poor contrast, transmission error, low brightness, and noise problems. This paper presents a novel and real-time mechanism of fundus image enhancement used for early grading of diabetic retinopathy, macular degeneration, retinal neoplasms, and choroid disruptions. The proposed system is based on two folds: (i) An RGB fundus image is initially taken and converted into a color appearance module (called lightness and denoted as J) of the CIECAM02 color space model to obtain image information in grayscale with bright light. Afterwards, in step (ii), the achieved J component is processed using a nonlinear contrast enhancement approach to improve the textural and color features of the fundus image without any further extraction steps. To test and evaluate the strength of the proposed technique, several performance and quality parameters-namely peak signal-to-noise ratio (PSNR), contrast-to-noise ratio (CNR), entropy (content information), histograms (intensity variation), and a structure similarity index measure (SSIM)-were applied to 1240 fundus images comprised of two publicly available datasets, DRIVE and MESSIDOR. It was determined from the experiments that the proposed enhancement procedure outperformed histogram-based approaches in terms of contrast, sharpness of fundus features, and brightness. This further revealed that it can be a suitable preprocessing tool for segmentation and classification of DR-related features algorithms. © 2018 by the authors.","Angiography; Color; Color computer graphics; Eye protection; Grading; Graphic methods; Image segmentation; Luminance; Ophthalmology; Signal to noise ratio, Color modeling; Contrast Enhancement; Diabetic retinopathy; Histogram-based enhancement procedures; Nonlinear contrast enhancement, Image enhancement"
"Staal OM,Salid S,Fougner A,Stavdahl O",Kalman smoothing for objective and automatic preprocessing of glucose data,2019,"A method for preprocessing a time series of glucose measurements based on Kalman smoothing is presented. Given a glucose data time series that may be irregularly sampled, the method outputs an interpolated time series of glucose estimates with mean and variance. The method can provide homogenization of glucose data collected from different devices by using separate measurement noise parameters for differing glucose measurement equipment. We establish a link between the ISO 15197 standard and the measurement noise variance used by the Kalman smoother for self-monitoring of blood glucose (SMBG) measurements. The method provides phaseless smoothing, and it can automatically correct errors in the original datasets like small fallouts and erroneous readings when surrounding data allow. The estimated variance can be used for deciding at which times the data are trustworthy. The method can be used as a preprocessing step in many kinds of glucose data processing and analysis tasks, such as computing the mean absolute relative deviation between measurement systems or estimating the plasma-to-interstitial fluid glucose dynamics of continuous glucose monitor or flash glucose monitor (FGM) signals. The method is demonstrated on SMBG and FGM glucose data from a clinical study. A MATLAB implementation of the method is publicly available. © 2013 IEEE.","Blood; Data handling; Homogenization method; Kalman filters; MATLAB; Spurious signal noise; Sugars; Time measurement; Time series, Biomedical measurements; Data processing and analysis; Glucose measurements; Interstitial fluids; Noise measurements; Pre-processing step; Relative deviations; Smoothing methods, Glucose, glucose; insulin, accuracy; algorithm; Article; blood glucose monitoring; comparative study; data processing; diabetes mellitus; dynamics; glucose blood level; human; mathematical model; signal noise ratio; theoretical model; algorithm; analysis; blood analysis; glucose blood level; procedures; signal processing; standards; statistical model, Algorithms; Blood Chemical Analysis; Blood Glucose; Humans; Models, Statistical; Signal Processing, Computer-Assisted"
"Alassaf RA,Alsulaim KA,Alroomi NY,Alsharif NS,Aljubeir MF,Olatunji SO,Alahmadi AY,Imran M,Alzahrani RA,Alturayeif NS",Preemptive Diagnosis of Diabetes Mellitus Using Machine Learning,2018,"Diabetes Mellitus (DM) is one of the most prevalent chronic diseases in the world with around 150 million patients. Patients with chronic diseases are highly susceptible to deterioration in their physical and mental health; consequently, hindering their independence, restricting their daily activities imposing a large financial burden on them and the government. If not discovered early, chronic diseases may lead to serious health complications or in extreme cases, death. Diagnostic solutions have been explored using intelligent methods, however, different ethnic groups have variant factors leading to the development of a disease. Therefore, the proposed system aims to preemptively diagnose DM in a region never explored before. Data are retrieved from King Fahd University Hospital (KFUH) in Khobar, Saudi Arabia. Data undergoes preprocessing to identify relevant features and prepare for identification/classification process. Experimental results show that ANN outperformed SVM, Naïve Bayes, and K-Nearest Neighbor with the testing accuracy of 77.5%. © 2018 IEEE.","Barium compounds; Deterioration; Diseases; Motion compensation; Nearest neighbor search; Neural networks; Support vector machines, Chronic disease; Diabetes mellitus; Health complications; Intelligent method; K-nearest neighbors; Relevant features; Testing accuracy; ve Bayes, Diagnosis"
"Xie H,Ahmadon MA,Yamaguchi S",Evaluation of Rough Sets Data Preprocessing on Context-Driven Semantic Analysis with RNN,2018,"In the application examples of NLP (natural language learning), the rich semantic information in medical literature can extract characteristic target words through the training of RNN-LSTM (recurrent neural network-long short-term memory). In the process of extracting these target words, we often encounter some wrong target words which cause RNN to reduce the hit rate and extend the training time. In this paper, we take Diabetes in medical research as an example, the data preprocessing of rough sets, and the word vector tagging for target word can improve the hit efficiency of the target words in the RNN-LSTM training process. © 2018 IEEE.","Natural language processing systems; Rough set theory; Semantics, Application examples; Data preprocessing; Medical; Medical literatures; Natural language learning; Semantic analysis; Semantic information; Training process, Long short-term memory"
"Qrenawi MI,Al Sarraj W",Identification of Cardiovascular Diseases Risk Factors among Diabetes Patients Using Ontological Data Mining Techniques,2018,"Healthcare environment is rich of data, but still needs knowledge extraction that is necessarily important for saving people lives. Medical Knowledge discovery is a process of extracting knowledge patterns from biomedical data, which is useful and crucial for making effective decisions especially in developing strategies and policies of preventive medical treatments. Data mining methods are the best-known way to recognize the hidden data standards. Ontology engineering used to improve knowledge domain representation, and further is considered for the enhancement and refinement of the mining techniques based on the discovered patterns driven from ontological data mining. In this paper, we apply ontology driven data mining techniques on a data set of diabetes patients who have cardiovascular disease. That process performed to identify the relationship between type two diabetes mellitus patients and their important laboratory tests specified by doctors. Doctors aim to investigate the probability of cardiovascular disease occurrence and stroke happening. Ontology driven Data mining techniques also used in experimental study as well as rule induction, association rules methods. In a late phase, we used frequent pattern discovery and rules induction method using ontological data mining algorithm (RMonto). The findings of this study reveals that the use of ontologies minimizes the number of attributes in the preprocessing stage and helps in all data mining stages; in addition to its important role in ontological data mining, we have a higher learning accuracy ratio exceeding 90%. The results of data mining methods and ontological data mining shows that the significance of some laboratory tests like: LP(a),CRP,HDL,FBG,TG,LDH and Chol to predict CVD risk among T2DM patients with a high accuracy. © 2018 IEEE.","Cardiology; Diseases; Medical education; Ontology, Cardio-vascular disease; cardiovascular; Data mining algorithm; Frequent pattern discovery; Healthcare environments; Medical knowledge discovery; Pre-processing stages; T2DM, Data mining"
"Suryakala SV,Prince S",Chemometric analysis of diffuse reflectance spectral data using singular value decomposition for blood glucose detection,2018,Diabetes mellitus is a metabolic disorder that affects the production or usage of insulin by the body. Diabetes prevails in the body as a long-term condition which causes several other disorders if left unnoticed. Proper control of Diabetes needs continuous monitoring. The current measurement technique is invasive in nature and requires the withdrawal of blood from the body. Periodic quantification of blood glucose leads to pain and discomfort for the subject. This paper presents a non-invasive glucose measuring system using near-infrared diffuse reflectance spectroscopy (DRS). This work attempts to determine the blood glucose value from the diffuse reflected spectra in the NIR region. The study is executed with the spectral signatures of 33 diabetic subjects collected non-invasively using diffuse reflectance spectrometer from a diabetic centre. Blood glucose level of the same subjects are also recorded using the clinical method. The spectral information is subjected to standard normal variate (SNV) preprocessing method to remove baseline drift and then dimension reduction using singular value decomposition (SVD) is applied to the preprocessed data. The extracted singular values when compared with the clinically measured blood glucose is found to have a proportional relationship. The proposed study using singular value decomposition paves us the way for estimating the blood glucose value non-invasively with the obtained set of clinical blood glucose and the corresponding singular value table as a standard reference set. © 2018 National Taiwan University.,"Blood; Glucose; Infrared devices; Reflection; Spectrometers; Spectroscopy, Blood glucose; Blood glucose detection; Diffuse reflectance spectroscopy; Glucose measuring systems; Measurement techniques; Near infrared diffuse reflectance; Proportional relationships; Standard normal variates, Singular value decomposition, glucose, adult; aged; Article; chemometric analysis; clinical article; decomposition; diabetic patient; diffuse reflectance spectroscopy; female; glucose absorption; glucose blood level; human; male; middle aged; near infrared spectroscopy; particle size; venous blood"
"Kurale NG,Vaidya MV",Retinal Hemorrhage Detection Using Splat Segmentation of Retinal Fundus Images,2018,"Diabetic Retinopathy is a condition caused because of diabetes, which can lead to severe loss of vision. It occurs due to damage of retinal blood vessels and leaking fluids from vessels. This results into total vision loss. Detecting DR at earlier stage, helps to treat early and save from severe damage to eye. To detect hemorrhages effectively, a new algorithm is evaluated. Firstly the important factor is preprocessing like edge effect removal, contrast enhancement etc. for better result. This algorithm does partitions to the retinal image into segments which is called as splats which is of same color, intensity and spatial location. Each splat contains various information from which we can extract different features. These segments i.e splat establish a set of information which extracts appropriate boundary. We select some important features from all extracted features like different filters, area, color, texture and splat related features etc. And a trained supervised SVM classifier is used to detect the disease. © 2017 IEEE.","Blood vessels; Classification (of information); Damage detection; Eye protection; Image segmentation, Contrast Enhancement; Diabetic retinopathy; Important features; Retinal blood vessels; Retinal fundus images; Retinal hemorrhages; Spatial location; Watershed transform, Ophthalmology"
"Bhuvaneswari G,Manikandan G",A novel machine learning framework for diagnosing the type 2 diabetics using temporal fuzzy ant miner decision tree classifier with temporal weighted genetic algorithm,2018,"Diabetic is becoming a very serious disease today for the most of people all over the world due to the unhealthy food habits. For predicting the diabetes, we introduce a new diabetic diagnosis system which combines a newly proposed temporal feature selection and temporal fuzzy ant miner tree (TFAMT) classifier for effective decision making in type-2 diabetes analysis. Moreover, a new temporal weighted genetic algorithm is proposed in this work for enhancing the detection accuracy by preprocessing the text and image data. Moreover, intelligent fuzzy rules are extracted from the weighted temporal capabilities with ant miner fuzzy decision tree classifier, and then fuzzy rule extractor is used to reduce the variety of functions in the extracted regulations. We empirically evaluated the effectiveness of the proposed TFAMT–TWGA model using the UCI Repository dataset and the collected retinopathy image dataset. The outcomes are analyzed and as compared with other exiting works. Furthermore, the detection accuracy is proven by way of using the ten-fold cross validation. © 2018, Springer-Verlag GmbH Austria, part of Springer Nature.","Behavioral research; Decision making; Decision trees; Diagnosis; Fuzzy inference; Fuzzy rules; Genetic algorithms; Image enhancement; Learning systems; Miners; Trees (mathematics), Ant miners; Cross validation; Decision tree classifiers; Detection accuracy; Diabetic diagnosis; Fuzzy decision trees; TFAMT; TWGA, Data mining"
"Lei X,Feng C",The establishment of diabetes diet classification model based on BL-WSmote,2018,"This paper analyzes the daily diet recipe of diabetes from traditional Chinese medicine diet, and establishes a model to determine the type of diabetes. The process of building a model is as follows. Firstly, use improved Smote algorithm to do data preprocessing. Secondly, using GA to optimize Random Forest do attribute reduction. Finally, using Bagging establish model. We establish 3 sets of comparison experiments. The comparison of 4 different algorithms between Random Forest, GDBT, Ada Booster, Bagging 4 different algorithms; The comparison between raw data, Smote improved data, BL-Smote improved data, BL-WSmote improved; The comparison between the whole attributes and the important attributes. The model accuracy is as high as 92%, it is proved that this model has certain applicable value in determining diabetes classification. © 2018 Association for Computing Machinery.","Medical problems; Medicine, Attribute reduction; Classification models; Data preprocessing; Model accuracy; Random forests; SMOTE algorithm; Strong classifiers; Traditional Chinese Medicine, Decision trees"
"Badgujar RD,Deore PJ",Region Growing Based Segmentation Using Forstner Corner Detection Theory for Accurate Microaneurysms Detection in Retinal Fundus Images,2018,"Several diseases have adverb effect on visual system of human visual system (eye) and diabetes is leading one among them. Prolong and uncontrolled diabetic patient is prone to Diabetic Retinopathy (DR). DR is asymptomatic disease hence requires detection in early stages to avoid big loss in vision. It shows immediate necessity of screening system to access eye images and analyze for DR detection. Microaneurysms (MAs) are primary lesion of DR, so their detection can give time for patient and ophthalmologist to prevent further vision loss. Region growing segmentation method is proposed for accurate detection of MAs. The preprocessing of retinal images uses non local means (NLM) filter and contrast limited adaptive histogram equalization (CLAHE) for noise removal and enhancement image quality. In segmentation, region growing algorithm in which the seeds for the grower are selected and positioned by means of Forstner Corner Detection theory is utilized. After segmentation, the redundant areas are removed using morphological operations (Niblack Adaptive Thresholding) and finally the Predator prey optimizer is used for optimizing the features for MA detection. © 2018 IEEE.","Computation theory; Diagnosis; Eye protection; Image denoising; Image enhancement; Image segmentation; Mathematical morphology; Ophthalmology, Corner detection; Diabetic retinopathy; Microaneurysms; Predator- preys; Region growing, Edge detection"
"Suriyal S,Druzgalski C,Gautam K",Mobile assisted diabetic retinopathy detection using deep neural network,2018,"Diabetic retinopathy (DR) is a major microvascular complication resulting from diabetes and continues to have a serious impact on global health systems. Globally about 95 million people suffer from DR. This paper focuses on detection aspects of a mobile application developed to perform DR screening in real time. The application is powered by a tensorflow deep neural network architecture that is trained and tested on 16,798 fundus images. These images are preprocessed to remove noise and prepare them to be fed into neural network. Preprocessing steps involve averaging all the images using a 5×5 filter to improve the quality of images and then these images are resized to 256×256 pixels. After preprocessing the input dataset is fed into the neural network. The convolutional neural network model used in this project is MobileNets, which is used for mobile devices. The neural network has 28 convolutional layers and after each layer there is batchnorm and ReLU nonlinear function except at the final layer. The output from last layer is a class label either DR or no DR. The final accuracy of the model is 73.3%. This model is optimized to work on mobile devices and does not require Internet connection to run. © 2018 IEEE.","Biomedical engineering; Convolution; Deep learning; Diagnosis; Eye protection; Image enhancement; mHealth; Mobile devices; Network architecture; Neural networks, Convolutional neural network; Diabetic retinopathy; Internet connection; Microvascular; Mobile applications; Nonlinear functions; Pre-processing step; tensorflow, Deep neural networks"
"Vahedi MR,MacBride KB,Wunsik W,Kim Y,Fong C,Padilla AJ,Pourhomayoun M,Zhong A,Kulkarni S,Arunachalam S,Jiang B",Predicting glucose levels in patients with type1 diabetes based on physiological and activity data,2018,"Managing blood glucose levels for type 1 diabetes patients is an absolute necessity to better glycemic control. In this paper, we present a predictive model that usesphysiological measurements and physical activity to predict continuous glucoselevels and help patients reduce and prevent hyperglycemia and hypoglycemia exposure, conditions that are harmful to patient health.The data of this research includes 4 months of physiological measurements, physical activity, and nutrition information collected from 93 patients with diabetes using the Medtronic MiniMed™ 530G insulin delivery system with Enlite™ sensor. Afterdata preprocessing, missing value imputation, feature extraction, and feature selection, a set of 180 featureswere derived to represent the raw data. Then, an appropriatepredictive model was developedbased on machine-learning algorithms to predict continuous glucose levels. The prediction accuracy and error have been calculated to evaluate the performance of the system. The results demonstratedthat the predictedglucose levelsclosely followed the actual sensor glucose (SG)values measuredby subcutaneous glucose sensor. © 2018 ACM.","Blood; Feature extraction; Forecasting; Glucose sensors; Health care; Insulin; Learning algorithms; Learning systems; Medical problems; Physiological models; Predictive analytics, Blood glucose; Blood glucose level; Insulin delivery system; Missing value imputation; Nutrition informations; Physiological measurement; Prediction accuracy; Predictive modeling, Glucose"
"Wei S,Zhao X,Miao C",A comprehensive exploration to the machine learning techniques for diabetes identification,2018,"Diabetes mellitus, known as diabetes, is a group of metabolic disorders and has affected hundreds of millions of people. The detection of diabetes is of great importance, concerning its severe complications. There have been plenty of research studies about diabetes identification, many of which are based on the Pima Indian diabetes data set. It's a data set studying women in Pima Indian population started from 1965, where the onset rate for diabetes is comparatively high. Most of the research studies done before mainly focused on one or two particular complex technique to test the data, while a comprehensive research over many common techniques is missing. In this paper, we make a comprehensive exploration to the most popular techniques (e.g. DNN (Deep Neural Network), SVM (Support Vector Machine), etc.) used to identify diabetes and data preprocessing methods. Basically, we examine these techniques by the accuracy of cross-validation on the Pima Indian data set. We compare the accuracy of each classifier over several ways of data preprocessors and we modify the parameters to improve their accuracy. The best technique we find has 77.86% accuracy using 10-fold cross-validation. We also analyze the relevance between each feature with the classification result. © 2018 IEEE.","Artificial intelligence; Deep neural networks; Internet of things; Learning systems; Population statistics; Support vector machines, 10-fold cross-validation; Classification results; Comprehensive research; Data preprocessing; Machine learning techniques; Metabolic disorders; Pima Indian Diabetes; SVM(support vector machine), Classification (of information)"
"Prasannan V,Kumar CS,Deepa V",An automated approach for diagnosing diabetic retinopathy in retinal fundus images,2018,"Diabetes mellitus and its associated complications, including diabetic retinopathy (DR) have been identified as a growing global public health problem. Early treatment and constant monitoring of DR can prevent 90 percent of visual loss. Manual screening of fundus images by ophthalmologists is tedious and time consuming. Hence, a computer-aided diagnosis system can significantly act as an efficient solution for the time consuming detection process. The propounded algorithm includes various stages such as pre-processing, feature extraction and classification. In literature, different approaches for preprocessing such as dual guassian, second derivative of Guassian and Gabor filter, mathematical morphology, K-mean clustering algorithms etc. are employed. In the proposed algorithm, preprocessing was done using Adaptive Histogram Equalization (AHE) and image de-noising using non-local means (NLM) filter. NLM takes the means of all the neighbouring pixels and weightage is given by checking the similarity between these pixels to the target pixel. Laplacian edge detection, by identifying the zero crossings of the second derivatives of the image intensity was used in both the methods. In the feature extraction stage, features like HOG, area, perimeter, mean and standard deviation are extracted. Lastly, Support Vector Machines (SVM) algorithm, k-nearest neighbours (KNN) and Artificial Neural Network (ANN) was used for the categorization of the images to healthy and diseased. The comparison on the functioning of AHE and NLM validates that NLM outperforms AHE. Parameters like accuracy, error rate, specificity, and precision were used to analyze the working of the classifiers. SVM with 0.875 accuracy, 0.12 error rate, 0.75 specificity and 0.80 precision outperformed well when analogized to the other methods. © 2018 IEEE.","Computer aided diagnosis; Extraction; Eye protection; Feature extraction; Gabor filters; K-means clustering; Mathematical morphology; Nearest neighbor search; Neural networks; Ophthalmology; Pixels; Support vector machines, Adaptive histogram equalizations (AHE); Computer aided diagnosis systems; Diabetic retinopathy; Feature extraction and classification; Fundus image; K nearest neighbours (k-NN); Mean and standard deviations; Support vector machines algorithms, Image denoising"
"Bohacik J,Zabovsky M",Naive Bayes for statlog heart database with consideration of data specifics,2018,"Heart disease belongs to one of the main reasons for mortality nowadays and it is expected to become worse due to factors such as aging, diabetes and obesity. In addition, existing misdiagnosis of patients reporting heart related ailment worsens this situation even further. In the paper, a probability approach to recognition of heart disease is analyzed with the employment of Naive Bayes on Statlog Heart Database and with the search of data preprocessing techniques for its improvement. A discretization algorithm of numerical attributes which takes the specifics of given heart disease patients into account is presented. It is based on supervised discretization with consideration of Equal Frequency Discretization. Experiments making use of 10-fold cross-validation show improvements of accuracy which are measured with sensitivity, specificity and their sum and the results are also compared with other classification algorithms. © 2017 IEEE.","Cardiology; Classification (of information); Classifiers; Diseases, 10-fold cross-validation; Classification algorithm; Data preprocessing technique; Discretization algorithms; Heart disease; Naive bayes; Probability approach; Supervised discretization, Heart"
"Karule PT,Joshi S",Blood vessels segmentation using thresholding approach for fundus image analysis,2018,"The principal target of blood vessels detection algorithm is to early detecting the diabetes in advanced stages by comparison of its states of retinal blood vessels. Due to relatively low contrast, potential presence of dark pathologies like microaneurysms and hemorrhages and variable size of blood vessels, segmentation of blood vessels is a nontrivial task. The dictum of work present in this paper is local thresholding approach, which can be used in computer based retinal image analysis to extract the retinal image vessels. To enhance the blood vessels and suppress the background information, we performed preprocessing operation on the retinal image. Then the enhanced image is segmented using local thresholding algorithm. The proposed approach is tested on the DRIVE dataset and is compared with alternative approaches. Experimental results obtained by the proposed approach show that it is effective when this obtained the average accuracy of 96.02% and best accuracy of 97.2%. © 2017 IEEE.","Computer aided analysis; Image analysis; Image enhancement; Image segmentation; Intelligent computing; Ophthalmology, Background information; Detection algorithm; Fundus image; Local thresholding; Non-trivial tasks; Pre-processing operations; Retinal blood vessels; Retinal image analysis, Blood vessels"
"Ali M,Ali R,Khan WA,Han SC,Bang J,Hur T,Kim D,Lee S,Kang BH",A Data-Driven Knowledge Acquisition System: An End-to-End Knowledge Engineering Process for Generating Production Rules,2018,"Data-driven knowledge acquisition is one of the key research fields in data mining. Dealing with large amounts of data has received a lot of attention in the field recently, and a number of methodologies have been proposed to extract insights from data in an automated or semi-automated manner. However, these methodologies generally target a specific aspect of the data mining process, such as data acquisition, data preprocessing, or data classification. However, a comprehensive knowledge acquisition method is crucial to support the end-to-end knowledge engineering process. In this paper, we introduce a knowledge acquisition system that covers all major phases of the cross-industry standard process for data mining. Acknowledging the importance of an end-to-end knowledge engineering process, we designed and developed an easy-to-use data-driven knowledge acquisition tool (DDKAT). The major features of the DDKAT are: (1) a novel unified features scoring approach for data selection; (2) a user-friendly data processing interface to improve the quality of the raw data; (3) an appropriate decision tree algorithm selection approach to build a classification model; and (4) the generation of production rules from various decision tree classification models in an automated manner. Furthermore, two diabetes studies were performed to assess the value of the DDKAT in terms of user experience. A total of 19 experts were involved in the first study and 102 students in the artificial intelligence domain were involved in the second study. The results showed that the overall user experience of the DDKAT was positive in terms of its attractiveness, as well as its pragmatic and hedonic quality factors. © 2013 IEEE.","Automation; Classification (of information); Data acquisition; Data handling; Data structures; Decision trees; Feature extraction; Knowledge acquisition; Knowledge engineering; Production; Trees (mathematics), Algorithm selection; Decision tree classification; Decision-tree algorithm; Features rankings; Knowledge acquisition systems; Knowledge acquisition tools; Production rules; User experience, Data mining"
"Saraswati GW,Choo YH,Kumar YJ",Developing diabetes ketoacidosis prediction using ANFIS model,2018,"This paper proposes the adaptive Neuro-fuzzy Inference System (ANFIS) to construct a diabetic ketoacidosis prediction model. Diabetic ketoacidosis results in large amount of ketones can be detected in urine through distinctive odour of acetone. Hence, urine odour analysis is able to diagnose diabetic ketoacidosis facilitating dianogstic test for diabetic patient. The Electronic Nose (E-nose) system consists of four metal oxide gas sensors was used to extract urine odour. Common process of diabetic diagnosis require patient to provide fasting urine for more accurate detection. Our work has shown both fasting and non-fasting urine are able to produce good diabetic detection accuracy through urine odour analysis. A total of 40 human subjects from CITO Laboratory, Semarang Central Java, Indonesia, involving 20 diabetic patients and 20 healthy subjects were used to build the prediction model. The proposed model has achieved at least 63% average accuracy in discriminating diabetic patient from healthy subject. When data preprocessing to average the training data samples was implemented, the detection performance was increased to above 93% The findings have shown promising results of using both fasting and non-fasting data samples for diabetic prediction. This is essential towards the flexibility of diabetic dianogstic test where it does not require patient to fast, therefore can be tested at anytime anywhere. © 2017 IEEE.","Acetone; Body fluids; Diagnosis; Electronic nose; Forecasting; Fuzzy neural networks; Fuzzy systems; Metals; Robotics, Adaptive neuro fuzzy inference systems (ANFIS); Data preprocessing; Detection performance; Diabetic diagnosis; Electronic nose (e-nose); Ketoacidosis; Metal oxide gas sensors; Odour analysis, Fuzzy inference"
"Qomariah DU,Tjandrasa H",Exudate detection in retinal fundus images using combination of mathematical morphology and Renyi entropy thresholding,2018,"Diabetic retinopathy (DR) is a microvascular complication of diabetes, causing abnormalities in the retina, and it is can cause blindness. Diabetic retinopathy can be detected by the appearance of hard exudates. Hard exudates are lipid formations leaking from these weakened blood vessels. Automatic detection of exudates is an early handler to diagnose diabetic retinopathy. This research proposed automatic detection of exudates using Renyi entropy thresholding and mathematical morphology. Renyi entropy thresholding has a controlling variable so that the obtained threshold value is more optimal. The proposed method using Renyi entropy thresholding and mathematical morphology has three stages: (1) preprocessing using contrast enhancement, (2) initial exudates detection based on mathematical morphology, and (3) exudates detection based on Renyi entropy thresholding. The test was performed using measurement evaluation method, sensitivity, specificity, and accuracy were 85.06%, 99.63%, and 99.54% respectively. © 2017 IEEE.","Blood vessels; Data communication systems; Eye protection; Image segmentation; Morphology, Automatic Detection; Contrast Enhancement; Diabetic retinopathy; Exudate; Exudate detections; Measurement evaluations; Retinal fundus images; Thresholding, Mathematical morphology"
"Adelina DC,Sigit R,Harsono T,Rochmad M",Identification of diabetes in pancreatic organs using iridology,2017,"Diabetes is a general disease often infected in humans. Many ways to detect diabetes, one of them is checking blood pressure, but this way is not effective, because it takes blood first and take a lot of time. Iridology is one way analysis health based on the iris. Therefore we need a tool used to identify pancreatic damage as an indication of diabetes through iridology. Load image is the first step to identify pancreatic organs based on the iris. The eye image that we used as the input system comes from the eye clinic database. The next step is adaptive median filtering used in the process preprocessing to reduce the noise on the image. After that the next step is segmentation process using hough circle transform method. The results of segmentation will be normalized and take the Region of interest. ROI will be done feature extraction by using GLCM (Gray Level Co-Occurrence Matrix). To know the condition of pancreas organ using backpropagation method. © 2017 IEEE.","Adaptive filters; Blood pressure; Image processing; Image segmentation; Median filters; Medical problems, Adaptive median filtering; Gray level co-occurrence matrix; Hough circles; Input systems; Iridology; Region of interest; Segmentation process; Transform methods, Intelligent computing"
"Morejón R,Viana M,Lucena C",An Approach to Generate Software Agents for Health Data Mining,2017,"Data mining is a hot topic that attracts researchers of different areas, such as database, machine learning, and agent-oriented software engineering. As a consequence of the growth of data volume, there is an increasing need to obtain knowledge from these large datasets that are very difficult to handle and process with traditional methods. Software agents can play a significant role performing data mining processes in ways that are more efficient. For instance, they can work to perform selection, extraction, preprocessing, and integration of data as well as parallel, distributed, or multisource mining. This paper proposes a framework based on multiagent systems to apply data mining techniques to health datasets. Last but not least, the usage scenarios that we use are datasets for hypothyroidism and diabetes and we run two different mining processes in parallel in each database. © 2017 World Scientific Publishing Company.","Artificial intelligence; Intelligent agents; Learning systems; Multi agent systems; Software agents; Software engineering, Agent Oriented Software Engineering; Data mining process; Data volume; Health data; Large datasets; Mining process; Multisources; Usage scenarios, Data mining"
"Mo J,Zhang L",Multi-level deep supervised networks for retinal vessel segmentation,2017,"Purpose: Changes in the appearance of retinal blood vessels are an important indicator for various ophthalmologic and cardiovascular diseases, including diabetes, hypertension, arteriosclerosis, and choroidal neovascularization. Vessel segmentation from retinal images is very challenging because of low blood vessel contrast, intricate vessel topology, and the presence of pathologies such as microaneurysms and hemorrhages. To overcome these challenges, we propose a neural network-based method for vessel segmentation. Methods: A deep supervised fully convolutional network is developed by leveraging multi-level hierarchical features of the deep networks. To improve the discriminative capability of features in lower layers of the deep network and guide the gradient back propagation to overcome gradient vanishing, deep supervision with auxiliary classifiers is incorporated in some intermediate layers of the network. Moreover, the transferred knowledge learned from other domains is used to alleviate the issue of insufficient medical training data. The proposed approach does not rely on hand-crafted features and needs no problem-specific preprocessing or postprocessing, which reduces the impact of subjective factors. Results: We evaluate the proposed method on three publicly available databases, the DRIVE, STARE, and CHASE_DB1 databases. Extensive experiments demonstrate that our approach achieves better or comparable performance to state-of-the-art methods with a much faster processing speed, making it suitable for real-world clinical applications. The results of cross-training experiments demonstrate its robustness with respect to the training set. Conclusions: The proposed approach segments retinal vessels accurately with a much faster processing speed and can be easily applied to other biomedical segmentation tasks. © 2017, CARS.","algorithm; Article; artificial neural network; back propagation; classifier; disease classification; false negative result; image processing; image segmentation; medical education; priority journal; retina blood vessel; retina image; vascularization; diagnostic imaging; human; retina blood vessel; retina disease; visual system examination, Diagnostic Techniques, Ophthalmological; Humans; Neural Networks (Computer); Retinal Diseases; Retinal Vessels"
"Savelli B,Bria A,Galdran A,Marrocco C,Molinara M,Campilho A,Tortorella F",Illumination Correction by Dehazing for Retinal Vessel Segmentation,2017,"Assessment of retinal vessels is fundamental for the diagnosis of many disorders such as heart diseases, diabetes and hypertension. The imaging of retina using advanced fundus camera has become a standard in computer-assisted diagnosis of opthalmic disorders. Modern cameras produce high quality color digital images, but during the acquisition process the light reflected by the retinal surface generates a luminosity and contrast variation. Irregular illumination can introduce severe distortions in the resulting images, decreasing the visibility of anatomical structures and consequently demoting the performance of the automated segmentation of these structures. In this paper, a novel approach for illumination correction of color fundus images is proposed and applied as preprocessing step for retinal vessel segmentation. Our method builds on the connection between two different phenomena, shadows and haze, and works by removing the haze from the image in the inverted intensity domain. This is shown to be equivalent to correct the nonuniform illumination in the original intensity domain. We tested the proposed method as preprocessing stage of two vessel segmentation methods, one unsupervised based on mathematical morphology, and one supervised based on deep learning Convolutional Neural Networks (CNN). Experiments were performed on the publicly available retinal image database DRIVE. Statistically significantly better vessel segmentation performance was achieved in both test cases when illumination correction was applied. © 2017 IEEE.","Cameras; Computer aided diagnosis; Deep neural networks; Demulsification; Diagnosis; Eye protection; Image processing; Image segmentation; Mathematical morphology; Neural networks; Ophthalmology, Computer assisted diagnosis; Convolutional neural network; Dehazing; Illumination correction; Non-uniform illumination; retina; Retinal vessel segmentations; Vessel segmentation, Color image processing"
"Maulana F,Endah SN",Comparison selection of attributes in preprocessing data for diagnosis of diabetes,2017,"Diabetes is the sixth leading cause of death for all ages in Indonesia according to Indonesia Health Profile 2008. The high mortality rate caused by diabetes causes the need for early detection so that it can be done quickly. In line with technological advances, Diagnosis of diabetes can be done with a system where the system can help detect diabetes accurately based on medical record data of diabetes. The problems that often arise in medical record data processing is the data that amounts to many, the attribute is not relevant, missing value, and vulnerable to outliers so that required efficient data preprocessing so that the resulting accuracy becomes more leverage and computation time becomes more minimal. This study examines the technique of efficient data preprocessing by comparing Backward Elimination (BE), Forward Selection (FS) and Stepwise Regression (SR) algorithms in performing attribute selection, while for diabetic data classification using K-Nearest Neighbor Algorithm. The test was conducted using K-Fold Cross Validation strategy with fold 10 value from medical record data of information management of diabetes disease of Pusat Pertamina Hospital as many as 1260 Data. The results showed that attribute selection in the preprocessing stages of data can improve accuracy in diagnosing diabetes. The highest accuracy is obtained from Stepwise Regression Algorithm on preprocessing data. © 2017 IEEE.","Diagnosis; Genetic algorithms; Information management; Medical problems; Motion compensation; Nearest neighbor search; Pattern recognition, Attribute selection; Backward elimination; K fold cross validations; K nearest neighbor algorithm; Preprocessing Data; Selection of attributes; Stepwise regression; Technological advances, Data handling"
"Piri S,Delen D,Liu T,Zolbanin HM",A data analytics approach to building a clinical decision support system for diabetic retinopathy: Developing and deploying a model ensemble,2017,"Diabetes is a common chronic disease that may lead to several complications. Diabetic retinopathy (DR), one of the most serious of these complications, is the most common cause of vision loss among diabetic patients. In this paper, we analyzed data from more than 1.4 million diabetics and developed a clinical decision support system (CDSS) for predicting DR. While the existing diagnostic approach requires access to ophthalmologists and expensive equipment, our CDSS only uses demographic and lab data to detect patients' susceptibility to retinopathy with a high accuracy. We illustrate how a combination of multiple data preparation and modeling steps helped us improve the performance of our CDSS. From the data preprocessing aspect, we aggregated the data at the patient level and incorporated comorbidity information into our models. From the modeling perspective, we built several predictive models and developed a novel “confidence margin” ensemble technique that outperformed the existing ensemble models. Our results suggest that diabetic neuropathy, creatinine serum, blood urea nitrogen, glucose serum plasma, and hematocrit are the most important variables in detecting DR. Our CDSS provides several important practical implications, including identifying the DR risk factors, facilitating the early diagnosis of DR, and solving the problem of low compliance with annual retinopathy screenings. © 2017 Elsevier B.V.","Artificial intelligence; Body fluids; Diagnosis; Eye protection; Nitrogen plasma; Predictive analytics; Urea, Clinical decision support systems; Data analytics; Diabetic retinopathy; Model ensembles; Predictive modeling; Variable importances, Decision support systems"
"Panwar M,Acharyya A,Shafik RA,Biswas D",K-nearest neighbor based methodology for accurate diagnosis of diabetes mellitus,2017,"Diabetes is one of the leading causes of death, disability and economic loss throughout the world. Type 2 diabetes is more common (90-95% worldwide) type of diabetes. However, it can be prevented or delayed by taking the right care and interventions which indeed an early diagnosis. There has been much advancement in the field of various machine learning algorithms specifically for medical diagnosis. But due to partially complete medical data sets, accuracy often decreases, results in more number of misclassification that can lead t o harmful complications. An accurate prediction and diagnosis of a disease becomes a challenging research problem for many researchers. Therefore, aimed to improve the diagnosis accuracy we have proposed a new methodology, based on novel preprocessing techniques, and K-nearest neighbor classifier. The effectiveness of the proposed methodology is validated with the help of various quantitative metrics and a comparative analysis, with previously reported studies using the same UCI dataset focusing on pima-diabetes disease diagnosis. This is the first work of its kind, where 100% classification accuracy is achieved by feature reduction from eight to two that shows the out performance of the proposed methodology over existing methods. © 2016 IEEE.","Learning algorithms; Learning systems; Losses; Motion compensation; Nearest neighbor search; Pattern matching; Systems analysis, Attribute checking; Classification accuracy; Diabetes mellitus; K-nearest neighbor classifier; K-nearest neighbors; Preprocessing; Preprocessing techniques; Quantitative metrics, Diagnosis"
"Li L,Shan J",Automated Microaneurysm Detection in Fundus Images through Region Growing,2017,"Diabetic retinopathy (DR) is the leading cause of blindness if not detected and treated in time and is a serious complication of diabetes. Since DR is a progressive eye disease, the early detection and diagnosis of DR is important to prevent patients from blindness. One of the most characteristic symptoms of DR is the presence of microaneurysm (MA) - the early sign of DR, which is hard to detect manually due to its small size. In this paper, we propose an automatic MA detection method based on region growing and region classification. We solve two problems: 1) given a fundus image, how to automatically partition the image into regions that may or may not contain MAs through a region growing approach, and 2) given a region in a fundus image, how to automatically evaluate whether this region contains MA by feeding the features of the region into an artificial neural network (ANN) for classification. The proposed approach involves image preprocessing, region growing, feature selection and classification steps. In the experiment, the public dataset DIAbetic RETinopathy DataBase 1 (DIARETDB1) is used to provide training/testing data and ground truth. The proposed method can achieve the performance with sensitivity 86.6%, specificity 96.3%, and accuracy 93.9%, for automatic MA detection. © 2017 IEEE.","Bioinformatics; Classification (of information); Diagnosis; Eye protection; Neural networks, Detection and diagnosis; Detection methods; Diabetic retinopathy; Feature selection and classification; Image preprocessing; Microaneurysms; Region classifications; Region growing, Feature extraction"
"Kurle SS,Maralbhavi NP,Salunke SU,Chandanshive AA",Diabetic retinopathy analysis using CDR technique,2017,"Diabetes has become one of the rapidly increasing health threats worldwide. Diabetes occurs when the pancreas fails to secrete enough insulin, slowly affecting the retina of the human eye. As it progresses, the vision of a patient starts deteriorating, leading to diabetic retinopathy. The diabetic retinopathy is a micro vascular complication of diabetes, causing abnormalities in the retina, and in the worst case, blindness. Typically there are no salient symptoms in the early stages of diabetic retinopathy, but their number and severity predominantly increase with time. The early stage detection of diabetic retinopathy should be done. As detection appears in the early stage the level of the disease can be observed. The hardware developed will help to detect the level of DR. The implementation will be done using fundus images of retina of diabetic retinopathy patient. Preprocessing is done on image and level will be detected along it. Earlier the detection is done by taking the images and processing can be done on it. The project helps provide different stages of diabetic retinopathy, so as to cure it and diagnose it. © 2017 IEEE.","Clock and data recovery circuits (CDR circuits); Control systems; Health risks; Image processing; Intelligent computing; Man machine systems, Cup to disc ratios; Diabetic retinopathy; Different stages; Fundus image; Human eye; Micro aneurysms; Pi models; Vascular complications, Eye protection"
"Dhomse Kanchan B,Mahale Kishor M",Study of machine learning algorithms for special disease prediction using principal of component analysis,2017,"The worldwide study on causes of death due to heart disease/syndrome has been observed that it is the major cause of death. If recent trends are allowed to continue, 23.6 million people will die from heart disease in coming 2030. The healthcare industry collects large amounts of heart disease data which unfortunately are not 'mined' to discover hidden information for effective decision making. In this paper, study of PCA has been done which finds the minimum number of attributes required to enhance the precision of various supervised machine learning algorithms. The purpose of this research is to study supervised machine learning algorithms to predict heart disease. Data mining has number of important techniques like categorization, preprocessing. Diabetic is a life threatening disease which prevent in several urbanized as well as emergent countries like India. The data categorization is diabetic patients datasets which is developed by collecting data from hospital repository consists of 1865 instances with dissimilar attributes. The examples in the dataset are two categories of blood tests, urine tests. In this research paper we discuss a variety of algorithm approaches of data mining that have been utilized for diabetic disease prediction. Data mining is a well known practice used by health organizations for classification of diseases such as diabetes and cancer in bioinformatics research. © 2016 IEEE.","Artificial intelligence; Cardiology; Computer aided diagnosis; Data mining; Decision making; Decision trees; Diseases; Education; Forecasting; Heart; Learning systems; Principal component analysis; Signal processing; Statistical tests; Supervised learning; Supports, Algorithm approaches; Component analysis; Diabetic patient; Health organizations; Healthcare industry; Hidden information; Supervised machine learning; Vector machines, Learning algorithms"
"Ashe SS,Ali I",A new method for detection of optical disc and macula for diabetic retinopathy,2017,"In recent years, the rapid growth of the silent killer, Diabetes, is a major reason of concern for health and also started a buzz among our society. On the same time, World Health Organization (WHO) is a dedicated health organization from United Nations quotes, 'By 2030 diabetes will be one of the seventh leading causes of death, whereas, the global prevalence of diabetes was estimated to be about 9% among adults aged above 18 (measured in 2014)'. Though, diabetes is not completely curable but early stage detection can helps in controlling the degree of severity of this silent killer. One of the controlling factors, which could help in early detection, is the retina of the eye, a light sensitive metabolically active region on which noninvasive observation can possible. As eye is a metabolically active organ, it gets affected at the earliest stage for the people suffering from Diabetes. Thereafter, analyzing the symptoms of retina, like, miroaneurysms, exudates, and edemas can predict the degree of severity. Since, a plan is required towards the studying these symptoms on digital image, the fundus image of the retina, and the detection of attributes, like, miroaneurysms, exudates and edemas. Before carrying out the analysis, it is very essential to properly locate the optic disc and macula which are geometrically important for the detection of Diabetic Retinopathy on digital images. In this paper, we propose intensity based preprocessing algorithm which is suitable for the detection of optic disc (OD) and Macula before the analysis of Diabetic Retinopathy. © 2016 IEEE.","Health; Image processing; Intelligent systems, Diabetic retinopathy; Edema; Health organizations; Macula; Optic disc; Pre-processing algorithms; Retina; World Health Organization, Eye protection"
"Kaur J,Mittal D",A generalized method for the detection of vascular structure in pathological retinal images,2017,"Variations in blood vasculature morphology of retinal fundus images is one of the dominant characteristic for the early detection and analysis of retinal abnormalities. Therefore the accurate interpretation of blood vasculature is useful for ophthalmologists to diagnose patients that suffer from retinal abnormalities. A generalized method to detect and segment blood vasculature using retinal fundus images has been proposed in this work using (i) preprocessing for quality improvement of retinal fundus images, (ii) initial segmentation of vasculature map to find vascular and non vascular structures, (iii) extraction of relevant set of geometrical based features from the vasculature map and intensity based features from original retinal fundus image that differentiate vascular and non vascular structures efficiently, (iv) supervised classification of vascular and non vascular structures using the extracted features, and (v) joining of candidate vascular structures to create connectivity. The proposed method is evaluated on clinically acquired dataset and different publically available standard datasets such as DRIVE, STARE, ARIA and HRF. The clinically acquired dataset consists of 468 retinal fundus images comprising of healthy images, images with mild, intermediate and severe pathologies. Test results of the proposed method shows average sensitivity/specificity/accuracy of 85.43/97.94/95.45 on the 785 retinal fundus images. The proposed method shows an improvement of 14.01% in sensitivity without degrading specificity and accuracy in comparison to the recently published methods. © 2017 Na??cz Institute of Biocybernetics and Biomedical Engineering of the Polish Academy of Sciences",age related macular degeneration; anatomical concepts; Article; controlled study; diabetes mellitus; diabetic retinopathy; diagnostic accuracy; eye fundus; fundus camera; human; image analysis; major clinical study; neovascularization (pathology); optic disk; priority journal; prophylaxis; retina image; sensitivity and specificity; visual impairment; visual system parameters
"Al-Fahdawi S,Qahwaji R,Al-Waisy AS,Ipson S,Malik RA,Brahma A,Chen X",A fully automatic nerve segmentation and morphometric parameter quantification system for early diagnosis of diabetic neuropathy in corneal images,2016,"Diabetic Peripheral Neuropathy (DPN) is one of the most common types of diabetes that can affect the cornea. An accurate analysis of the nerve structures can assist the early diagnosis of this disease. This paper proposes a robust, fast and fully automatic nerve segmentation and morphometric parameter quantification system for corneal confocal microscope images. The segmentation part consists of three main steps. First, a preprocessing step is applied to enhance the visibility of the nerves and remove noise using anisotropic diffusion filtering, specifically a Coherence filter followed by Gaussian filtering. Second, morphological operations are applied to remove unwanted objects in the input image such as epithelial cells and small nerve segments. Finally, an edge detection step is applied to detect all the nerves in the input image. In this step, an efficient algorithm for connecting discontinuous nerves is proposed. In the morphometric parameters quantification part, a number of features are extracted, including thickness, tortuosity and length of nerve, which may be used for the early diagnosis of diabetic polyneuropathy and when planning Laser-Assisted in situ Keratomileusis (LASIK) or Photorefractive keratectomy (PRK). The performance of the proposed segmentation system is evaluated against manually traced ground-truth images based on a database consisting of 498 corneal sub-basal nerve images (238 are normal and 260 are abnormal). In addition, the robustness and efficiency of the proposed system in extracting morphometric features with clinical utility was evaluated in 919 images taken from healthy subjects and diabetic patients with and without neuropathy. We demonstrate rapid (13 seconds/image), robust and effective automated corneal nerve quantification. The proposed system will be deployed as a useful clinical tool to support the expertise of ophthalmologists and save the clinician time in a busy clinical setting. © 2016 Elsevier Ireland Ltd","Algorithms; Anisotropy; Diagnosis; Edge detection; Mathematical morphology; Medical problems; Optical anisotropy, Anisotropic diffusion filtering; Confocal microscope images; Corneal subbasal epithelium; Morphological operations; Morphometric parameters; Nerve segmentations; Peripheral neuropathy; Photorefractive keratectomies, Image segmentation, adult; anisotropy; Article; clinical article; clinical feature; confocal microscopy; controlled study; diabetic neuropathy; diabetic patient; early diagnosis; epithelium cell; human; keratomileusis; morphometrics; photorefractive keratectomy; anatomy and histology; autonomic nervous system; case control study; cornea; Diabetic Nephropathies; innervation; pathology, Autonomic Nervous System; Case-Control Studies; Cornea; Diabetic Nephropathies; Humans"
"Zeng M,Zou B,Wei F,Liu X,Wang L",Effective prediction of three common diseases by combining SMOTE with Tomek links technique for imbalanced medical data,2016,"Diabetes, vertebral column pathologies and Parkinson's disease are three common diseases which have high prevalence and brought great trouble and pain to billions of patients. Computer aided diagnosis can support decision making of physicians. However, imbalanced nature of data sets hampered the mining of medical resources. In this study, we proposed a powerful preprocessing method by combining Synthetic Minority Oversampling Technique (SMOTE) with Tomek links technique and then is applied to the imbalanced medical data sets of the three diseases. By using 8 classifiers, we compared the experimental results with those of using only SMOTE technique to evaluate the effectiveness of this method. The results show that the method of SMOTE combined with Tomek links technique is much superior compared with that of using only SMOTE. The performances are evidently better, with 31, 27, 30 out of a total of 32 evaluation metrics are improved for diabetes, Parkinson's disease, and vertebral column, respectively. © 2016 IEEE.","Computer aided diagnosis; Decision making; Medical problems; Neurodegenerative diseases; Pathology, Medical data; Parkinson's disease; SMOTE; Tomek links; Vertebral column, Medical computing"
"Kavitha R,Christopher T",Classification of Heart Rate data using BFO-KFCM clustering and improved extreme learning machine classifier,2016,"The Electrocardiogram is a tool used to access the electrical recording and muscular function of the heart and in last few decades it is extensively used in the investigation and diagnosis of heart related diseases. It must be noted that the heart rate fluctuates not only because of cardiac demand, however is also influenced as a result of the occurrence of cardiac disease and diabetes. In addition, it has been shown that Heart Rate Variability (HRV) may well be utilized as an early indicator of cardiac disease susceptibility and the existence of diabetes. As a result, the HRV can be exercised for early clinical test of these diseases. Most existing systems make use of Support Vector Machine (SVM), owing to the generalization performance, it is not sufficient for the accurate classification of heart rate data. In order to overcome this complication, Improved Extreme Learning Machine (IELM) classifier is used, to obtain the best parameter value and best feature subset through the use of Bacterial Foraging Optimization (BFO) that feed the classifier. Here in this work, features of linear and nonlinear are extracted from the HRV signals. Following the preprocessing, feature extraction is done effectively together with feature selection with the assistance of BFO for the purpose of data reduction. Subsequently, proposed a scheme to integrate Kernel Fuzzy C-Means (KFCM) clustering and classifier to adequately enhance the accuracy result for ECG beat classification. The accuracy result for classification of heart rate data is shown in the proposed scheme. © 2016 IEEE.","Cardiology; Diagnosis; Electrocardiography; Feature extraction; Heart; Information science; Knowledge acquisition; Learning systems; Reduction; Support vector machines, Clustering; Electrocardiogram signal; Feature detection; IELM; KFCM, Classification (of information)"
"Marzbanrad F,Khandoker AH,Hambly BD,Ng E,Tamayo M,Lu Y,Matthews S,Karmakar C,Palaniswami M,Jelinek HF,McLachlan C",Methodological comparisons of heart rate variability analysis in patients with type 2 diabetes and angiotensin converting enzyme polymorphism,2016,"Angiotensin converting enzyme (ACE) polymorphism has been shown to be important in hypertension progression and also in diabetes complications, especially associated with heart disease. Heart rate variability (HRV) is an established measure for classification of autonomic function regulating heart rate, based on the interbeat interval time series derived from a raw ECG recording. Results of this paper show that the length (number of interbeat intervals) and preprocessing of the tachogram affect the HRV analysis outcome. The comparison was based on tachogram lengths of 250, 300, 350, and 400 RR-intervals and five preprocessing approaches. An automated adaptive preprocessing method for the heart rate biosignal and tachogram length of 400 interbeat intervals provided the best classification. HRV results differed for the Type 2 Diabetes Mellitus (T2DM) group between the I/I genotype and the I/D and D/D genotypes, whereas for controls there was no significant difference in HRV between genotypes. Selecting an appropriate length of recording and automated preprocessing has confirmed that there is an effect of ACE polymorphism including the I/I genotype and that I/I should not be combined with I/D genotype in determining the extent of autonomic modulation of the heart rate. © 2015 IEEE.","Enzymes; Polymorphism, Adaptive preprocessing; Angiotensin-converting enzyme; Heart rate variability; Heart rate variability analysis; Interval time series; Methodological comparison; Preprocessing approaches; Type 2 diabetes mellitus, Heart, ACE protein, human; dipeptidyl carboxypeptidase, aged; Diabetes Mellitus, Type 2; female; genetic polymorphism; genetics; heart rate; human; male; middle aged; pathophysiology; physiology, Aged; Diabetes Mellitus, Type 2; Female; Heart Rate; Humans; Male; Middle Aged; Peptidyl-Dipeptidase A; Polymorphism, Genetic"
"Vijayan VV,Anjali C",Decision support systems for predicting diabetes mellitus-A Review,2015,"Diabetes mellitus is caused due to the increased level of sugar content in the blood. This can cause series complications like kidney failure, stroke, cancer, heart disease and blindness. The early detection and diagnosis, helps to identify and avoid these complications. A number of computerized information systems were designed using different classifiers for predicting and diagnosing diabetes. Selecting proper algorithms for classification clearly increases the accuracy and efficiency of the system. The main objective of this study is to review the benefits of different preprocessing techniques for decision support systems for predicting diabetes which are based on Support Vector Machine (SVM), Naive Bayes classifier and Decision Tree. The preprocessing methods focused on this study are Principal Component Analysis and Discretization. The accuracy variation with and without preprocessing techniques are also evaluated. The tool under consideration is the Weka for this study. The dataset was taken from the University of California, Irvine (UCI) repository of machine learning. © 2015 IEEE.","Artificial intelligence; Classification (of information); Classifiers; Decision support systems; Decision trees; Diagnosis; Diseases; Forecasting; Learning systems; Medical computing; Pattern recognition; Principal component analysis; Support vector machines; Trees (mathematics), Discretizations; ensembling; hybridization; Medical data mining; Naive Bayes classifiers; preprocessing; variability, Data mining"
"Chetty N,Vaisla KS,Patil N",An Improved Method for Disease Prediction Using Fuzzy Approach,2015,Data mining is a process of extracting useful information from the huge amount of data. Data Mining has great scope in the field of medicine. This article deals with the working on PIMA and Liver-disorder datasets. Many researchers have proposed the use of K-nearest neighbor (KNN) algorithm for diabetes disease prediction. Some researchers have proposed a different approach by using K-means clustering for preprocessing and then using KNN for classification. These approaches resulted in poor classification accuracy or prediction. In our work we proposed and developed two different methods first one is fuzzy c-means clustering algorithm followed by a KNN classifier and second one is fuzzy c-means clustering algorithm followed by fuzzy KNN classifier to improve the accuracy of classification. We are successful in obtaining the better results than the existing methods for the given datasets. Our second approach produced better result than the first one. Classification is carried out using ten folds cross-validation technique. © 2015 IEEE.,"Algorithms; Copying; Data mining; Forecasting; Fuzzy clustering; Fuzzy systems; Learning algorithms; Nearest neighbor search, Accuracy of classifications; Cross-validation technique; Fuzzy C-means algorithms; Fuzzy c-means clustering algorithms; Fuzzy k-NN algorithm; K nearest neighbor algorithm; k-NN algorithm; Liver disorder, Clustering algorithms"
"Jakhmola S,Pradhan T",A computational approach of data smoothening and prediction of diabetes dataset,2015,"Data mining when applied on medical diagnosis can help doctors to take major decisions. Diabetes is a disease which has to be monitored by the patient so as not to cause severe damage to the body. Therefore to predict diabetes is an important task that is most important for the patient. In this study, a new data smoothening technique is proposed for noise removal from the data. It is very important for the user to have control over the smoothening of the data so that the information loss can be monitored. The proposed method allows the user to control the level of data smoothening by accepting the loss percentage on the individual data points. Allowable loss is calculated and a decision is made to smoothen the value or retain it to the level which is accurate. The proposed method will enable the user to get the output based on his requirements of preprocessing. The proposed algorithm will allow the user to interact with the data preprocessing system unlike the primitive algorithms. Different levels of smoothened output are obtained by different loss percentage. This preprocessed output produced will be of a better quality and will resemble more to the real world data. Furthermore, correlation and multiple regression is applied on the preprocessed diabetes dataset and a prediction is made on this basis. © 2015 ACM.","Correlation methods; Data mining; Diagnosis; Forecasting; Information science, Computational approach; Data points; Data preprocessing; Information loss; Multiple regressions; Noise removal; Real-world; Smoothening, Medical computing"
Perner P,Standardization in IRIS diagnosis,2015,"Molecular image-based techniques are widely used in medicine to detect specific diseases. The analysis of the eye plays an important role in order to detect specific diseases. Eye background analysis is used in order to detect certain forms of diabetes and others diseases. In the alternative medicine plays the diagnosis of the iris an important role. One understands by iris diagnosis (Iridology) the investigation and analysis of the colored part of the eye, the iris, to discover factors which play an important role for the prevention and treatment of illnesses, but al-so for the preservation of an optimum health. Although alternative practitioner describe substantial success with the iris diagnosis. The conventional medicine is not convinced of the diagnosis method. A big drawback of the method is the subjective interpretation of what is seen in the iris image. An automatic system would pave the way for much wider use of the iris diagnosis for the diagnosis of illnesses and for the purpose of individual health protection. With this paper we de-scribe our work towards an automatic iris diagnosis system. We describe the image acquisition and the problems with it. Different ways of image acquisition and image preprocessing are explained. We describe the image analysis method for the detection of the iris. This method is based on our novel case-based object recognition and case mining method. Results for the recognition of the iris are given. We describe how to detect the pupil and not wanted lamp spots. We explain how to recognize orange blue spots in the iris and match them against the topological map of the iris. Finally, we give an outlook for further work. © 2015 IEEE.","Biometrics; Diseases; Image acquisition; Mining; Object recognition; Standardization; Topology, Colored Spot Recognition; Iris images; Iris recognition; Object matching; Pupil Recognition; Topological Matching, Diagnosis"
"Prasad BR,Agarwal S",Modeling risk prediction of diabetes - A preventive measure,2015,"Databases in clinical scenario have tremendous amount of data regarding patients and clinical history associated. Here, data mining plays vital role in searching for patterns within huge clinical data that could provide useful basis of knowledge for efficient and effective decision-making. Classification mechanism is widely used tool of data mining employed in healthcare applications to facilitate disease diagnosis and prediction. Usually medical dataset are high dimension in nature containing many insignificant attributes or features and result poor classification with inaccuracies. Feature selection is a technique used for preprocessing the high-dimensional data to reduce data dimension and to remove redundant and irrelevant features. This paper provides a systematic data mining approach for selecting best indicators of diabetes among many attributes present in the database and gives an appropriate model to track the diabetes before its onset. It selects the most appropriate classifier model for the given dataset through voting mechanism to achieve best accuracy and eliminating any biased result. © 2014 IEEE.","Clustering algorithms; Computer aided diagnosis; Data mining; Decision making; Feature extraction; Forecasting; Medical problems; Risk assessment, Appropriate models; Classification mechanism; Classifier models; Disease diagnosis; Health care application; High dimensional data; Preventive measures; Voting mechanism, Classification (of information)"
"Deshpande SS,Wakankar A",Automated detection of Polycystic Ovarian Syndrome using follicle recognition,2015,"Polycystic Ovarian Syndrome (PCOS) is one of the most common hormonal disorder present in females in reproductive age group. Early detection and treatment of PCOS is important since it is often associated with obesity, type 2 diabetes mellitus, and high cholesterol levels. In this paper, automated detection of PCOS is done by calculating no of follicles in ovarian ultrasound image and then incorporating clinical, biochemical and imaging parameters to classify patients in two groups i.e. normal and PCOS affected. Number of follicles are detected by ovarian ultrasound image processing using preprocessing which includes contrast enhancement and filtering, feature extraction using Multiscale morphological approach and segmentation. Support Vector Machine algorithm is used for classification which takes into account all the parameters such as body mass index (BMI), hormonal levels, menstrual cycle length and no of follicles detected in ovarian ultrasound image processing. The results obtained are verified by doctors and compared with manual detection. The accuracy obtained for the proposed method is 95%. © 2014 IEEE.","Health; Image enhancement; Image segmentation; Support vector machines; Ultrasonic applications, Contrast Enhancement; Morphological approach; Polycycstic Ovarian syndrome; Polycystic ovarian syndrome; Reproductive age group; Support vector machine algorithm; Type 2 diabetes mellitus; Ultrasound image processing, Feature extraction"
"Dashtbozorg B,Mendonça AM,Campilho A",Optic disc segmentation using the sliding band filter,2015,"Background: The optic disc (OD) centre and boundary are important landmarks in retinal images and are essential for automating the calculation of health biomarkers related with some prevalent systemic disorders, such as diabetes, hypertension, cerebrovascular and cardiovascular diseases.Methods: This paper presents an automatic approach for OD segmentation using a multiresolution sliding band filter (SBF). After the preprocessing phase, a low-resolution SBF is applied on a downsampled retinal image and the locations of maximal filter response are used for focusing the analysis on a reduced region of interest (ROI). A high-resolution SBF is applied to obtain a set of pixels associated with the maximum response of the SBF, giving a coarse estimation of the OD boundary, which is regularized using a smoothing algorithm.Results: Our results are compared with manually extracted boundaries from public databases (ONHSD, MESSIDOR and INSPIRE-AVR datasets) outperforming recent approaches for OD segmentation. For the ONHSD, 44% of the results are classified as Excellent, while the remaining images are distributed between the Good (47%) and Fair (9%) categories. An average overlapping area of 83%, 89% and 85% is achieved for the images in ONHSD, MESSIDOR and INSPIR-AVR datasets, respectively, when comparing with the manually delineated OD regions.Discussion: The evaluation results on the images of three datasets demonstrate the better performance of the proposed method compared to recently published OD segmentation approaches and prove the independence of this method when from changes in image characteristics such as size, quality and camera field of view. © 2014 Elsevier Ltd.","Ophthalmology; Quality control, Band filters; Boundary extraction; Optic disc; Retinal image; Segmentation evaluation, Image segmentation, algorithm; comparative study; devices; factual database; fluorescence imaging; human; image processing; pathology; procedures; retina, Algorithms; Algorithms; Databases, Factual; Databases, Factual; Humans; Humans; Image Processing, Computer-Assisted; Image Processing, Computer-Assisted; Optical Imaging; Optical Imaging; Retina; Retina"
"Li W,Li Y,Hu C,Chen X,Dai H",Point process analysis in brain networks of patients with diabetes,2014,"Noise and individual differences arise from disturbances in the effective use of resting-state functional magnetic resonance image (fMRI) datasets. In this study, the point process is used to treat fMRI datasets of healthy controls and patients with diabetes; then, functional brain networks of subjects are established using two sets of BOLD signals. The results illustrate that differences between the healthy controls and the patients were more obvious in point process signals than nonpoint process signals. Our results also suggest that there is a higher recognition accuracy of the signals by preprocessing with the point process. These findings may suggest that the point process approach can reduce BOLD signals noise, providing a new method for functional magnetic resonance data preprocessing, and may provide a promising method for early data preprocessing in computer-aided disease diagnostics. © 2014 Elsevier B.V.","Diagnosis; Magnetic resonance imaging, Brain networks; Data preprocessing; Disease diagnostics; Functional magnetic resonance images (fMRI); Individual Differences; Point process; Recognition accuracy; Resting-state fmri, Functional neuroimaging, accuracy; adult; aged; article; artificial neural network; BOLD signal; brain function; clinical article; cluster analysis; controlled study; diabetes mellitus; female; functional magnetic resonance imaging; human; male; priority journal; resting state network; support vector machine; very elderly"
"Prentasic P,Loncaric S",Weighted ensemble based automatic detection of exudates in fundus photographs,2014,"Diabetic retinopathy (DR) is a visual complication of diabetes, which has become one of the leading causes of preventable blindness in the world. Exudate detection is an important problem in automatic screening systems for detection of diabetic retinopathy using color fundus photographs. In this paper, we present a method for detection of exudates in color fundus photographs, which combines several preprocessing and candidate extraction algorithms to increase the exudate detection accuracy. The first stage of the method consists of an ensemble of several exudate candidate extraction algorithms. In the learning phase, simulated annealing is used to determine weights for combining the results of the ensemble candidate extraction algorithms. The second stage of the method uses a machine learning-based classification for detection of exudate regions. The experimental validation was performed using the DRiDB color fundus image set. The validation has demonstrated that the proposed method achieved higher accuracy in comparison to state-of-the art methods. © 2014 IEEE.","Artificial intelligence; Color; Diagnosis; Extraction; Image processing; Learning systems; Photography; Simulated annealing, Automatic Detection; Color fundus photograph; Diabetic retinopathy; Experimental validations; Extraction algorithms; Exudate detections; Image processing and analysis; State-of-the-art methods, Eye protection, algorithm; computer assisted diagnosis; diabetic retinopathy; exudate; eye fundus; human; ophthalmoscopy; photography; sensitivity and specificity; support vector machine, Algorithms; Diabetic Retinopathy; Exudates and Transudates; Fundus Oculi; Humans; Image Interpretation, Computer-Assisted; Ophthalmoscopy; Photography; Sensitivity and Specificity; Support Vector Machine"
"Deepa M,Mymoon Zuviriya N",Comparative analysis on supervised classification techniques for segmentation and detecting abnormal blood vessels in retinal images,2014,"The development of new vessels on the retina of people with diabetes is rare, but is likely to lead to severe visual impairment. The technique implements a supervised classification method for blood vessel detection as well as new vessels on the optic disc in digital retinal images. Blood vessel segmentation is performed through various stages: Preprocessing, Feature Extraction by using Gray-level and Moment Invariants-based, Classification and Post processing. For new vessel detection, the fourteen features are chosen based on their discrimination capability and absence of correlation with other features. Classification is performed using a Support Vector Machine. The system is trained and tested by cross-validation using 25 images with new vessels and 25 normal images without new vessels. © 2012 IEEE.","Blood; Classification (of information); Extraction; Eye protection; Feature extraction; Image classification; Image segmentation; Ophthalmology; Support vector machines, Diabetic retinopathy; K-NN classifier; Moment invariant; Naive bayes; Retinal image; Supervised classification; SVM classifiers, Blood vessels"
"Usman Akram M,Khalid S,Tariq A,Khan SA,Azam F",Detection and classification of retinal lesions for grading of diabetic retinopathy,2014,"Diabetic Retinopathy (DR) is an eye abnormality in which the human retina is affected due to an increasing amount of insulin in blood. The early detection and diagnosis of DR is vital to save the vision of diabetes patients. The early signs of DR which appear on the surface of the retina are microaneurysms, haemorrhages, and exudates. In this paper, we propose a system consisting of a novel hybrid classifier for the detection of retinal lesions. The proposed system consists of preprocessing, extraction of candidate lesions, feature set formulation, and classification. In preprocessing, the system eliminates background pixels and extracts the blood vessels and optic disc from the digital retinal image. The candidate lesion detection phase extracts, using filter banks, all regions which may possibly have any type of lesion. A feature set based on different descriptors, such as shape, intensity, and statistics, is formulated for each possible candidate region: this further helps in classifying that region. This paper presents an extension of the m-Mediods based modeling approach, and combines it with a Gaussian Mixture Model in an ensemble to form a hybrid classifier to improve the accuracy of the classification. The proposed system is assessed using standard fundus image databases with the help of performance parameters, such as, sensitivity, specificity, accuracy, and the Receiver Operating Characteristics curves for statistical analysis. © 2013 Elsevier Ltd.","Cotton-wool spots; Diabetic retinopathy; Haemorrhage; Hard exudates; M-Mediods; Microaneurysms; NPDR, Blood vessels; Classification (of information); Eye protection; Filter banks; Image segmentation; Ophthalmology, Grading, article; contrast enhancement; diabetic retinopathy; diagnostic accuracy; disease classification; human; optic disk; priority journal; retina image; sensitivity and specificity, Classification; Cotton wool spots; Diabetic retinopathy; Haemorrhage; Hard exudates; m-Mediods; Microaneurysms; NPDR, Adult; Aged; Aged, 80 and over; Diabetic Retinopathy; Diagnostic Techniques, Ophthalmological; Humans; Image Interpretation, Computer-Assisted; Middle Aged; Pattern Recognition, Automated"
"Scholtes-Timmerman MJ,Bijlsma S,Fokkert MJ,Slingerland R,Van Veen SJ",Raman spectroscopy as a promising tool for noninvasive point-of-care glucose monitoring,2014,"Background: Self-monitoring of glucose is important for managing diabetes. Noninvasive glucose monitors are not yet available, but patients would benefit highly from such a device. Methods: We present results that may lead to a novel, point-of-care noninvasive system to measure blood glucose based on Raman spectroscopy. A hospitalized cohort of 111 subjects was measured using a custom-made Raman spectrometer system. Blood glucose reference samples were used to correlate Raman data to glucose levels, using advanced preprocessing and analysis algorithms. Results: A correlation coefficient (R2) of .83 was found correlating independent Raman-based predictions on reference blood glucose for the full cohort. Stratification of the cohort in gender-specific groups raised correlation levels to .88 (females) and .94 (males). Glucose could be measured noninvasively with average errors as low as 0.9 mM. Conclusion: We conclude that this novel system shows promising results for the advance of noninvasive, point-of-care glucose monitoring. © 2014 Diabetes Technology Society.","glucose; glucose blood level, adult; aged; Article; blood glucose monitoring; cohort analysis; female; gender; glucose blood level; human; human tissue; major clinical study; male; non invasive procedure; point of care testing; Raman spectrometry; analysis; blood glucose monitoring; devices; hospital information system; middle aged; physiologic monitoring; procedures; Raman spectrometry; very elderly, Adult; Aged; Aged, 80 and over; Blood Glucose; Blood Glucose Self-Monitoring; Female; Humans; Male; Middle Aged; Monitoring, Physiologic; Point-of-Care Systems; Spectrum Analysis, Raman"
"Garcia-Gomez VJ,Alberich-Bayarri A,Sanz-Requena R,Garcia AM,Marti-Bonmati L,Naranjo V","Design, development and implementation of semi-automated CINE MR images segmentation pipeline using feature extraction and active contours",2014,"Coronary heart disease is a major cause of death in developed countries. There are some factors like cholesterol, high blood pressure, diabetes or obesity that increase the risk of having coronary heart disease. Early detection of the disease may have a better treatment response. Cardiac imaging methods require new processing analysis approaches. In this paper, new segmentation system has been studied in order to develop a semi-automated methodology for left ventricular myocardium segmentation from cardiac MR CINE images based on figure detection and active contours. Different image preprocessing techniques like the Hough Transform, centroid detection and snakes were integrated in a pipeline that permits the analysis and generation of structured reports with imaging biomarkers of the cardiac function in different cardiomyopathies. To implement the new segmentation method, a new segmentation and image analysis software has been created. Cardiac reports are made automatically with this tool using bull eyes and biomarkers like ejection fraction (EF), myocardial mass, cardiac output or thickening. © 2014 IEEE.","Blood pressure; Cardiology; Diseases; Feature extraction; Heart; Hough transforms; Magnetic resonance imaging; Pipelines, Coronary heart disease; Developed countries; High blood pressures; Image analysis software; Image preprocessing; Left ventricular myocardiums; Segmentation methods; Segmentation system, Image segmentation"
"Jelinek HJ,Alothman T,Cornforth DJ,Khalaf K,Khandoker AH",Effect of biosignal preprocessing and recording length on clinical decision making for cardiac autonomic neuropathy,2014,"Early identification of cardiac autonomic neuropathy (CAN) leads to better treatment outcomes. Heart rate variability (HRV) analysis allows identification of CAN but is sensitive to the length of recording and the presence of artifacts and ectopics, requiring preprocessing and consideration of length of recording. RR intervals from 10-second and 5-minute ECG recordings from patients with no CAN, early CAN and definite CAN were preprocessed using adaptive filtering with the controlling parameter c set at 0.2, 0.5 and 0.8, and time and frequency domain HRV analysis applied. Early CAN and definite CAN required different setting of c with respect to the length of recording. The 5-minute recording with c=0.2 provided the best results using RMSSD for normal versus eCAN (p=0.0007) and for eCAN versus dCAN (0.019). Clinically, this has potential use in general practice for screening patients at risk, newly diagnosed with diabetes, or for follow-up during the course of diabetes. © 2014 IEEE.",Biosignals; Clinical decision making; Controlling parameters; ECG recording; Heart rate variability; RR intervals; Time and frequency domains; Treatment outcomes
"Sharath Kumar PN,Kumar RR,Sathar A,Sahasranamam V",Automatic detection of exudates in retinal images using histogram analysis,2013,"Diabetic Retinopathy (DR) is the major cause of blindness caused by the damage to the blood vessels in the retina from diabetes. It cannot be prevented but early detection through fundus imaging by an ophthalmologist can prevent further vision loss. Presence of microaneurysms, hemorrhages, cotton-wool spots and exudates are the symptoms of mild DR. Of these, the detection of exudates is one of the important factors in the early diagnosis of DR. Exudates are fatty deposits on the retina which appear as yellowish regions in fundus image. Fundus images show considerable variation in brightness which makes automatic detection of exudates difficult. In this study, we are proposing a new method for preprocessing and false positive elimination towards the reliable detection of exudates. The brightness of the fundus image was changed by the nonlinear curve with brightness values of the hue saturation value (HSV) space. To emphasize brighter yellow regions (exudates), gamma correction was performed on each red and green components of the image. Subsequently, the histograms of each red and green component were extended. After that, the exudates candidates were detected using histogram analysis. Finally, false positives were removed by using multi-channel histogram analysis. To evaluate the new method for the detection of exudates, we examined 158 fundus images, including 84 abnormal images with exudates and 74 normal images. The sensitivity and specificity for the detection of abnormal and normal cases were 88.45% and 95.5% respectively. © 2013 IEEE.","Diabetic retinopathy; exudates; False-positive eliminations; Fundus image; Histogram analysis; preprocessing, Blood vessels; Computational complexity; Eye protection; Luminance; Statistical methods, Graphic methods"
"Du N,Li Y",Automated identification of diabetic retinopathy stages using support vector machine,2013,"Diabetic retinopathy (DR) is a condition where the retina is damaged due to fluid leaking from the blood vessels into the retina. The main stages of diabetic retinopathy are non-proliferate diabetes retinopathy (NPDR) and proliferate diabetes retinopathy (PDR). Early detection of diabetic retinopathy is crucial to prevent blindness. In this work, we have proposed a computer based approach for the detection of diabetic retinopathy stage using color fundus images. Image preprocessing, morphological processing techniques and texture analysis methods are applied on the fundus images to detect the features such as area of blood vessels, hard exudates and the contrast, homogeneity. The features are fed to the support vector machine (SVM). We demonstrate a classification accuracy of 93%, sensitivity of 90% and specificity of 100%. © 2013 TCCT, CAA.","Blood vessels; Support vector machines, Automated identification; Computer-based approach; Diabetic retinopathy; Exudates; Fundus image; Morphological processing; Retinal blood vessels; Texture analysis method, Eye protection"
"Nirmaladevi M,Alias Balamurugan SA,Swathi UV",An amalgam KNN to predict diabetes mellitus,2013,"Medical Data mining extracts hidden patterns from medical data. This paper presents the development of an amalgam model for classifying Pima Indian diabetic database (PIDD). This amalgam model combines k-means with k-Nearest Neighbor (KNN) with multi-sep preprocessing. Many researchers have found that the KNN algorithm accomplishes very good performance in their experiments on different data sets. In this amalgam model, the quality of the data is improved by removing noisy data thereby helping to improve the accuracy and efficiency of the KNN algorithm.k-means clustering is used to identify and eliminate incorrectly classified instances. The missing values are replaced by means and medians. A fine tuned classification is done using k-Nearest Neighbor (KNN) by taking the correctly clustered instance with preprocessed subset as inputs for the KNN. The best choice of k depends upon the data. Generally, larger values of k reduce the effect of noise on the classification. A good k is selected by cross-validation technique. The aim of this paper is determining the value of k for PIDD for better classification accuracy using amalgam KNN. Experimental results signify the proposed amalgam KNN along with preprocessing produces best result for different k values. If k value is more the proposed model obtained the classification accuracy of 97.4%. Ten fold cross validation with larger k value produces better classification accuracy for PIDD. The results are also compared with simple KNN and cascaded K-MEANS and KNN for the same k values. © 2013 IEEE.","Classification accuracy; Cross validation; Cross-validation technique; Diabetes mellitus; K nearest neighbor (KNN); K-means; k-NN algorithm; Medical data mining, Classification (of information); Communication; Data mining; Nanotechnology, Learning algorithms"
"Akram MU,Tariq A,Khan SA,Bazar SA",Microaneurysm detection for early diagnosis of diabetic retinopathy,2013,"Microaneurysms (MAs) are the first visible sign of diabetic retinopathy (DR), a retinal abnormality which may lead to blindness in diabetes patients. In time and precise MAs detection is very important for early diagnosis of DR and can save patient's vision. In this paper, we present an automated system for accurate and reliable detection of MAs. The proposed system consists of preprocessing, feature extraction and classification stages. The preprocessing step extracts all possible regions which may be considered as MAs from input retinal image and feature extraction stage represents each region with a number of features. A novel hybrid classifier which combines Gaussian mixture model and support vector machine in an ensemble, finally classifies each region as MA or non-MAo The proposed system uses genetic algorithm in order to optimized the weights for hybrid classifier. The evaluation of proposed system is performed using publicly available retinal image database and results are compared with existing techniques to demonstrate the validity of proposed system. © 2013 IEEE.","Automation; Feature extraction; Image retrieval; Ophthalmology, Diabetic retinopathy; Feature extraction and classification; Gaussian Mixture Model; Hybrid classifier; Microaneurysms; Pre-processing step; Preprocessing; Reliable detection, Eye protection"
"Somodevilla MJ,Mendez M,Celis CP,Pineda IH",Mining biomedical data from mexrisc,2013,"In this paper, it is presented a support system for decision making to diabetes prevention. Using MexRisc platform, a large number of data is collected, and then preprocessing data techniques are applied in order to do a classification process. © 2013 IEEE.","Artificial intelligence; Classification (of information); Data mining; Decision support systems; Medical problems, Biomedical data; Classification process; Clustering; Number of datum; Support systems, Computer science"
"Gajawada S,Toshniwal D",A framework for classification using genetic algorithm based clustering,2012,Clustering has been used in literature to enhance classification accuracy. But most partitional clustering methods need the number of clusters as input and also they are sensitive to initialization. Although hierarchical clustering methods may be more effective in finding clustering structure of the dataset than partitional methods but hierarchical clustering methods give tree structure known as dendrogram which is a sequence of clustering solutions. Hence hierarchical clustering algorithms are not generally applied in the preprocessing step to classification methods. This problem can be solved by cutting the dendrogram to get single clustering solution. In this paper we propose a framework for classification which uses Optimal Clustering Genetic Algorithm (OCGA) to obtain optimal level of cutting the dendrogram. A single clustering solution is obtained by cutting the dendrogram at optimal level. The clusters obtained are used to enhance classification accuracy of the classification methods. The proposed classification methods have been applied for the diagnosis of diabetes disease. © 2012 IEEE.,"Based clustering; Classification accuracy; Classification methods; Clustering solutions; Dendrograms; Hier-archical clustering; Hierarchical clustering algorithms; Hierarchical clustering methods; Number of clusters; Optimal clustering; Optimal level; Partitional clustering; Partitional methods; Pre-processing; Pre-processing step; Tree structures, Classification (of information); Cluster analysis; Diagnosis; Genetic algorithms; Intelligent systems; Optimization; Systems analysis; Trees (mathematics), Clustering algorithms"
"Mirsharif Q,Tajeripour F",Investigating image enhancement methods for better classification of retinal blood vessels into arteries and veins,2012,"Developing an automatic tool for classification of retinal blood vessels into arteries and veins has gone under special attention recently due to its importance in early diagnosis of several diseases namely, diabetes, hypertension and stroke. Indeed such pathologies make alternations in artery or vein vessel tree leading to an abnormal arteriolar-to-venular width ratio (AVR). To measure AVR, arteries and veins must be carefully separated. For this purpose, a few methods have been proposed in the literature most of which are based on feature extraction. However, different factors such as non-uniformity of lightness during the image acquisition process degrade the quality of retinal images which in turn affect the results of computer algorithms. In this paper, we investigate a number of image enhancement techniques for improving the quality of retinal images considering the specific characteristics of those images. Experimental results demonstrate the significant role of image enhancement as a preprocessing step in developing an efficient system for automatic classification of retinal blood vessels into arteries and veins. © 2012 IEEE.","Acquisition process; Automatic classification; Automatic tools; Early diagnosis; Efficient systems; Enhancement techniques; Histogram equalizations; Multi-scale Retinex; Nonuniformity; Pre-processing step; Retinal blood vessels; Retinal image; Width ratio, Algorithms; Artificial intelligence; Diagnosis; Feature extraction; Ophthalmology; Signal processing, Image enhancement"
"Shi JJ,Alenezy M,Smirnova IV,Bilgen M",Construction of a two-parameter empirical model of left ventricle wall motion using cardiac tagged magnetic resonance imaging data,2012,"Background: A one-parameter model was previously proposed to characterize the short axis motion of the LV wall at the mid-ventricle level. The single parameter of this model was associated with the radial contraction of myocardium, but more comprehensive model was needed to account for the rotation at the apex and base levels. The current study developed such model and demonstrated its merits and limitations with examples.Materials and methods: The hearts of five healthy individuals were visualized using cardiac tagged magnetic resonance imaging (tMRI) covering the contraction and relaxation phases. Based on the characteristics of the overall dynamics of the LV wall, its motion was represented by a combination of two components - radial and rotational. Each component was represented by a transformation matrix with a time-dependent variable ? or ?.Image preprocessing step and model fitting algorithm were described and applied to estimate the temporal profiles of ? and ? within a cardiac cycle at the apex, mid-ventricle and base levels. During this process, the tagged lines of the acquired images served as landmark reference for comparing against the model prediction of the motion. Qualitative and quantitative analyses were performed for testing the performance of the model and thus its validation.Results: The ? and ? estimates exhibited similarities in values and temporal trends once they were scaled by the radius of the epicardium (repi)and plotted against the time scaled by the period of the cardiac cycle (Tcardiac) of each heart measured during the data acquisition. ?/repi peaked at about ?t/Tcardiac=0.4 and with values 0.34, 0.4 and 0.3 for the apex, mid-ventricle and base level, respectively. ?/repi similarly maximized in amplitude at about ?t/Tcardiac=0.4, but read 0.2 for the apex and - 0.08 for the base level. The difference indicated that the apex twisted more than the base.Conclusion: It is feasible to empirically model the spatial and temporal evolution of the LV wall motion using a two-parameter formulation in conjunction with tMRI-based visualization of the LV wall in the transverse planes of the apex, mid-ventricle and base. In healthy hearts, the analytical model will potentially allow deriving biomechanical entities, such as strain, strain rate or torsion, which are typically used as diagnostic, prognostic or predictive markers of cardiovascular diseases including diabetes. © 2012 Shi et al.; licensee BioMed Central Ltd.","Cardiac cycles; Cardiac modeling; Cardio-vascular disease; Comprehensive model; Empirical model; Healthy individuals; Image preprocessing; Left ventricles; Model fitting; Model prediction; Myocardial deformation; Qualitative and quantitative analysis; Relaxation phasis; Single parameter; Tagged magnetic resonance; Tagged MRI; Temporal evolution; Temporal profile; Temporal trends; Time-dependent variables; Transformation matrices; Transverse planes; Two-component; Wall motion, Biomechanics; Linear transformations; Magnetic resonance imaging; Parameter estimation; Strain rate, Heart, article; biological model; female; heart; heart ventricle function; human; image processing; male; movement (physiology); nuclear magnetic resonance imaging; physiology; reproducibility, Female; Heart; Humans; Image Processing, Computer-Assisted; Magnetic Resonance Imaging; Male; Models, Biological; Movement; Reproducibility of Results; Ventricular Function"
"JayaKumari C,Maruthi R",Detection of hard exudates in color fundus images of the human retina,2012,"Diabetic Retinopathy is a progressive ocular disease. The disease may advance from mild to severe non-proliferative diabetic retinopathy and it is one of the most significant factors contributing to blindness. Therefore, it is necessary everyone with diabetes should get a comprehensive dilated eye exam at least once in a year. In this study, a state-of-art image processing techniques to automatically detect the presence of hard exudates in the fundus images are presented. After the contrast adaptive histogram equalization as preprocessing stage, contextual clustering algorithms have been applied to segment the exudates. The key features are like the standard deviation, mean, intensity, edge strength and compactness of the segmented regions are extracted and fed as inputs into Echo State Neural Network (ESNN) to discriminate between the normal and pathological image. A total of 50 images have been used to find the exudates out of which 35 images consisting of both normal and abnormal are used to train the ESSN and the remaining 15 images are used to test the neural network. Furthermore, it confirms 93.0% sensitivity and 100% specificity in terms of exudates based classification.","Adaptive histogram equalization; Contextual clustering; Diabetic retinopathy; Fundus image; Hard exudates; Human retina; Image processing technique; Key feature; Ocular disease; Pathological images; Segmented regions; Standard deviation, Clustering algorithms; Eye protection; Image processing; Neural networks; Systems analysis, Communication"
"Jelinek HF,Rocha A,Carvalho T,Goldenstein S,Wainer J",Machine learning and pattern classification in identification of indigenous retinal pathology,2011,"Diabetic retinopathy (DR) is a complication of diabetes, which if untreated leads to blindness. DR early diagnosis and treatment improve outcomes. Automated assessment of single lesions associated with DR has been investigated for sometime. To improve on classification, especially across different ethnic groups, we present an approach using points-of-interest and visual dictionary that contains important features required to identify retinal pathology. Variation in images of the human retina with respect to differences in pigmentation and presence of diverse lesions can be analyzed without the necessity of preprocessing and utilizing different training sets to account for ethnic differences for instance. © 2011 IEEE.","Automated assessment; Diabetic retinopathy; Early diagnosis; Ethnic groups; Human retina; Training sets, Diseases; Eye protection; Ophthalmology; Pathology, Aldehydes, algorithm; article; artificial intelligence; automated pattern recognition; computer assisted diagnosis; diabetic retinopathy; human; image enhancement; information retrieval; methodology; pathology; reproducibility; retinoscopy; sensitivity and specificity, Algorithms; Artificial Intelligence; Diabetic Retinopathy; Humans; Image Enhancement; Image Interpretation, Computer-Assisted; Information Storage and Retrieval; Pattern Recognition, Automated; Reproducibility of Results; Retinoscopy; Sensitivity and Specificity"
"Poostchi H,Khakmardan S,Pourreza H",Diabetic Retinopathy dark lesion detection: Preprocessing phase,2011,"Diabetic Retinopathy is the common cause of vision loss and blindness in patients with diabetes. Diabetic Retinopathy indicative lesions include dark lesions such as Microaneurysms and Hemorrhages; and bright lesions like Exudates. Automatic detection of distinct lesions in digital color fundus photographs is a critical step in development of diabetic retinopathy automatic detection systems. Dark lesions are the early signs of the disease. In addition, preprocessing phase is affectively required in any automatic dark lesion detection system for contrast enhancement around the dark lesions. Therefore, in this paper several different methods of preprocessing digital color fundus photographs, as the first critical step of dark lesions detection, are summarized. © 2011 IEEE.","Diabetic retinopathy; Fundus photographs; Lesion detection; preprocessing; retina, Knowledge engineering; Photography, Eye protection"
"Purwita AA,Adityowibowo K,Dameitry A,Atman MW",Automated microaneurysm detection using mathematical morphology,2011,"Diabetes is one of the most rapidly increasing health threats worldwide. One of the further abnormalities is on retina (diabetic retinopathy). Early treatment can be conduct from detection of microaneurysms. The main concentration of this paper is the algorithm to detect microaneurysm with mathematical morphology. The mathematical morphology is choosen because microaneurysms tend to have typical shape. Generally, the algorithm is consist of three stages. The first is preprocessing, the second is detecting candidate microaneurysms, and the third is postprocessing handling the process of removing unused features. The performances is evaluated using the database from DIARETDB1 which provides ground truth collected from several experts and a strict evaluation protocol. The optimal performance will be satified when considering green channel obtaining, PAL size image processing, adaptive histogram equalization threshold at 0.03, canny edge detection threshold at 0.16, MAs and optimum microaneurysms size at 5 to 16 pixels. © 2011 IEEE.","Adaptive histogram equalization; Canny edge detection; Diabetic retinopathy; Evaluation protocol; Ground truth; Microaneurysms; Optimal performance; postprocessing; preprocessing; Three stages, Algorithms; Biomedical engineering; Communication; Edge detection; Eye protection; Health risks; Image processing; Information technology, Mathematical morphology"
Rostampour S,Novel algorithm by low complexity filter on retinal vessel segmentation,2011,"This article shows a new method to detect blood vessels in the retina by digital images. Retinal vessel segmentation is important for detection of side effect of diabetic disease, because diabetes can form new capillaries which are very brittle. The research has been done in two phases: preprocessing and processing. Preprocessing phase consists to apply a new filter that produces a suitable output. It shows vessels in dark color on white background and make a good difference between vessels and background. The complexity is very low and extra images are eliminated. The second phase is processing and used the method is called Bayesian. It is a built-in in supervision classification method. This method uses of mean and variance of intensity of pixels for calculate of probability. Finally Pixels of image are divided into two classes: vessels and background. Used images are related to the DRIVE database. After performing this operation, the calculation gives 95 percent of efficiency average. The method also was performed from an external sample DRIVE database which has retinopathy, and perfect result was obtained. © 2011 Copyright Society of Photo-Optical Instrumentation Engineers (SPIE).","Bayesian; Classification methods; Dark colors; Digital image; Low-complexity filter; Novel algorithm; Preprocessing phase; retina; Retinal vessels; Second phase; Side effect; vessel detection, Algorithms; Blood vessels; Eye protection; Imaging systems; Microcirculation; Ophthalmology; Pixels, Image segmentation"
"Zhao Y,Wang Z,Tang Y,Zhao M,Chen S,Hou J,Ke M",The development of Diabetics-oriented Telemedical Information System,2011,"The number of diabetes keeps increasing for many years, which has become one of the world's leading causes of death. Besides, the greatest hazards of diabetes are constituted by its complications such as hypertension and cardiovascular problems. As the treatment to diabetes usually acquires for quite a long time, the daily healthcare of those patients is a costly work. In this paper, a development of Diabetics-oriented Tele-medical Information System (DTMIS) is introduced. This DTMIS provides users with comprehensive, convenient and timely health monitoring and medical service. DTMIS can realize the real-time telemedicine monitoring of a diabetic's physiological parameters. The system is a complex structure combining the use of wearable sensing shirt, Bluetooth technology and GSM networking. And we have implemented a physiological signal preprocessing method that can detect abnormal data and provides preliminary suggestions to patients here. In the end, it can be concluded that the implementation of this platform system will provide a complete health condition monitoring and healthcare service. © 2011 IEEE.","Abnormal data; Bluetooth technology; Causes of death; Complex structure; Diabetics; Genetic factors; Health monitoring; Healthcare services; Medical services; Physiological parameters; Physiological signals; Platform systems; Pulse- wave; Telemedical information systems; Wearable sensing, Information systems; Patient treatment; Physiological models; Physiology; Telemedicine, Condition monitoring"
AlJarullah AA,Decision tree discovery for the diagnosis of type II diabetes,2011,"The discovery of knowledge from medical databases is important in order to make effective medical diagnosis. The aim of data mining is to extract knowledge from information stored in database and generate clear and understandable description of patterns. In this study, decision tree method was used to predict patients with developing diabetes. The dataset used is the Pima Indians Diabetes Data Set, which collects the information of patients with and without developing diabetes. The study goes through two phases. The first phase is data preprocessing including attribute identification and selection, handling missing values, and numerical discretization. The second phase is a diabetes prediction model construction using the decision tree method. Weka software was used throughout all the phases of this study. © 2011 IEEE.","Data preprocessing; Data sets; Decision tree method; Handling missing values; Medical database; Numerical discretization; Prediction model; Second phase; Tree discovery; Type II, Decision trees; Diagnosis; Information technology; Innovation; Mathematical models; Medical computing; Medical education; Plant extracts, Data mining"
"Giancardo L,Meriaudeau F,Karnowski TP,Tobin Jr KW,Grisan E,Favaro P,Ruggeri A,Chaum E",Textureless macula swelling detection with multiple retinal fundus images,2011,"Retinal fundus images acquired with nonmydriatic digital fundus cameras are versatile tools for the diagnosis of various retinal diseases. Because of the ease of use of newer camera models and their relatively low cost, these cameras can be employed by operators with limited training for telemedicine or point-of-care (PoC) applications. We propose a novel technique that uses uncalibrated multiple-view fundus images to analyze the swelling of the macula. This innovation enables the detection and quantitative measurement of swollen areas by remote ophthalmologists. This capability is not available with a single image and prone to error with stereo fundus cameras. We also present automatic algorithms to measure features from the reconstructed image, which are useful in PoC automated diagnosis of early macular edema, e.g., before the appearance of exudation. The technique presented is divided into three parts: first, a preprocessing technique simultaneously enhances the dark microstructures of the macula and equalizes the image; second, all available views are registered using nonmorphological sparse features; finally, a dense pyramidal optical flow is calculated for all the images and statistically combined to build a naive height map of the macula. Results are presented on three sets of synthetic images and two sets of real-world images. These preliminary tests show the ability to infer a minimum swelling of 300 ? and to correlate the reconstruction with the swollen location. © 2006 IEEE.","Bio-medical image processing; diabetes; Image motion analysis; Medical diagnostics; stereo image processing, Cameras; Diagnosis; Image reconstruction; Image registration; Imaging systems; Mathematical operators; Ophthalmology; Optical data processing; Optical flows; Personnel training, Medical imaging, algorithm; article; calibration; camera; digital fundus camera; exudate; eye fundus; eye photography; human; image processing; image reconstruction; measurement error; multiple retinal fundus image; optic flow; quantitative analysis; retina macula edema, Algorithms; Fundus Oculi; Humans; Image Processing, Computer-Assisted; Macula Lutea; Ophthalmoscopy; Point-of-Care Systems; Telemedicine"
"Singh N,Kumar A,Tripathi RC",An automated hybrid technique for detecting the stage of non-proliferative diabetic retinopathy,2010,"Diabetes is fast becoming a scourge in the modern day society both in the developing and the developed societies. Diabetes related complications lead to a lot of morbidity and Diabetic Retinopathy is fast becoming the cause of preventable blindness. Early detection and treatment with Laser will go a long way in checking this disease. Non-proliferative Diabetic Retinopathy (NPDR) is the set of early changes that take place in the Retina. It is divided into 3 categories into mild, moderate and severe. Initial changes when the microaneurysms (MA) start appearing. Then it is followed by hemorrhages. Finally appearance of cotton wool spots and hard exudates categorize it into severe NPDR. The stage of neo vascularization (NV) when new blood vessels begin to appear (to compensate for the reduced blood supply and nutrition to the retina) finally qualifies for proliferative Diabetic Retinopathy. The idea is to extract the features of NPDR and depending on their intensity and frequency they can be graded into mild, moderate and severe. This automated grading can be matched with the specialist's perception and its accuracy can be tested. In this work, we have proposed a computer based automated hybrid technique for the detection of stages of Non-Proliferative Diabetic Retinopathy (NPDR) retinopathy stage using the color fundus images. The features are extracted from the Sample images using the image processing techniques and fed to the support vector machine (SVM). After color normalization preprocessing stage, an evidence value for every pixel is calculated by SVM. Then a mathematical morphological technique, a fuzzy c-means clustering technique, PCA, a support vector machine and a nearest neighbor classifier for further processing. The SVM classifier uses features extracted by combined 2DPCA instead of explicit image features as the input vector Combined 2DPCA is proposed and virtual SVM is applied to achieve the higher accuracy of classification. We demonstrate a Sensitivity of 97.1% for the classifier with the Specificity of 98.3%. Thus, an automated system for diagnosis of NPDR can be a useful tool for the Specialist to support in screening an detection of early Diabetic Retinopathy changes and hence timely intervention leading to reduced DR(Diabetic retinopathy) related blindness. © 2010 ACM.","Automated grading; Automated systems; Blood supply; Color normalization; Cotton-wool spots; Diabetic retinopathy; Early detection; Fundus image; Fuzzy C means clustering; Hard exudates; Hybrid techniques; Image features; Image processing technique; Input vector; Microaneurysms; Nearest Neighbor classifier; non-proliferative diabetic retinopathy (NPDR); SVM classifiers; Vascularization, Automation; Blood; Blood vessels; Diagnosis; Extraction; Image enhancement; Mathematical morphology; Principal component analysis; Support vector machines, Eye protection"
"Guo D,Zhang D,Li N",Monitor blood glucose levels via breath analysis system and sparse representation approach,2010,"It has been reported that the abnormal concentration of acetone in exhaled air is an indicator of diabetes and the concentration rises progressively with the blood glucose level of patients. Therefore, the acetone in human breath can be used to monitor the development of diabetes. In this paper, we introduce a breath analysis system to measure acetone in human breath, and therefore to evaluate the blood glucose levels of diabetics. The system structure, breath collection method, and signal preprocessing method are introduced. To enhance the system performance, we use a novel classification approach, i.e., Sparse Representation based Classification (SRC), to classify diabetics' breath samples into different blood glucose levels. Experimental results show that coupling with SRC, the system is able to classify these levels with satisfactory accuracy. ©2010 IEEE.","Abnormal concentrations; Blood glucose level; Breath analysis; Classification approach; Collection methods; Human breath; Signal preprocessing; Sparse representation; System structures, Acetone; Blood; Sensors, Glucose"
"Vahabi Z,Vafadoost M,Gharibzadeh S",The new approach to automatic detection of Optic Disc from non-dilated retinal images,2010,"Diabetic retinopathy is the commonest cause of blindness. Diabetes causes cataracts, Glaucoma and diabetic retinopathy. The Optic Disc is the exit point of retinal nerve fibers from the eye and the entrance and exit point for retinal blood vessels. The detection of Optic Disc is very essential to locate the various anatomical features in the retinal images. We describe a new filtering approach in the wavelet domain for image preprocessing. Sobel edge detection, Texture Analysis, Intensity and Template matching was used to detect Optic Disc. The proposed algorithm is tested on 150 images of Messidor dataset. Experimental results indicates that we are able to achieve 87.54% sensitivity, 99.76% specificity and 99.81% accuracy. © 2010 IEEE.","Diabetic retinopathy; Gradient; Morphlogical operation; Optic disk; Wavelet packet, Algorithms; Biomedical engineering; Blood vessels; Disks (structural components); Edge detection; Entropy; Eye protection; Image enhancement; Ophthalmology; Template matching, Image matching"
"Jayalskshmi T,Santhakumaran A",Impact of preprocessing for diagnosis of diabetes mellitus using artificial neural networks,2010,Medicine has always benefited from the technology. Artificial Neural Networks is currently the promising area of interest to solve medical problems. Diagnosis of diabetes is one of the most challenging problems in machine learning. This medical data set is seldom complete. Artificial neural networks require complete set of data for an accurate classification. The system explains how the pre-processing procedure and missing values influence the data set during the classification. The implemented system compares various missing value techniques and pre-processing techniques. Some combinations prove the real influence of these techniques. A classifier has applied to Pima Indian Diabetes dataset and the results were improved tremendously when using certain combination of preprocessing and missing value techniques. The experimental system achieves an excellent classification accuracy of 99% which is best than before. © 2010 IEEE.,"Area of interest; Artificial Neural Network; Classification accuracy; Data sets; Diabetes mellitus; Experimental system; Machine-learning; Medical data; Missing values; Pima Indian Diabetes; Pre-processing; Pre-processing method, Autocorrelation; Backpropagation; Classification (of information); Data flow analysis; Learning systems; Medical problems; Processing; Value engineering, Neural networks"
"Jayalakshmi T,Santhakumaran A",A novel classification method for diagnosis of diabetes mellitus using artificial neural networks,2010,"Many real world problems can be solved with Artificial Neural Networks in the areas of pattern recognition, signal processing and medical diagnosis. Most of the medical data set is seldom complete. Artificial Neural Networks require complete set of data for an accurate classification. This paper dwells on the various missing value techniques to improve the classification accuracy. The proposed system also investigates the impact on preprocessing during the classification. A classifier was applied to Pima Indian Diabetes Dataset and the results were improved tremendously when using certain combination of preprocessing techniques. The experimental system achieves an excellent classification accuracy of 99% which is best than before. © 2010 IEEE.","Artificial Neural Network; Classification accuracy; Classification methods; Data sets; Diabetes mellitus; Experimental system; Medical data; Medical diagnosis; Missing values; Pima Indian Diabetes; Pre-processing method; Preprocessing techniques; Real-world problem, Data storage equipment; Diagnosis; Medical problems; Pattern recognition; Processing; Signal processing; Value engineering, Neural networks"
"Fard ST,Chrostowski L,Kwok E,Amann MC",Chemometric approach for improving VCSEL-based glucose predictions,2010,"Optical methods are one of the painless and promising techniques that can be used for blood glucose predictions for diabetes patients. The use of thermally tunable vertical cavity surface-emitting lasers (VCSELs) as the light source to obtain blood absorption spectra, along with the multivariate technique partial least squares for analysis and glucose estimation, has been demonstrated. With further improvements by using data preprocessing and two VCSELs, we have achieved a clinically acceptable level in the physiological range in buffered solutions. The results of previous experiments conducted using white light showed that increasing the number of wavelength intervals used in the analysis improves the accuracy of prediction. The average prediction error, using absorption spectra from one VCSEL in aqueous solution, is about 1.2 mM. This error is reduced to 0.8 mM using absorption spectra from two VCSELs. This result confirms that increasing the number of VCSELs improves the accuracy of prediction. © 2006 IEEE.","Aqueous solutions; Average prediction error; Blood glucose; Buffered solutions; Chemometric approach; Chemometrics; Data preprocessing; Diabetes patients; Glucose monitoring; Multivariate techniques; Optical methods; Partial least squares; Physiological range; Real-time glucose monitoring; Vertical-cavity surface emitting laser; White light, Absorption; Blood; Forecasting; Light; Light absorption; Light sources; Surface emitting lasers; Transceivers, Glucose, buffer; glucose, absorption spectroscopy; accuracy; aqueous solution; article; blood; chemometric analysis; diabetic patient; glucose blood level; human; information processing; laser; physiology; prediction; signal noise ratio; spectral sensitivity; vertical cavity surface emitting laser; white light, Blood Glucose; Humans; Lasers; Magnetic Resonance Spectroscopy; Models, Biological; Monitoring, Physiologic; Predictive Value of Tests; Reproducibility of Results; Signal Processing, Computer-Assisted"
"Guo D,Zhang D,Li N,Zhang L,Yang J",A novel breath analysis system based on electronic olfaction,2010,"Certain gases in the breath are known to be indicators of the presence of diseases and clinical conditions. These gases have been identified as biomarkers using equipments, such as gas chromatography and electronic nose (e-nose). GC is very accurate but is expensive, time consuming, and nonportable. E-nose has the advantages of low cost and easy operation, but is not particular for analyzing breath odor, and hence, has a limited application in diseases diagnosis. This paper proposes a novel system that is special for breath analysis. We selected chemical sensors that are sensitive to the biomarkers and compositions in human breath, developed the system, and introduced the odor signal preprocessing and classification method. To evaluate the system performance, we captured breath samples from healthy persons and patients known to be afflicted with diabetes, renal disease, and airway inflammation, respectively, and conducted experiments on medical treatment evaluation and disease identification. The results show that the system is not only able to distinguish between breath samples from subjects suffering from various diseases or conditions (diabetes, renal disease, and airway inflammation) and breath samples from healthy subjects, but in the case of renal failure is also helpful in evaluating the efficacy of hemodialysis (treatment for renal failure). © 2010 IEEE.","Biomarkers; Chemical analysis; Chemical sensors; Chromatography; Diagnosis; Disease control; Electronic nose; Gas chromatography; Pathology; Patient treatment, Airway inflammation; Breath analysis; Classification methods; Clinical conditions; Electronic nose (e-nose); Electronic olfaction; Signal preprocessing; Therapy monitoring, Diseases, article; breath analysis; clinical effectiveness; controlled study; diabetes mellitus; diagnostic accuracy; diagnostic error; electronic nose; hemodialysis; human; kidney disease; kidney failure; medical instrumentation; olfactometer; respiratory tract inflammation; sensor; signal processing"
"Balakrishnan S,Narayanaswamy R,Savarimuthu N,Samikannu R",Svm ranking with backward search for feature selection in type II diabetes databases,2008,"Clinical databases have accumulated large quantities of information about patients and their clinical history. Data mining is the search for relationships and patterns within this data that could provide useful knowledge for effective decision-making. Classification analysis is one of the widely adopted data mining techniques for healthcare applications to support medical diagnosis, improving quality of patient care, etc. Usually medical databases are high dimensional in nature. If a training dataset contains irrelevant features (i.e., attributes), classification analysis may produce less accurate results. Data pre-processing is required to prepare the data for data mining and machine learning to increase the predictive accuracy. Feature selection is a preprocessing technique commonly used on high-dimensional data and its purposes include reducing dimensionality, removing irrelevant and redundant features, reducing the amount of data needed for learning, improving algorithms' predictive accuracy, and increasing the constructed models' comprehensibility. Much research work in data mining has gone into improving the predictive accuracy of the classifiers by applying the techniques of feature selection. The importance of feature selection in medical data mining is appreciable as the diagnosis of the disease could be done in this patient-care activity with minimum number of features. Feature selection may provide us with the means to reduce the number of clinical measures made while still maintaining or even enhancing accuracy and reducing false negative rates. In medical diagnosis, reduction in false negative rate can, literally, be the difference between life and death. In this paper we propose a feature selection approach for finding an optimum feature subset that enhances the classification accuracy of Naive Bayes classifier. Experiments were conducted on the Pima Indian Diabetes Dataset to assess the effectiveness of our approach. The results confirm that SVM Ranking with Backward Search approach leads to promising improvement on feature selection and enhances classification accuracy. © 2008 IEEE.","Backward search; Classification accuracy; False negative rate; Feature selection; Predictive accuracy; SVM, Classifiers; Control theory; Cybernetics; Data mining; Data processing; Database systems; Diagnosis; Learning algorithms; Support vector machines, Medical computing"
"Han J,Rodriguze JC,Beheshti M",Diabetes data analysis and prediction model discovery using RapidMiner,2008,"Data mining techniques have been extensively applied in bioinformatics to analyze biomedical data. In this paper, we choose the Rapid-I's RapidMiner as our tool to analyze a Pima Indians Diabetes Data Set, which collects the information of patients with and without developing diabetes. The discussion follows the data mining process. The focus will be on the data preprocessing, including attribute identification and selection, outlier removal, data normalization and numerical discretization, visual data analysis, hidden relationships discovery, and a diabetes prediction model construction. © 2008 IEEE.","Biomedical datum; Data analysis; Data mining process; Data mining techniques; Data normalizations; Data pre-processing; Data sets; Numerical discretization; Prediction models; Visual data analysis, Bioinformatics; Information management; Mining, Data mining"
"Nayak J,Bhat PS,Acharya U R,Lim CM,Kagathi M",Automated identification of diabetic retinopathy stages using digital fundus images,2008,"Diabetic retinopathy (DR) is caused by damage to the small blood vessels of the retina in the posterior part of the eye of the diabetic patient. The main stages of diabetic retinopathy are non-proliferate diabetes retinopathy (NPDR) and proliferate diabetes retinopathy (PDR). The retinal fundus photographs are widely used in the diagnosis and treatment of various eye diseases in clinics. It is also one of the main resources for mass screening of diabetic retinopathy. In this work, we have proposed a computer-based approach for the detection of diabetic retinopathy stage using fundus images. Image preprocessing, morphological processing techniques and texture analysis methods are applied on the fundus images to detect the features such as area of hard exudates, area of the blood vessels and the contrast. Our protocol uses total of 140 subjects consisting of two stages of DR and normal. Our extracted features are statistically significant (p<0.0001) with distinct mean±SD as shown in Table 1. These features are then used as an input to the artificial neural network (ANN) for an automatic classification. The detection results are validated by comparing it with expert ophthalmologists. We demonstrated a classification accuracy of 93%, sensitivity of 90% and specificity of 100%. © 2007 Springer Science+Business Media, LLC.","article; artificial neural network; automation, computers and data processing; blood vessel; diabetic retinopathy; diagnostic accuracy; diagnostic imaging; eye disease; eye fundus; human; image analysis; morphology; photography; sensitivity and specificity; statistical significance, Diabetic Retinopathy; Diagnosis, Computer-Assisted; Fluorescein Angiography; Humans"
"Cho BH,Yu H,Kim KW,Kim TH,Kim IY,Kim SI",Application of irregular and unbalanced data to predict diabetic nephropathy using visualization and feature selection methods,2008,"Objective: Diabetic nephropathy is damage to the kidney caused by diabetes mellitus. It is a common complication and a leading cause of death in people with diabetes. However, the decline in kidney function varies considerably between patients and the determinants of diabetic nephropathy have not been clearly identified. Therefore, it is very difficult to predict the onset of diabetic nephropathy accurately with simple statistical approaches such as t-test or ?2-test. To accurately predict the onset of diabetic nephropathy, we applied various machine learning techniques to irregular and unbalanced diabetes dataset, such as support vector machine (SVM) classification and feature selection methods. Visualization of the risk factors was another important objective to give physicians intuitive information on each patient's clinical pattern. Methods and materials: We collected medical data from 292 patients with diabetes and performed preprocessing to extract 184 features from the irregular data. To predict the onset of diabetic nephropathy, we compared several classification methods such as logistic regression, SVM, and SVM with a cost sensitive learning method. We also applied several feature selection methods to remove redundant features and improve the classification performance. For risk factor analysis with SVM classifiers, we have developed a new visualization system which uses a nomogram approach. Results: Linear SVM classifiers combined with wrapper or embedded feature selection methods showed the best results. Among the 184 features, the classifiers selected the same 39 features and gave 0.969 of the area under the curve by receiver operating characteristics analysis. The visualization tool was able to present the effect of each feature on the decision via graphical output. Conclusions: Our proposed method can predict the onset of diabetic nephropathy about 2-3 months before the actual diagnosis with high prediction performance from an irregular and unbalanced dataset, which statistical methods such as t-test and logistic regression could not achieve. Additionally, the visualization system provides physicians with intuitive information for risk factor analysis. Therefore, physicians can benefit from the automatic early warning of each patient and visualize risk factors, which facilitate planning of effective and proper treatment strategies. © 2007 Elsevier B.V. All rights reserved.","Data visualization; Decision support systems; Feature extraction; Medical problems; Patient monitoring; Risk analysis; Statistical methods; Support vector machines, Diabetic nephropathy; Logistic regression; Risk factor analysis, Hospital data processing, hemoglobin A1c; high density lipoprotein cholesterol, article; controlled study; diabetic nephropathy; diagnostic accuracy; human; major clinical study; medical record; nomogram; non insulin dependent diabetes mellitus; prediction and forecasting; priority journal; risk factor; sensitivity and specificity; support vector machine; systolic blood pressure, Algorithms; Artificial Intelligence; Decision Support Systems, Clinical; Diabetic Nephropathies; Diagnosis, Computer-Assisted; Humans; Logistic Models; Neural Networks (Computer); Predictive Value of Tests; Risk Factors; ROC Curve"
Luukka P,Similarity classifier using similarity measure derived from Yu's norms in classification of medical data sets,2007,"A new approach using a similarity measure based on Yu's norms is presented for the detection of erythemato-squamous diseases, diabetes, breast cancer, lung cancer and lymphography. The domain contains records of patients with known diagnoses. The results are very promising with all data sets and (in conclusion, can be drawn that) a similarity model derived from Yu's norms could be used for the diagnosis of patients taking into consideration the error rate. A similarity classifier derived from Yu's norms was used to detect the six erythemato-squamous diseases when 34 features defining six disease indications were used as inputs. The results confirmed that the proposed model has potential in detecting the erythemato-squamous diseases. The similarity model derived from Yu's norms achieved an accuracy rate (97.8 %) which was higher than that of the stand-alone neural network model or the ANFIS model suggested in Übeyli and Güler [Automatic detection of erythemato-squamous diseases using adaptive neuro-fuzzy inference systems, Comput. Biol. Med. 35 (2005) 421-433] or the similarity model based on ?ukasiewicz similarity [Luukka and Leppälampi, Similarity classifier with generalized mean applied to medical data, Comput. Biol. Med. 36 (2006) 1026-1040]. With PIMA Indian diabetes, the detection model has an error rate of about 24 % which is much better than the overall rate of 33 % for diabetes. Also, a classifier was applied to the lung cancer data set and the results were to my knowledge better than before. When the lung cancer data were preprocessed with an entropy minimization technique and the classifier with similarity based on Yu's norm was applied, 99.99 % accuracy was achieved. The use of this preprocessing method enhanced the results over 30 %. In lymphography, entropy minimization also enhanced the results remarkably and 86.2 % accuracy was achieved. © 2006 Elsevier Ltd. All rights reserved.","Data acquisition; Entropy; Medical problems; Optimization; Patient treatment; Tumors, Lymphography; Medical data sets; Similarity classifier; Yu's norms, Diagnostic products, article; artificial neural network; breast cancer; controlled study; diabetes mellitus; diagnostic accuracy; diagnostic error; diagnostic procedure; entropy; erythema; human; lung cancer; lymphography; medical informatics; priority journal; squamous epithelium, Breast Neoplasms; Databases, Factual; Diabetes Mellitus; Diagnosis, Computer-Assisted; Female; Fuzzy Logic; Humans; Lung Neoplasms; Lymphography; Male; Neural Networks (Computer); Principal Component Analysis; Skin Diseases, Citrus maxima"
"Saptari V,Youcef-Toumi K",Measurements and quality assessments of near-infrared plasma glucose spectra in the combination band region using a scanning filter spectrometer,2005,"Near-infrared measurements of glucose in human plasma are performed using a custom, rapid, high-throughput filter-based spectrometer covering a spectral range between 2080 and 2315 nm. Quality of the measured glucose signals is quantified through the use of two figures of merit: selectivity and limit of detection. Selectivity measures the uniqueness of the glucose spectrum from among the interfering spectra. Limit of detection measures the smallest glucose concentration change detectable. The proposed system, which includes the spectroscopic hardware and a spectral preprocessing algorithm, is shown to produce a selectivity value of 0.57, with zero being nonselective and one being fully selective, and a limit of detection value of 2.2 mM. Prediction of an independent dataset is also performed using net analyte signal-based and partial least-squares multi-variate calibration techniques, which produce standard error of prediction values of 1.14 and 1.45 mM, respectively. © 2005 Society of Photo-Optical Instrumentation Engineers.","Algorithms; Glucose; Infrared spectroscopy; Spectrometers; Spectrum analysis, Diabetes; Near-infrared measurements; Plasma glucose spectra; Scanning filter spectrometer, Biomedical engineering, algorithm; article; equipment; equipment design; evaluation; glucose blood level; human; infrared spectrophotometry; instrumentation; methodology; quality control; reproducibility; sensitivity and specificity, Algorithms; Blood Glucose; Equipment Design; Equipment Failure Analysis; Humans; Quality Control; Reproducibility of Results; Sensitivity and Specificity; Spectrophotometry, Infrared"
"Koehler C,Koenig A,Temelkova-Kurktschiev T,Hanefeld M",Application of interactive multivariate data visualization to the analysis of patients findings in metabolic research,1999,"In this paper, methods for multivariate data projection, resulting feature map display, and interactive visual analysis are applied in an interdisciplinary cooperation for the analysis of patients findings in metabolic research. From a medical database, collected in corresponding research, data sets were subject to preprocessing, projection, and visual analysis. Globally significant parameters could be identified by this work, that coincide with certain patient groups, e.g. characterized by the attributes sex and diabetes. Further, the visualization techniques opened a way to find local correlations and interdependencies between parameters within subgroups. The medical analysis is supported by a recent dedicated PC-based tool that allows the processing and interactive visualization of the medical databases by means of novel features and techniques.","Database systems; Feature extraction; Metabolism; Visualization, Multivariate data visualization, Medical computing"
